{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729ed21",
   "metadata": {},
   "source": [
    "# Metadata stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be730fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66fe0dd1",
   "metadata": {},
   "source": [
    "## ROSMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('./AMP_AD_datasets/ROSMAP_Covariates_ages_censored.tsv', sep='\\t')\n",
    "\n",
    "# Calculating the number of unique values in each column\n",
    "unique_values = df.nunique()\n",
    "\n",
    "unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6602ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['diagnosis', 'tissue', 'race', 'spanish',\n",
    "       'apoe4_allele', 'sex', 'final_batch', 'pmi', 'RIN', 'RIN2', 'age_death']\n",
    "\n",
    "# Function to print unique values and their counts for given column names\n",
    "def print_unique_values_counts(dataframe, columns):\n",
    "    for column in columns:\n",
    "        print(f\"Unique value counts for {column}:\")\n",
    "        print(dataframe[column].value_counts())\n",
    "        print(\"\\n\")  # Print a newline for better readability between columns\n",
    "\n",
    "# Call the function with the DataFrame and list of column names\n",
    "print_unique_values_counts(df, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0125d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8ab0012",
   "metadata": {},
   "source": [
    "## MSSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f768154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('./AMP_AD_datasets/MSBB_Covariates_ages_censored.tsv', sep='\\t')\n",
    "\n",
    "# Calculating the number of unique values in each column\n",
    "unique_values = df.nunique()\n",
    "\n",
    "unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['tissue', 'sex', 'race', 'spanish', 'ethnicity',\n",
    "       'age_death', 'RIN', 'RIN2', 'diagnosis', 'sequencingBatch', 'pmi',\n",
    "       'apoe4_allele']\n",
    "\n",
    "# Function to print unique values and their counts for given column names\n",
    "def print_unique_values_counts(dataframe, columns):\n",
    "    for column in columns:\n",
    "        print(f\"Unique value counts for {column}:\")\n",
    "        print(dataframe[column].value_counts())\n",
    "        print(\"\\n\")  # Print a newline for better readability between columns\n",
    "\n",
    "# Call the function with the DataFrame and list of column names\n",
    "print_unique_values_counts(df, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7d296",
   "metadata": {},
   "source": [
    "## MAYO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('./AMP_AD_datasets/Mayo_Covariates_ages_censored.tsv', sep='\\t')\n",
    "\n",
    "# Calculating the number of unique values in each column\n",
    "unique_values = df.nunique()\n",
    "\n",
    "unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ffc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['tissue', 'diagnosis', 'apoe4_allele',\n",
    "       'sex', 'flowcell', 'pmi', 'RIN', 'RIN2', 'age_death']\n",
    "\n",
    "# Function to print unique values and their counts for given column names\n",
    "def print_unique_values_counts(dataframe, columns):\n",
    "    for column in columns:\n",
    "        print(f\"Unique value counts for {column}:\")\n",
    "        print(dataframe[column].value_counts())\n",
    "        print(\"\\n\")  # Print a newline for better readability between columns\n",
    "\n",
    "# Call the function with the DataFrame and list of column names\n",
    "print_unique_values_counts(df, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29482641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3472108",
   "metadata": {},
   "source": [
    "## Corrections before merging metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the DataFrame from a TSV file\n",
    "file_path = './AMP_AD_datasets/Mayo_Covariates_ages_censored.tsv'  # Update this to your actual file path\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "df = df.rename(columns={'flowcell': 'batch'})\n",
    "\n",
    "# Step 2: Identify unique values in 'batch' column and sort them alphabetically\n",
    "unique_batches = sorted(df['batch'].unique())\n",
    "\n",
    "# Step 3: Assign a unique number to each sorted unique value\n",
    "batch_to_number = {batch: i+1 for i, batch in enumerate(unique_batches)}\n",
    "\n",
    "# Step 4: Replace the original 'batch' values in the DataFrame with the assigned numbers\n",
    "df['batch'] = df['batch'].map(batch_to_number)\n",
    "\n",
    "# Step 5: Save the modified DataFrame as a CSV file\n",
    "new_file_path = './AMP_AD_datasets/MAYO_metadata_v1.csv'  # Update this to your desired new file path\n",
    "df.to_csv(new_file_path, index=False)  # Set index=False to avoid saving the index as a separate column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f839f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af05615d",
   "metadata": {},
   "source": [
    "## Merging the metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a634c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names\n",
    "file_names = ['./AMP_AD_datasets/ROSMAP_metadata_v1.csv', \n",
    "              './AMP_AD_datasets/MSBB_metadata_v1.csv', \n",
    "              './AMP_AD_datasets/MAYO_metadata_v1.csv']\n",
    "\n",
    "# Empty list to hold DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Columns to ensure are in each DataFrame\n",
    "required_columns = ['race', 'spanish', 'ethnicity']\n",
    "\n",
    "# Step 1: Read each CSV file and process\n",
    "for file_name in file_names:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "   \n",
    "    # Ensure all required columns are present, add them if they are not\n",
    "    for column in required_columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = pd.NA\n",
    "    \n",
    "    df['study'] = file_name.split('/')[2].split('_')[0]\n",
    "            \n",
    "    # Append to the list of DataFrames\n",
    "    dfs.append(df)\n",
    "\n",
    "# Use the column order of the first DataFrame for all others, including any new columns\n",
    "column_order = dfs[0].columns.tolist()\n",
    "\n",
    "# Reorder and concatenate, ensuring all DataFrames have the same column order\n",
    "merged_df = pd.concat([df.reindex(columns=column_order) for df in dfs], ignore_index=True)\n",
    "\n",
    "# Step 5: Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('./merged_metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d07aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7cd17ff",
   "metadata": {},
   "source": [
    "## Converting values to numerics in merged metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbaf1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = './merged_metadata.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Dictionaries for conversion\n",
    "diagnosis = {'AD':1, 'CT':0, 'OTHER':2, 'PSP':3, 'PATH_AGE':4}\n",
    "sex = {'male': 0, 'female': 1}\n",
    "tissue = {'ACC': 1, 'CBE': 2, 'DLPFC': 3, 'FP': 4, 'IFG': 5, 'PCC': 6, 'PHG': 7, 'STG': 8, 'TCX': 9}\n",
    "\n",
    "# Convert values in the 'diagnosis', 'sex', and 'tissue' columns using the map method\n",
    "df['diagnosis'] = df['diagnosis'].map(diagnosis)\n",
    "df['sex'] = df['sex'].map(sex)\n",
    "df['tissue'] = df['tissue'].map(tissue)\n",
    "\n",
    "# Change '90+' value in the 'age_death' column to 90\n",
    "df['age_death'] = df['age_death'].replace('90+', 90)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('./metadata_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8123f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of NULL values in each column\n",
    "null_values = df.isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bf4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c4c879",
   "metadata": {},
   "source": [
    "## Visualization of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosmap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = './metadata_v1.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "rosmap_df = df[df['study'] == 'ROSMAP']\n",
    "\n",
    "columns_to_visualize = ['diagnosis', 'tissue', 'race', 'apoe4_allele', 'sex']\n",
    "\n",
    "# Adjust figsize for overall figure and subplot size, making each chart smaller\n",
    "# Increase the height as needed to separate the charts more\n",
    "fig, axes = plt.subplots(len(columns_to_visualize), 1, figsize=(6, 3 * len(columns_to_visualize)))\n",
    "\n",
    "for i, column in enumerate(columns_to_visualize):\n",
    "    # For each column, count the occurrences of each unique value\n",
    "    value_counts = rosmap_df[column].value_counts()\n",
    "    \n",
    "    # Plotting the bar chart for the current column\n",
    "    axes[i].bar(value_counts.index.astype(str), value_counts.values, color='blue')\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].set_xlabel('Value')\n",
    "  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Adjust layout padding\n",
    "plt.tight_layout(pad=3.0)  # Increase pad size for more space between subplots\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57822a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b7e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f2dad42",
   "metadata": {},
   "source": [
    "# Feature importance selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401925a",
   "metadata": {},
   "source": [
    "## Chi-Square method for categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c120c904",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './metadata_v1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the DataFrame from a CSV file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./metadata_v1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace 'your_file_path.csv' with the path to your actual CSV file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Filter the DataFrame\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ROSMAP_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROSMAP\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]))]\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './metadata_v1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from a CSV file\n",
    "file_path = './b'  # Replace 'your_file_path.csv' with the path to your actual CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter the DataFrame\n",
    "ROSMAP_df = df[(df['study'] == 'ROSMAP') & (df['diagnosis'].isin([0, 1]))]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "ROSMAP_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming ROSMAP_df is already defined and loaded with your data\n",
    "\n",
    "# Specify your binary target column and the list of categorical independent variable names\n",
    "target_column = 'diagnosis'\n",
    "independent_variables = ['tissue', 'race', 'spanish', 'apoe4_allele', 'sex', 'batch']\n",
    "\n",
    "# Ensure the target variable is binary and encoded as 0s and 1s\n",
    "le = LabelEncoder()\n",
    "ROSMAP_df.loc[:, target_column] = le.fit_transform(ROSMAP_df[target_column])\n",
    "\n",
    "# Convert categorical variables to type 'category' if they aren't already\n",
    "for var in independent_variables:\n",
    "    ROSMAP_df.loc[:, var] = ROSMAP_df[var].astype('category')\n",
    "\n",
    "# Note: There's a mistake in your chi2 function call; it should reference ROSMAP_df, not df\n",
    "chi_scores, p_values = chi2(ROSMAP_df[independent_variables].apply(lambda x: x.cat.codes), ROSMAP_df[target_column])\n",
    "\n",
    "# Display the p-values for each independent variable\n",
    "for var, p in zip(independent_variables, p_values):\n",
    "    print(f\"P-value for {var}: {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f575a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROSMAP_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903a5f2",
   "metadata": {},
   "source": [
    "## Normality of the continous independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "# List of your continuous variable column names\n",
    "continuous_variables = ['pmi', 'RIN', 'RIN2', 'age_death', 'AlignmentSummaryMetrics_PCT_PF_READS_ALIGNED', 'RnaSeqMetrics_PCT_INTRONIC_BASES', 'RnaSeqMetrics_PCT_INTERGENIC_BASES',\n",
    "                        'RnaSeqMetrics_PCT_CODING_BASES']  # Replace these with your actual column names\n",
    "\n",
    "# Initialize an empty dictionary to store Shapiro-Wilk test results\n",
    "normality_test_results = {}\n",
    "\n",
    "# Perform the Shapiro-Wilk test for each variable\n",
    "for var in continuous_variables:\n",
    "    stat, p_value = shapiro(ROSMAP_df[var].dropna())  # dropna() to remove missing values\n",
    "    normality_test_results[var] = p_value\n",
    "\n",
    "    # Interpret the results\n",
    "    alpha = 0.05  # Significance level\n",
    "    if p_value > alpha:\n",
    "        print(f\"{var}: Data looks normal (fail to reject H0, p-value={p_value:.3f})\")\n",
    "    else:\n",
    "        print(f\"{var}: Data does not look normal (reject H0, p-value={p_value:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82575a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29c7fde1",
   "metadata": {},
   "source": [
    "## Reg model for continous variables p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Specify your binary target column and list of independent variable names\n",
    "target_column = 'diagnosis'  # Replace with your actual target column name\n",
    "independent_variables = ['pmi', 'RIN', 'RIN2', 'age_death', 'AlignmentSummaryMetrics_PCT_PF_READS_ALIGNED', 'RnaSeqMetrics_PCT_INTRONIC_BASES', 'RnaSeqMetrics_PCT_INTERGENIC_BASES',\n",
    "                        'RnaSeqMetrics_PCT_CODING_BASES']\n",
    "\n",
    "# Ensure the independent variables and target are correctly formatted\n",
    "X = ROSMAP_df[independent_variables]\n",
    "y = ROSMAP_df[target_column]\n",
    "\n",
    "# Add a constant to the independent variables set for statsmodels\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model using statsmodels\n",
    "model = sm.Logit(y, X).fit()\n",
    "\n",
    "# Display the summary of the model which includes p-values among other statistics\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c60682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4baf5794",
   "metadata": {},
   "source": [
    "# Distribution of gene expresion levels Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dff = pd.read_csv(\"/home/vmottaqi/rnaseq_synapse/AMP_AD_datasets/ROSMAP_Normalized_counts_(CQN).tsv\", sep='\\t')\n",
    "\n",
    "df = dff.iloc[:, 1:]\n",
    "# Count negative values across the DataFrame\n",
    "negative_values_count = (df < 0).sum().sum()  # Sums up all the True values for the condition df < 0\n",
    "\n",
    "# Count NaN (NULL) values across the DataFrame\n",
    "null_values_count = df.isnull().sum().sum()  # Sums up all the NaN values\n",
    "\n",
    "print(f\"Total negative values in the dataset: {negative_values_count}\")\n",
    "print(f\"Total NULL (NaN) values in the dataset: {null_values_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa57973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  # For numerical operations\n",
    "\n",
    "# Load your DataFrame, ensuring the first column (gene names) is read as a regular column\n",
    "df = pd.read_csv(\"/home/vmottaqi/rnaseq_synapse/AMP_AD_datasets/ROSMAP_Normalized_counts_(CQN).tsv\", sep='\\t')\n",
    "\n",
    "# Calculate the median and variance for each gene across samples\n",
    "df['Median'] = df.iloc[:, 1:].mean(axis=1)  # Exclude the first column (gene names) for calculation\n",
    "df['Variance'] = df.iloc[:, 1:].var(axis=1)  # Exclude the first column (gene names) for calculation\n",
    "\n",
    "# Transform the median and variance back from log2 values\n",
    "df['Median_back_transformed'] = np.power(2, df['Median'])\n",
    "df['Variance_back_transformed'] = np.power(2, df['Variance'])\n",
    "\n",
    "# Create a new DataFrame with gene names, median, variance, and their back-transformed values\n",
    "output_df = df[['feature', 'Median', 'Variance', 'Median_back_transformed', 'Variance_back_transformed']]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "output_df.to_csv('mean_ROSMAP.csv', index=False)\n",
    "\n",
    "print(\"Gene expression statistics computed and back-transformed values added successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"mean_ROSMAP.csv\")\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the DataFrame with median and variance back-transformed values\n",
    "df = pd.read_csv('median_ROSMAP.csv')\n",
    "\n",
    "# Histogram for Median_back_transformed\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['Median_back_transformed'], bins=3000, alpha=0.7)\n",
    "plt.xlabel('Expression Levels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Median of gene expression levels')\n",
    "plt.legend()\n",
    "plt.xlim(0, 600)  # Limiting the x-axis to be between 0 and 2\n",
    "plt.show()\n",
    "\n",
    "# Histogram for Variance_back_transformed\n",
    "plt.figure(figsize=(8, 5))\n",
    "# Use np.logspace to create logarithmic bins\n",
    "logbins = np.logspace(np.log10(df['Variance_back_transformed'].min()), np.log10(df['Variance_back_transformed'].max()), 50)\n",
    "plt.hist(df['Variance_back_transformed'], bins=logbins, alpha=0.7, color='orange')\n",
    "plt.xscale('log')  # Set x-axis to log scale\n",
    "plt.xlabel('Variance (log scale)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Variance of gene expression levels')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"mean_r.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d2891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aecb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b66562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d8f039",
   "metadata": {},
   "source": [
    "# Concating the datasets with metadata (not worked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_paths = ['./AMP_AD_datasets/ROSMAP_Normalized_counts_(CQN).tsv', \n",
    "              './AMP_AD_datasets/MSBB_Normalized_counts_(CQN).tsv', \n",
    "              './AMP_AD_datasets/Mayo_Normalized_counts_(CQN).tsv']\n",
    "\n",
    "# Load the first column (gene names) from each dataset and store in a list\n",
    "gene_lists = [pd.read_csv(file, sep='\\t', usecols=[0])[pd.read_csv(file, sep='\\t', usecols=[0]).columns[0]].unique() for file in file_paths]\n",
    "\n",
    "# Convert each list of gene names to a set\n",
    "gene_sets = [set(gene_list) for gene_list in gene_lists]\n",
    "\n",
    "# Find the intersection of gene names across all datasets\n",
    "common_genes = set.intersection(*gene_sets)\n",
    "\n",
    "# Print the number of common gene names\n",
    "print(f\"Number of common gene names across all datasets: {len(common_genes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af207de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the metadata file\n",
    "metadata_path = './metadata_v1.csv'  # Adjust path as needed\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Initialize an empty dataframe for merged gene expression data\n",
    "gene_expression_merged = pd.DataFrame()\n",
    "\n",
    "# List of gene expression datasets\n",
    "gene_expression_files = ['./AMP_AD_datasets/ROSMAP_Normalized_counts_(CQN).tsv', './AMP_AD_datasets/MSBB_Normalized_counts_(CQN).tsv', './AMP_AD_datasets/Mayo_Normalized_counts_(CQN).tsv']  # Adjust paths as needed\n",
    "\n",
    "# Process each gene expression dataset\n",
    "for file in gene_expression_files:\n",
    "    # Load dataset\n",
    "    gene_data = pd.read_csv(file, sep='\\t', index_col=0)  # Assuming the first column contains gene names\n",
    "    \n",
    "    # Transpose so that samples are rows and genes are columns\n",
    "    gene_data_transposed = gene_data.transpose()\n",
    "    \n",
    "    # If this is the first dataset, initialize gene_expression_merged with it\n",
    "    if gene_expression_merged.empty:\n",
    "        gene_expression_merged = gene_data_transposed\n",
    "    else:\n",
    "        # Otherwise, merge this dataset with the existing gene_expression_merged on samples (index)\n",
    "        gene_expression_merged = gene_expression_merged.merge(gene_data_transposed, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "# Rename index to 'specimenID' for merging with metadata\n",
    "gene_expression_merged.index.name = 'specimenID'\n",
    "\n",
    "# Merge metadata with gene expression data based on 'specimenID'\n",
    "final_df = metadata.merge(gene_expression_merged, on='specimenID')\n",
    "\n",
    "# Save the final merged dataframe to a new CSV file\n",
    "final_df.to_csv('./merged_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68037ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7962583",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_files = ['./AMP_AD_datasets/ROSMAP_Normalized_counts_(CQN).tsv', './AMP_AD_datasets/MSBB_Normalized_counts_(CQN).tsv', './AMP_AD_datasets/Mayo_Normalized_counts_(CQN).tsv']\n",
    "gene_data = pd.read_csv(gene_expression_files[0], sep='\\t', index_col=0)\n",
    "gene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_data1 = pd.read_csv(gene_expression_files[1], sep='\\t')\n",
    "gene_data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7465c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a76258d3",
   "metadata": {},
   "source": [
    "# Datasets filtering (cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f7bcd",
   "metadata": {},
   "source": [
    "## 1. unique common genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144378e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_paths = ['./AMP_AD_datasets/ROSMAP_Normalized_counts_(CQN).tsv', \n",
    "              './AMP_AD_datasets/MSBB_Normalized_counts_(CQN).tsv', \n",
    "              './AMP_AD_datasets/Mayo_Normalized_counts_(CQN).tsv']\n",
    "\n",
    "# Load the first column (gene names) from each dataset and store in a list\n",
    "gene_lists = [pd.read_csv(file, sep='\\t', usecols=[0])[pd.read_csv(file, sep='\\t', usecols=[0]).columns[0]].unique() for file in file_paths]\n",
    "\n",
    "# Convert each list of gene names to a set\n",
    "gene_sets = [set(gene_list) for gene_list in gene_lists]\n",
    "\n",
    "# Find the intersection of gene names across all datasets\n",
    "common_genes = set.intersection(*gene_sets)\n",
    "common_genes_list = list(common_genes)\n",
    "\n",
    "# Print the number of common gene names\n",
    "print(f\"Number of common gene names across all datasets: {len(common_genes)}\")\n",
    "print(common_genes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1717da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5919962",
   "metadata": {},
   "source": [
    "## Filtering metadata with diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from a CSV file\n",
    "file_path = './metadata_v1.csv'  # Replace 'your_file_path.csv' with the path to your actual CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = df[df['diagnosis'].isin([0, 1])]\n",
    "filtered_df.reset_index(drop=True)\n",
    "filtered_df.to_csv('metadata_v2_d_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb487898",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './metadata_v2_d_filtered.csv'  # Replace 'your_file_path.csv' with the path to your actual CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6143ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1626dd39",
   "metadata": {},
   "source": [
    "## Filtering the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq = pd.read_csv('./AMP_AD_datasets/ROSMAP_Normalized_counts_(CQN).tsv', sep=\"\\t\", index_col=0).transpose()\n",
    "rnaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4278da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from a CSV file\n",
    "file_path = './metadata_v2_d_filtered.csv'  # Replace 'your_file_path.csv' with the path to your actual CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter the DataFrame\n",
    "metadata = df[(df['study'] == 'ROSMAP')]\n",
    "sample_ids = metadata['specimenID'].tolist()\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter genes\n",
    "rnaseq = rnaseq.loc[:, rnaseq.columns.isin(common_genes_list)]\n",
    "\n",
    "# Filter samples\n",
    "rnaseq = rnaseq.loc[rnaseq.index.isin(sample_ids), :]\n",
    "\n",
    "# Write filtered data to csv\n",
    "rnaseq.to_csv('./AMP_AD_datasets/ROSMAP_counts_v2.csv')\n",
    "rnaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bcc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./AMP_AD_datasets/ROSMAP_counts_v2.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58bbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faedb0e2",
   "metadata": {},
   "source": [
    "# Batch effect removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbd00e",
   "metadata": {},
   "source": [
    "## Checking batches in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bace19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from a CSV file\n",
    "file_path = './metadata_v2_d_filtered.csv'  # Replace 'your_file_path.csv' with the path to your actual CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter the DataFrame\n",
    "ROSMAP_df = df[(df['study'] == 'ROSMAP')]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "ROSMAP_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e469efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tissues_per_batch = ROSMAP_df.groupby('batch')['tissue'].unique()\n",
    "\n",
    "# Print the result\n",
    "print(unique_tissues_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998be6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e7ad473",
   "metadata": {},
   "source": [
    "## Visualization & Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a729ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as an\n",
    "from reComBat import reComBat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next one has less parameters\n",
    "def plot(data,metadata,type='tsne',plot_mode='all',name=None):\n",
    "    adata = an.AnnData(X=data,obs=metadata)\n",
    "\n",
    "\n",
    "    if plot_mode == 'all':\n",
    "        to_colour_by = ['diagnosis',\n",
    "                        'tissue',\n",
    "                        'apoe4_allele_numerical',\n",
    "                        'sex',\n",
    "                        'age_death_numerical',\n",
    "                        'final_batch'\n",
    "                        ]\n",
    "    else:\n",
    "        to_colour_by = [\n",
    "                        'Zero-hop cluster'\n",
    "                        ]\n",
    "\n",
    "    if type == 'tsne':\n",
    "        sc.tl.tsne(adata,use_rep='X')\n",
    "        if name is not None:\n",
    "            sc.pl.tsne(adata,color=to_colour_by,show=False,ncols=1,hspace=0.25,legend_fontsize=8,save='_'+name)\n",
    "        else:\n",
    "            sc.pl.tsne(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8)\n",
    "    elif type == 'umap':\n",
    "        sc.pp.neighbors(adata,use_rep='X')\n",
    "        sc.tl.umap(adata)\n",
    "        if name is not None:\n",
    "            sc.pl.umap(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8,save='_'+name)\n",
    "        else:\n",
    "            sc.pl.umap(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8)\n",
    "    elif type == 'pca':\n",
    "        sc.tl.pca(adata,use_highly_variable=False)\n",
    "        if name is not None:\n",
    "            sc.pl.pca(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8,save='_'+name)\n",
    "        else:\n",
    "            sc.pl.pca(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8046ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data,metadata,type='tsne',plot_mode='all',name=None):\n",
    "    adata = an.AnnData(X=data,obs=metadata)\n",
    "\n",
    "\n",
    "    if plot_mode == 'all':\n",
    "        to_colour_by = ['diagnosis',\n",
    "                        'tissue',\n",
    "                        'apoe4_allele_numerical',\n",
    "                        'sex',\n",
    "                        'final_batch'\n",
    "                        ]\n",
    "    else:\n",
    "        to_colour_by = [\n",
    "                        'Zero-hop cluster'\n",
    "                        ]\n",
    "\n",
    "    if type == 'tsne':\n",
    "        sc.tl.tsne(adata,use_rep='X')\n",
    "        if name is not None:\n",
    "            sc.pl.tsne(adata,color=to_colour_by,show=False,ncols=1,hspace=0.25,legend_fontsize=8,save='_'+name)\n",
    "        else:\n",
    "            sc.pl.tsne(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8)\n",
    "    elif type == 'umap':\n",
    "        sc.pp.neighbors(adata,use_rep='X')\n",
    "        sc.tl.umap(adata)\n",
    "        if name is not None:\n",
    "            sc.pl.umap(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8,save='_'+name)\n",
    "        else:\n",
    "            sc.pl.umap(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8)\n",
    "    elif type == 'pca':\n",
    "        sc.tl.pca(adata,use_highly_variable=False)\n",
    "        if name is not None:\n",
    "            sc.pl.pca(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8,save='_'+name)\n",
    "        else:\n",
    "            sc.pl.pca(adata,color=to_colour_by,show=True,ncols=1,hspace=0.25,legend_fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563443c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c398af0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000287978</th>\n",
       "      <th>ENSG00000287985</th>\n",
       "      <th>ENSG00000288011</th>\n",
       "      <th>ENSG00000288025</th>\n",
       "      <th>ENSG00000288033</th>\n",
       "      <th>ENSG00000288048</th>\n",
       "      <th>ENSG00000288049</th>\n",
       "      <th>ENSG00000288062</th>\n",
       "      <th>ENSG00000288075</th>\n",
       "      <th>ENSG00000288107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487_120515</th>\n",
       "      <td>2.764989</td>\n",
       "      <td>4.061551</td>\n",
       "      <td>3.554166</td>\n",
       "      <td>1.068802</td>\n",
       "      <td>2.929166</td>\n",
       "      <td>4.970807</td>\n",
       "      <td>2.706827</td>\n",
       "      <td>3.501699</td>\n",
       "      <td>3.281699</td>\n",
       "      <td>4.418461</td>\n",
       "      <td>...</td>\n",
       "      <td>3.191969</td>\n",
       "      <td>-1.378371</td>\n",
       "      <td>2.149665</td>\n",
       "      <td>2.086181</td>\n",
       "      <td>1.479524</td>\n",
       "      <td>1.495721</td>\n",
       "      <td>-0.791065</td>\n",
       "      <td>2.821804</td>\n",
       "      <td>3.738933</td>\n",
       "      <td>2.457909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182_120424</th>\n",
       "      <td>2.901827</td>\n",
       "      <td>4.298117</td>\n",
       "      <td>3.583453</td>\n",
       "      <td>0.835894</td>\n",
       "      <td>2.351920</td>\n",
       "      <td>2.412521</td>\n",
       "      <td>3.179636</td>\n",
       "      <td>4.781755</td>\n",
       "      <td>3.720931</td>\n",
       "      <td>4.586456</td>\n",
       "      <td>...</td>\n",
       "      <td>2.696077</td>\n",
       "      <td>-0.489106</td>\n",
       "      <td>2.203705</td>\n",
       "      <td>1.261326</td>\n",
       "      <td>1.124651</td>\n",
       "      <td>0.290829</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>3.595646</td>\n",
       "      <td>3.305149</td>\n",
       "      <td>2.220830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193_120424</th>\n",
       "      <td>3.002286</td>\n",
       "      <td>4.288366</td>\n",
       "      <td>3.964352</td>\n",
       "      <td>1.095810</td>\n",
       "      <td>2.575588</td>\n",
       "      <td>3.438342</td>\n",
       "      <td>3.297591</td>\n",
       "      <td>4.486892</td>\n",
       "      <td>3.478221</td>\n",
       "      <td>4.653638</td>\n",
       "      <td>...</td>\n",
       "      <td>2.245766</td>\n",
       "      <td>-0.877943</td>\n",
       "      <td>2.336529</td>\n",
       "      <td>1.467132</td>\n",
       "      <td>1.446733</td>\n",
       "      <td>-0.652423</td>\n",
       "      <td>-5.634499</td>\n",
       "      <td>3.176359</td>\n",
       "      <td>2.446567</td>\n",
       "      <td>1.556566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694_120605</th>\n",
       "      <td>3.968552</td>\n",
       "      <td>3.910733</td>\n",
       "      <td>3.322179</td>\n",
       "      <td>0.816828</td>\n",
       "      <td>4.210172</td>\n",
       "      <td>4.655648</td>\n",
       "      <td>3.717705</td>\n",
       "      <td>5.253858</td>\n",
       "      <td>3.950820</td>\n",
       "      <td>3.956390</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.472877</td>\n",
       "      <td>-2.302634</td>\n",
       "      <td>1.874555</td>\n",
       "      <td>0.886850</td>\n",
       "      <td>0.826430</td>\n",
       "      <td>1.456522</td>\n",
       "      <td>-0.688764</td>\n",
       "      <td>2.747393</td>\n",
       "      <td>2.812522</td>\n",
       "      <td>0.827998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366_120502</th>\n",
       "      <td>3.442133</td>\n",
       "      <td>4.036847</td>\n",
       "      <td>3.494517</td>\n",
       "      <td>1.544751</td>\n",
       "      <td>4.253015</td>\n",
       "      <td>4.281989</td>\n",
       "      <td>3.306333</td>\n",
       "      <td>4.997177</td>\n",
       "      <td>3.734629</td>\n",
       "      <td>4.460500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.982265</td>\n",
       "      <td>-0.300853</td>\n",
       "      <td>1.959814</td>\n",
       "      <td>1.294352</td>\n",
       "      <td>1.715126</td>\n",
       "      <td>0.327011</td>\n",
       "      <td>-5.439004</td>\n",
       "      <td>3.287655</td>\n",
       "      <td>2.981390</td>\n",
       "      <td>1.578917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_81</th>\n",
       "      <td>3.616346</td>\n",
       "      <td>4.939349</td>\n",
       "      <td>4.331040</td>\n",
       "      <td>3.260085</td>\n",
       "      <td>2.251728</td>\n",
       "      <td>6.362204</td>\n",
       "      <td>3.427606</td>\n",
       "      <td>5.227210</td>\n",
       "      <td>5.367607</td>\n",
       "      <td>4.027927</td>\n",
       "      <td>...</td>\n",
       "      <td>2.376233</td>\n",
       "      <td>2.036649</td>\n",
       "      <td>2.804139</td>\n",
       "      <td>4.213553</td>\n",
       "      <td>0.665665</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>-3.681164</td>\n",
       "      <td>3.853500</td>\n",
       "      <td>4.113843</td>\n",
       "      <td>3.184639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_9_rerun</th>\n",
       "      <td>3.141163</td>\n",
       "      <td>3.376257</td>\n",
       "      <td>3.830212</td>\n",
       "      <td>2.921539</td>\n",
       "      <td>2.652769</td>\n",
       "      <td>4.109077</td>\n",
       "      <td>2.956279</td>\n",
       "      <td>5.514726</td>\n",
       "      <td>5.382944</td>\n",
       "      <td>3.936892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516212</td>\n",
       "      <td>0.970051</td>\n",
       "      <td>1.802014</td>\n",
       "      <td>3.715537</td>\n",
       "      <td>1.292183</td>\n",
       "      <td>1.879587</td>\n",
       "      <td>-4.816121</td>\n",
       "      <td>1.828070</td>\n",
       "      <td>4.521649</td>\n",
       "      <td>1.165025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_93</th>\n",
       "      <td>4.414114</td>\n",
       "      <td>4.879912</td>\n",
       "      <td>5.067875</td>\n",
       "      <td>3.478595</td>\n",
       "      <td>1.533871</td>\n",
       "      <td>4.710924</td>\n",
       "      <td>3.912469</td>\n",
       "      <td>6.012846</td>\n",
       "      <td>5.264565</td>\n",
       "      <td>3.798947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.907891</td>\n",
       "      <td>2.648342</td>\n",
       "      <td>3.820658</td>\n",
       "      <td>3.822753</td>\n",
       "      <td>-0.538331</td>\n",
       "      <td>1.359241</td>\n",
       "      <td>-2.336540</td>\n",
       "      <td>4.112797</td>\n",
       "      <td>4.357865</td>\n",
       "      <td>2.395877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_94</th>\n",
       "      <td>4.234132</td>\n",
       "      <td>4.809306</td>\n",
       "      <td>4.897595</td>\n",
       "      <td>3.520087</td>\n",
       "      <td>1.262454</td>\n",
       "      <td>4.577437</td>\n",
       "      <td>3.890817</td>\n",
       "      <td>5.983485</td>\n",
       "      <td>5.230406</td>\n",
       "      <td>4.193936</td>\n",
       "      <td>...</td>\n",
       "      <td>1.458429</td>\n",
       "      <td>2.206137</td>\n",
       "      <td>3.435656</td>\n",
       "      <td>3.959864</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>1.580673</td>\n",
       "      <td>-4.106154</td>\n",
       "      <td>3.441018</td>\n",
       "      <td>4.191228</td>\n",
       "      <td>1.391244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_97</th>\n",
       "      <td>3.962652</td>\n",
       "      <td>4.929144</td>\n",
       "      <td>4.861973</td>\n",
       "      <td>3.139919</td>\n",
       "      <td>1.792775</td>\n",
       "      <td>5.094976</td>\n",
       "      <td>3.834445</td>\n",
       "      <td>5.793358</td>\n",
       "      <td>5.067875</td>\n",
       "      <td>4.162785</td>\n",
       "      <td>...</td>\n",
       "      <td>2.583273</td>\n",
       "      <td>2.958046</td>\n",
       "      <td>3.283264</td>\n",
       "      <td>3.463398</td>\n",
       "      <td>0.547452</td>\n",
       "      <td>1.382132</td>\n",
       "      <td>-1.186112</td>\n",
       "      <td>3.823107</td>\n",
       "      <td>3.765085</td>\n",
       "      <td>3.385557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>952 rows  17002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ENSG00000000003  ENSG00000000419  ENSG00000000457  \\\n",
       "487_120515           2.764989         4.061551         3.554166   \n",
       "182_120424           2.901827         4.298117         3.583453   \n",
       "193_120424           3.002286         4.288366         3.964352   \n",
       "694_120605           3.968552         3.910733         3.322179   \n",
       "366_120502           3.442133         4.036847         3.494517   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              3.616346         4.939349         4.331040   \n",
       "RISK_9_rerun         3.141163         3.376257         3.830212   \n",
       "RISK_93              4.414114         4.879912         5.067875   \n",
       "RISK_94              4.234132         4.809306         4.897595   \n",
       "RISK_97              3.962652         4.929144         4.861973   \n",
       "\n",
       "              ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "487_120515           1.068802         2.929166         4.970807   \n",
       "182_120424           0.835894         2.351920         2.412521   \n",
       "193_120424           1.095810         2.575588         3.438342   \n",
       "694_120605           0.816828         4.210172         4.655648   \n",
       "366_120502           1.544751         4.253015         4.281989   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              3.260085         2.251728         6.362204   \n",
       "RISK_9_rerun         2.921539         2.652769         4.109077   \n",
       "RISK_93              3.478595         1.533871         4.710924   \n",
       "RISK_94              3.520087         1.262454         4.577437   \n",
       "RISK_97              3.139919         1.792775         5.094976   \n",
       "\n",
       "              ENSG00000001036  ENSG00000001084  ENSG00000001167  \\\n",
       "487_120515           2.706827         3.501699         3.281699   \n",
       "182_120424           3.179636         4.781755         3.720931   \n",
       "193_120424           3.297591         4.486892         3.478221   \n",
       "694_120605           3.717705         5.253858         3.950820   \n",
       "366_120502           3.306333         4.997177         3.734629   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              3.427606         5.227210         5.367607   \n",
       "RISK_9_rerun         2.956279         5.514726         5.382944   \n",
       "RISK_93              3.912469         6.012846         5.264565   \n",
       "RISK_94              3.890817         5.983485         5.230406   \n",
       "RISK_97              3.834445         5.793358         5.067875   \n",
       "\n",
       "              ENSG00000001460  ...  ENSG00000287978  ENSG00000287985  \\\n",
       "487_120515           4.418461  ...         3.191969        -1.378371   \n",
       "182_120424           4.586456  ...         2.696077        -0.489106   \n",
       "193_120424           4.653638  ...         2.245766        -0.877943   \n",
       "694_120605           3.956390  ...        -3.472877        -2.302634   \n",
       "366_120502           4.460500  ...         2.982265        -0.300853   \n",
       "...                       ...  ...              ...              ...   \n",
       "RISK_81              4.027927  ...         2.376233         2.036649   \n",
       "RISK_9_rerun         3.936892  ...         0.516212         0.970051   \n",
       "RISK_93              3.798947  ...         1.907891         2.648342   \n",
       "RISK_94              4.193936  ...         1.458429         2.206137   \n",
       "RISK_97              4.162785  ...         2.583273         2.958046   \n",
       "\n",
       "              ENSG00000288011  ENSG00000288025  ENSG00000288033  \\\n",
       "487_120515           2.149665         2.086181         1.479524   \n",
       "182_120424           2.203705         1.261326         1.124651   \n",
       "193_120424           2.336529         1.467132         1.446733   \n",
       "694_120605           1.874555         0.886850         0.826430   \n",
       "366_120502           1.959814         1.294352         1.715126   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              2.804139         4.213553         0.665665   \n",
       "RISK_9_rerun         1.802014         3.715537         1.292183   \n",
       "RISK_93              3.820658         3.822753        -0.538331   \n",
       "RISK_94              3.435656         3.959864         0.782715   \n",
       "RISK_97              3.283264         3.463398         0.547452   \n",
       "\n",
       "              ENSG00000288048  ENSG00000288049  ENSG00000288062  \\\n",
       "487_120515           1.495721        -0.791065         2.821804   \n",
       "182_120424           0.290829         0.242340         3.595646   \n",
       "193_120424          -0.652423        -5.634499         3.176359   \n",
       "694_120605           1.456522        -0.688764         2.747393   \n",
       "366_120502           0.327011        -5.439004         3.287655   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              0.064638        -3.681164         3.853500   \n",
       "RISK_9_rerun         1.879587        -4.816121         1.828070   \n",
       "RISK_93              1.359241        -2.336540         4.112797   \n",
       "RISK_94              1.580673        -4.106154         3.441018   \n",
       "RISK_97              1.382132        -1.186112         3.823107   \n",
       "\n",
       "              ENSG00000288075  ENSG00000288107  \n",
       "487_120515           3.738933         2.457909  \n",
       "182_120424           3.305149         2.220830  \n",
       "193_120424           2.446567         1.556566  \n",
       "694_120605           2.812522         0.827998  \n",
       "366_120502           2.981390         1.578917  \n",
       "...                       ...              ...  \n",
       "RISK_81              4.113843         3.184639  \n",
       "RISK_9_rerun         4.521649         1.165025  \n",
       "RISK_93              4.357865         2.395877  \n",
       "RISK_94              4.191228         1.391244  \n",
       "RISK_97              3.765085         3.385557  \n",
       "\n",
       "[952 rows x 17002 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/vmottaqi/rnaseq_synapse/AMP_AD_datasets/ROSMAP_counts_v2.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('metadata_v2_d_filtered.csv', index_col='specimenID')\n",
    "metadata = df[(df['study'] == 'ROSMAP')]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f368f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.rename(columns={'age_death': 'age_death_numerical',\n",
    "                         'pmi':'pmi_numerical',\n",
    "                         'batch':'final_batch', 'RIN2':'RIN2_numerical',\n",
    "                         'RnaSeqMetrics_PCT_INTERGENIC_BASES':'RnaSeqMetrics_PCT_INTERGENIC_BASES_numerical',\n",
    "                         'RnaSeqMetrics_PCT_CODING_BASES':'RnaSeqMetrics_PCT_CODING_BASES_numerical'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1218f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53983a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.final_batch = metadata.final_batch.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36372aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_coarse  = metadata[['final_batch',\n",
    "                             'diagnosis',\n",
    "                             'tissue',\n",
    "                             'apoe4_allele',\n",
    "                             'sex',\n",
    "                             'pmi_numerical',\n",
    "                             'age_death_numerical', 'RIN2_numerical',\n",
    "                             'RnaSeqMetrics_PCT_INTERGENIC_BASES_numerical',\n",
    "                             'RnaSeqMetrics_PCT_CODING_BASES_numerical']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fddfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fit = metadata_coarse.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2de948",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7396c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Not needed\n",
    "valid_ids = list(set(data.index).intersection(set(metadata_coarse.index)))\n",
    "valid_ids.sort()\n",
    "data_fit = data.loc[valid_ids]\n",
    "metadata_fit = metadata_coarse.loc[valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6cbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(data_fit.index == metadata_fit.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fit = data_fit.reset_index(drop=True)\n",
    "data_fit\n",
    "data_fit.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b876c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eec402",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['diagnosis', 'tissue', 'apoe4_allele', 'sex']  # Replace these with your actual variable names\n",
    "\n",
    "# Convert each variable in the list to categorical\n",
    "for variable in categorical_variables:\n",
    "    metadata_fit[variable] = metadata_fit[variable].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a batch problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319abd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_counts = metadata_fit['final_batch'].value_counts()\n",
    "print(batch_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_counts = metadata_fit['final_batch'].value_counts()\n",
    "single_sample_batches = batch_counts[batch_counts == 1].index\n",
    "\n",
    "# Display the index of the samples belonging to batches with only one sample\n",
    "single_sample_indices = metadata_fit[metadata_fit['final_batch'].isin(single_sample_batches)].index\n",
    "print(\"Indices of single-sample batches:\", single_sample_indices)\n",
    "\n",
    "# Remove these samples from both metadata and dataset\n",
    "metadata_fit = metadata_fit[~metadata_fit['final_batch'].isin(single_sample_batches)]\n",
    "data_fit = data_fit.drop(index=single_sample_indices)\n",
    "\n",
    "# Verify removal - This will display the new count of samples per batch, excluding those with originally one sample\n",
    "print(metadata_fit['final_batch'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb519dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_fit,metadata_fit,type='umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09328b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reComBat(parametric=False,            # use parametric or non-parametric empirical Bayes method. \n",
    "                                             # The parametric method is significantly faster, whereas the \n",
    "                                             # non-parametric method is more flexible.\n",
    "                 model='ridge',              # The regression model to be used. \n",
    "                                             # In our experience pure ridge regression performs best for singular design matrices \n",
    "                                             # and pure linear regression is best for non=singular matrices.\n",
    "                 config={'alpha':1e-9},      # Optional arguments for the regression model. \n",
    "                                             # We tend to use a tiny regularisation parameter. \n",
    "                                             # This has also been cnfirmed by CV.\n",
    "                 conv_criterion=1e-4,        # The convergence criterion for the empirical Bayes optimisation.\n",
    "                                             # This value works well in practise.\n",
    "                 max_iter=1000,              # The maximum number of iterations to stop if convergence is not reached.\n",
    "                                             # This may also be useful for smaller convergence criteria.\n",
    "                 n_jobs=8,                   # This parameter is only useful in non-parametric optimisation.\n",
    "                                             # The non-parametric optimisation is very slow, but can be parallelised easily.\n",
    "                                             # Set this to the number of CPUs on your machine for significant speed ups.\n",
    "                 mean_only=False,            # Adjust the mean of your data only (not the variance).\n",
    "                                             # This can be useful for single sample batches (where the variance is infinite)\n",
    "                 optimize_params=True,       # If False no empirical Bayes optimisation is performed.\n",
    "                 reference_batch=None,       # If a reference batch is present (e.g. a batch which is considered \"batch effect free\")\n",
    "                                             # it can be set such that all data is adjuste dwith respect to this reference batch.\n",
    "                 verbose=True                # Turn log messages on or off\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_fit,metadata_fit.final_batch,X=metadata_fit.drop(['final_batch'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combat = model.transform(data_fit,metadata_fit.final_batch,X=metadata_fit.drop(['final_batch'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09df8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f599d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combat.to_csv(\"./AMP_AD_datasets/ROSMAP_counts1_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97620981",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"./AMP_AD_datasets/ROSMAP_counts1_v3.csv\", index_col=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db54682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of NaNs in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bee9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL check\n",
    "num_nans = data_combat.isna().sum().sum()\n",
    "\n",
    "print(f\"Number of NaNs in the DataFrame: {num_nans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts_per_row = data_combat.isna().sum(axis=0)\n",
    "\n",
    "# Print the row index and number of NaNs for rows with at least one NaN\n",
    "for index, nan_count in nan_counts_per_row[nan_counts_per_row > 0].items():\n",
    "    print(f\"Col index: {index}, Number of NaNs: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cff5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['ENSG00000210082', 'ENSG00000211459']\n",
    "\n",
    "# Remove the specified columns from the DataFrame\n",
    "data_combat = data_combat.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_combat,metadata_fit,type='umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a65d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ed9f8fc",
   "metadata": {},
   "source": [
    "## Metadata modfiying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c07df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = './AMP_AD_datasets/ROSMAP_counts1_v3.csv'\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['ENSG00000210082', 'ENSG00000211459', 'ENSG00000198886']  # Update this list with the actual column names you want to remove\n",
    "\n",
    "# Remove the specified columns if they exist\n",
    "for column in columns_to_remove:\n",
    "    if column in df.columns:\n",
    "        df.drop(columns=[column], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "new_file_path = './AMP_AD_datasets/ROSMAP_counts1_v4.csv'\n",
    "df.to_csv(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eaf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = 'metadata_v2_d_filtered.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove rows where the 'specimenID' column has the value '492_120515'\n",
    "df = df[df['specimenID'] != '492_120515']\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "new_file_path = './metadata_v3.csv'\n",
    "df.to_csv(new_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68e113",
   "metadata": {},
   "source": [
    "# Create figures as final for talk (UMAP & tSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe85dc",
   "metadata": {},
   "source": [
    "#### UMAP and tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8082a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "import seaborn as sns\n",
    "\n",
    "def plot(data, metadata, plot_type='umap', name=None):\n",
    "    # Prepare data\n",
    "    features = data.values\n",
    "    labels = metadata['batch'].astype('category').cat.codes  # Convert to categorical codes for coloring\n",
    "    \n",
    "    # Initialize and fit the reducer\n",
    "    if plot_type == 'umap':\n",
    "        reducer = UMAP(random_state=42)\n",
    "        embedding = reducer.fit_transform(features)\n",
    "        title = 'UMAP'\n",
    "    elif plot_type == 'tsne':\n",
    "        reducer = TSNE(n_components=2, random_state=42)\n",
    "        embedding = reducer.fit_transform(features)\n",
    "        title = 't-SNE'\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    scatter = sns.scatterplot(x=embedding[:, 0], y=embedding[:, 1], hue=metadata['batch'], palette='husl', legend='full', s=60)\n",
    "    plt.title(f'{title} {name}')\n",
    "    plt.legend(title='Batch', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xlabel(f'{title}-1')\n",
    "    plt.ylabel(f'{title}-2')\n",
    "    \n",
    "    # Save the plot if a name is provided\n",
    "    if name:\n",
    "        plt.savefig(f\"{name}_{plot_type.lower()}.png\", dpi=900, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459d71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d8ad1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d265f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets and metadata\n",
    "df = pd.read_csv('backup/metadata_v2_d_filtered.csv', index_col='specimenID')\n",
    "metadata_before = df[(df['study'] == 'ROSMAP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059c4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('backup/metadata_v3.csv', index_col='specimenID')\n",
    "metadata_before = df[(df['study'] == 'ROSMAP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112996f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individualID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>tissue</th>\n",
       "      <th>race</th>\n",
       "      <th>spanish</th>\n",
       "      <th>apoe4_allele</th>\n",
       "      <th>sex</th>\n",
       "      <th>batch</th>\n",
       "      <th>pmi</th>\n",
       "      <th>RIN</th>\n",
       "      <th>RIN2</th>\n",
       "      <th>age_death</th>\n",
       "      <th>AlignmentSummaryMetrics_PCT_PF_READS_ALIGNED</th>\n",
       "      <th>RnaSeqMetrics_PCT_INTRONIC_BASES</th>\n",
       "      <th>RnaSeqMetrics_PCT_INTERGENIC_BASES</th>\n",
       "      <th>RnaSeqMetrics_PCT_CODING_BASES</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>study</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specimenID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487_120515</th>\n",
       "      <td>R9904978</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.433333</td>\n",
       "      <td>6.9</td>\n",
       "      <td>47.61</td>\n",
       "      <td>72.720055</td>\n",
       "      <td>0.931411</td>\n",
       "      <td>0.225013</td>\n",
       "      <td>0.058488</td>\n",
       "      <td>0.342722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182_120424</th>\n",
       "      <td>R9818080</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>70.56</td>\n",
       "      <td>81.111567</td>\n",
       "      <td>0.944450</td>\n",
       "      <td>0.172408</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>0.394201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193_120424</th>\n",
       "      <td>R9817161</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>7.1</td>\n",
       "      <td>50.41</td>\n",
       "      <td>80.906229</td>\n",
       "      <td>0.958718</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>0.048166</td>\n",
       "      <td>0.357855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694_120605</th>\n",
       "      <td>R9817056</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>7.1</td>\n",
       "      <td>50.41</td>\n",
       "      <td>87.753593</td>\n",
       "      <td>0.960609</td>\n",
       "      <td>0.201002</td>\n",
       "      <td>0.045065</td>\n",
       "      <td>0.397276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366_120502</th>\n",
       "      <td>R9809661</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>7.4</td>\n",
       "      <td>54.76</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.931962</td>\n",
       "      <td>0.205742</td>\n",
       "      <td>0.048650</td>\n",
       "      <td>0.378299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_81</th>\n",
       "      <td>R4703595</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>7.3</td>\n",
       "      <td>53.29</td>\n",
       "      <td>88.796715</td>\n",
       "      <td>0.980628</td>\n",
       "      <td>0.434482</td>\n",
       "      <td>0.059079</td>\n",
       "      <td>0.220906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_9_rerun</th>\n",
       "      <td>R6776130</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.89</td>\n",
       "      <td>83.958932</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.460919</td>\n",
       "      <td>0.119986</td>\n",
       "      <td>0.179597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_93</th>\n",
       "      <td>R6162454</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>7.2</td>\n",
       "      <td>51.84</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.949833</td>\n",
       "      <td>0.420760</td>\n",
       "      <td>0.047032</td>\n",
       "      <td>0.237576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_94</th>\n",
       "      <td>R6162454</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>6.8</td>\n",
       "      <td>46.24</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.958425</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.055424</td>\n",
       "      <td>0.223222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_97</th>\n",
       "      <td>R1787342</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6.283333</td>\n",
       "      <td>6.3</td>\n",
       "      <td>39.69</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.964837</td>\n",
       "      <td>0.401705</td>\n",
       "      <td>0.052819</td>\n",
       "      <td>0.252883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSMAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             individualID  diagnosis  tissue  race  spanish  apoe4_allele  \\\n",
       "specimenID                                                                  \n",
       "487_120515       R9904978          0       3   1.0      2.0             0   \n",
       "182_120424       R9818080          0       3   1.0      2.0             0   \n",
       "193_120424       R9817161          1       3   1.0      2.0             0   \n",
       "694_120605       R9817056          0       3   1.0      2.0             0   \n",
       "366_120502       R9809661          1       3   1.0      2.0             1   \n",
       "...                   ...        ...     ...   ...      ...           ...   \n",
       "RISK_81          R4703595          0       3   1.0      2.0             0   \n",
       "RISK_9_rerun     R6776130          0       3   1.0      2.0             0   \n",
       "RISK_93          R6162454          1       3   1.0      2.0             0   \n",
       "RISK_94          R6162454          1       6   1.0      2.0             0   \n",
       "RISK_97          R1787342          0       3   1.0      2.0             0   \n",
       "\n",
       "              sex  batch        pmi  RIN   RIN2  age_death  \\\n",
       "specimenID                                                   \n",
       "487_120515      0      4  12.433333  6.9  47.61  72.720055   \n",
       "182_120424      0      7  16.000000  8.4  70.56  81.111567   \n",
       "193_120424      1      4   1.750000  7.1  50.41  80.906229   \n",
       "694_120605      0      4   6.416667  7.1  50.41  87.753593   \n",
       "366_120502      1      7  17.416667  7.4  54.76  90.000000   \n",
       "...           ...    ...        ...  ...    ...        ...   \n",
       "RISK_81         1     17  19.500000  7.3  53.29  88.796715   \n",
       "RISK_9_rerun    1     17   6.500000  1.7   2.89  83.958932   \n",
       "RISK_93         1     17   6.033333  7.2  51.84  90.000000   \n",
       "RISK_94         1     17   6.033333  6.8  46.24  90.000000   \n",
       "RISK_97         1     17   6.283333  6.3  39.69  90.000000   \n",
       "\n",
       "              AlignmentSummaryMetrics_PCT_PF_READS_ALIGNED  \\\n",
       "specimenID                                                   \n",
       "487_120515                                        0.931411   \n",
       "182_120424                                        0.944450   \n",
       "193_120424                                        0.958718   \n",
       "694_120605                                        0.960609   \n",
       "366_120502                                        0.931962   \n",
       "...                                                    ...   \n",
       "RISK_81                                           0.980628   \n",
       "RISK_9_rerun                                      0.932115   \n",
       "RISK_93                                           0.949833   \n",
       "RISK_94                                           0.958425   \n",
       "RISK_97                                           0.964837   \n",
       "\n",
       "              RnaSeqMetrics_PCT_INTRONIC_BASES  \\\n",
       "specimenID                                       \n",
       "487_120515                            0.225013   \n",
       "182_120424                            0.172408   \n",
       "193_120424                            0.203963   \n",
       "694_120605                            0.201002   \n",
       "366_120502                            0.205742   \n",
       "...                                        ...   \n",
       "RISK_81                               0.434482   \n",
       "RISK_9_rerun                          0.460919   \n",
       "RISK_93                               0.420760   \n",
       "RISK_94                               0.461341   \n",
       "RISK_97                               0.401705   \n",
       "\n",
       "              RnaSeqMetrics_PCT_INTERGENIC_BASES  \\\n",
       "specimenID                                         \n",
       "487_120515                              0.058488   \n",
       "182_120424                              0.041036   \n",
       "193_120424                              0.048166   \n",
       "694_120605                              0.045065   \n",
       "366_120502                              0.048650   \n",
       "...                                          ...   \n",
       "RISK_81                                 0.059079   \n",
       "RISK_9_rerun                            0.119986   \n",
       "RISK_93                                 0.047032   \n",
       "RISK_94                                 0.055424   \n",
       "RISK_97                                 0.052819   \n",
       "\n",
       "              RnaSeqMetrics_PCT_CODING_BASES ethnicity   study  \n",
       "specimenID                                                      \n",
       "487_120515                          0.342722       NaN  ROSMAP  \n",
       "182_120424                          0.394201       NaN  ROSMAP  \n",
       "193_120424                          0.357855       NaN  ROSMAP  \n",
       "694_120605                          0.397276       NaN  ROSMAP  \n",
       "366_120502                          0.378299       NaN  ROSMAP  \n",
       "...                                      ...       ...     ...  \n",
       "RISK_81                             0.220906       NaN  ROSMAP  \n",
       "RISK_9_rerun                        0.179597       NaN  ROSMAP  \n",
       "RISK_93                             0.237576       NaN  ROSMAP  \n",
       "RISK_94                             0.223222       NaN  ROSMAP  \n",
       "RISK_97                             0.252883       NaN  ROSMAP  \n",
       "\n",
       "[951 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2faec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17eb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is after batch correction\n",
    "data_before = pd.read_csv('AMP_AD_datasets/ROSMAP_counts1_v4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59fb067e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000287978</th>\n",
       "      <th>ENSG00000287985</th>\n",
       "      <th>ENSG00000288011</th>\n",
       "      <th>ENSG00000288025</th>\n",
       "      <th>ENSG00000288033</th>\n",
       "      <th>ENSG00000288048</th>\n",
       "      <th>ENSG00000288049</th>\n",
       "      <th>ENSG00000288062</th>\n",
       "      <th>ENSG00000288075</th>\n",
       "      <th>ENSG00000288107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487_120515</th>\n",
       "      <td>2.810547</td>\n",
       "      <td>4.148122</td>\n",
       "      <td>3.874218</td>\n",
       "      <td>1.799121</td>\n",
       "      <td>2.092121</td>\n",
       "      <td>5.002842</td>\n",
       "      <td>2.649805</td>\n",
       "      <td>4.190346</td>\n",
       "      <td>4.136761</td>\n",
       "      <td>4.312964</td>\n",
       "      <td>...</td>\n",
       "      <td>2.244224</td>\n",
       "      <td>0.946858</td>\n",
       "      <td>1.712583</td>\n",
       "      <td>2.383336</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>1.532749</td>\n",
       "      <td>-0.533156</td>\n",
       "      <td>3.458250</td>\n",
       "      <td>4.136794</td>\n",
       "      <td>2.612982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182_120424</th>\n",
       "      <td>3.072559</td>\n",
       "      <td>4.348032</td>\n",
       "      <td>3.915100</td>\n",
       "      <td>1.540571</td>\n",
       "      <td>1.550940</td>\n",
       "      <td>2.956883</td>\n",
       "      <td>3.285399</td>\n",
       "      <td>5.331494</td>\n",
       "      <td>4.567047</td>\n",
       "      <td>4.383134</td>\n",
       "      <td>...</td>\n",
       "      <td>1.688370</td>\n",
       "      <td>1.601382</td>\n",
       "      <td>1.881198</td>\n",
       "      <td>1.878234</td>\n",
       "      <td>-0.342688</td>\n",
       "      <td>0.448150</td>\n",
       "      <td>0.563890</td>\n",
       "      <td>4.036977</td>\n",
       "      <td>3.648011</td>\n",
       "      <td>2.219072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193_120424</th>\n",
       "      <td>3.048206</td>\n",
       "      <td>4.433027</td>\n",
       "      <td>4.399047</td>\n",
       "      <td>1.828867</td>\n",
       "      <td>1.722782</td>\n",
       "      <td>3.527224</td>\n",
       "      <td>3.380979</td>\n",
       "      <td>5.063308</td>\n",
       "      <td>4.345387</td>\n",
       "      <td>4.671514</td>\n",
       "      <td>...</td>\n",
       "      <td>1.824380</td>\n",
       "      <td>1.468307</td>\n",
       "      <td>2.007384</td>\n",
       "      <td>1.672998</td>\n",
       "      <td>-0.085115</td>\n",
       "      <td>-0.581725</td>\n",
       "      <td>-5.248091</td>\n",
       "      <td>3.881210</td>\n",
       "      <td>2.879113</td>\n",
       "      <td>1.575236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694_120605</th>\n",
       "      <td>4.055124</td>\n",
       "      <td>3.964488</td>\n",
       "      <td>3.567052</td>\n",
       "      <td>1.555186</td>\n",
       "      <td>3.398263</td>\n",
       "      <td>4.715326</td>\n",
       "      <td>3.863657</td>\n",
       "      <td>5.749745</td>\n",
       "      <td>4.878878</td>\n",
       "      <td>3.719107</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.782687</td>\n",
       "      <td>-0.010839</td>\n",
       "      <td>1.409716</td>\n",
       "      <td>1.075076</td>\n",
       "      <td>-0.674845</td>\n",
       "      <td>1.494947</td>\n",
       "      <td>-0.380824</td>\n",
       "      <td>3.377167</td>\n",
       "      <td>3.231484</td>\n",
       "      <td>0.722272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366_120502</th>\n",
       "      <td>3.668267</td>\n",
       "      <td>4.101272</td>\n",
       "      <td>3.836283</td>\n",
       "      <td>2.226500</td>\n",
       "      <td>3.744153</td>\n",
       "      <td>4.861074</td>\n",
       "      <td>3.422126</td>\n",
       "      <td>5.559446</td>\n",
       "      <td>4.566165</td>\n",
       "      <td>4.274035</td>\n",
       "      <td>...</td>\n",
       "      <td>2.009806</td>\n",
       "      <td>1.761749</td>\n",
       "      <td>1.675437</td>\n",
       "      <td>1.846511</td>\n",
       "      <td>0.172702</td>\n",
       "      <td>0.484624</td>\n",
       "      <td>-5.139369</td>\n",
       "      <td>3.740314</td>\n",
       "      <td>3.348135</td>\n",
       "      <td>1.401988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_81</th>\n",
       "      <td>3.071534</td>\n",
       "      <td>4.370200</td>\n",
       "      <td>3.751393</td>\n",
       "      <td>2.303922</td>\n",
       "      <td>2.713576</td>\n",
       "      <td>5.257081</td>\n",
       "      <td>3.073116</td>\n",
       "      <td>4.634543</td>\n",
       "      <td>4.281490</td>\n",
       "      <td>4.083849</td>\n",
       "      <td>...</td>\n",
       "      <td>1.784520</td>\n",
       "      <td>0.312004</td>\n",
       "      <td>1.968610</td>\n",
       "      <td>3.432143</td>\n",
       "      <td>1.744969</td>\n",
       "      <td>-0.881486</td>\n",
       "      <td>-4.839170</td>\n",
       "      <td>3.770227</td>\n",
       "      <td>3.824714</td>\n",
       "      <td>2.717601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_9_rerun</th>\n",
       "      <td>2.602653</td>\n",
       "      <td>3.114323</td>\n",
       "      <td>3.258719</td>\n",
       "      <td>1.935287</td>\n",
       "      <td>3.190918</td>\n",
       "      <td>3.444899</td>\n",
       "      <td>2.681341</td>\n",
       "      <td>4.889645</td>\n",
       "      <td>4.354689</td>\n",
       "      <td>3.930179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511380</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>0.972381</td>\n",
       "      <td>2.849720</td>\n",
       "      <td>2.417253</td>\n",
       "      <td>1.029323</td>\n",
       "      <td>-5.697212</td>\n",
       "      <td>1.730592</td>\n",
       "      <td>4.241378</td>\n",
       "      <td>0.970021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_93</th>\n",
       "      <td>3.860583</td>\n",
       "      <td>4.285095</td>\n",
       "      <td>4.334896</td>\n",
       "      <td>2.533047</td>\n",
       "      <td>2.112452</td>\n",
       "      <td>3.869989</td>\n",
       "      <td>3.460004</td>\n",
       "      <td>5.345419</td>\n",
       "      <td>4.224580</td>\n",
       "      <td>3.864694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060206</td>\n",
       "      <td>0.815049</td>\n",
       "      <td>2.683152</td>\n",
       "      <td>3.002727</td>\n",
       "      <td>0.631767</td>\n",
       "      <td>0.502251</td>\n",
       "      <td>-3.785618</td>\n",
       "      <td>4.037104</td>\n",
       "      <td>4.083396</td>\n",
       "      <td>2.015397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_94</th>\n",
       "      <td>3.683321</td>\n",
       "      <td>4.180770</td>\n",
       "      <td>4.178936</td>\n",
       "      <td>2.583869</td>\n",
       "      <td>1.893575</td>\n",
       "      <td>3.806877</td>\n",
       "      <td>3.441687</td>\n",
       "      <td>5.312824</td>\n",
       "      <td>4.209908</td>\n",
       "      <td>4.203680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487801</td>\n",
       "      <td>0.404469</td>\n",
       "      <td>2.326239</td>\n",
       "      <td>3.136790</td>\n",
       "      <td>1.882202</td>\n",
       "      <td>0.738802</td>\n",
       "      <td>-5.144972</td>\n",
       "      <td>3.357130</td>\n",
       "      <td>3.906274</td>\n",
       "      <td>1.144429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_97</th>\n",
       "      <td>3.415151</td>\n",
       "      <td>4.302146</td>\n",
       "      <td>4.155775</td>\n",
       "      <td>2.172324</td>\n",
       "      <td>2.357716</td>\n",
       "      <td>4.245688</td>\n",
       "      <td>3.409077</td>\n",
       "      <td>5.148801</td>\n",
       "      <td>4.067227</td>\n",
       "      <td>4.173281</td>\n",
       "      <td>...</td>\n",
       "      <td>2.081118</td>\n",
       "      <td>1.031673</td>\n",
       "      <td>2.258343</td>\n",
       "      <td>2.627448</td>\n",
       "      <td>1.634748</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>-2.886333</td>\n",
       "      <td>3.745269</td>\n",
       "      <td>3.466199</td>\n",
       "      <td>2.843279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows  16999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ENSG00000000003  ENSG00000000419  ENSG00000000457  \\\n",
       "487_120515           2.810547         4.148122         3.874218   \n",
       "182_120424           3.072559         4.348032         3.915100   \n",
       "193_120424           3.048206         4.433027         4.399047   \n",
       "694_120605           4.055124         3.964488         3.567052   \n",
       "366_120502           3.668267         4.101272         3.836283   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              3.071534         4.370200         3.751393   \n",
       "RISK_9_rerun         2.602653         3.114323         3.258719   \n",
       "RISK_93              3.860583         4.285095         4.334896   \n",
       "RISK_94              3.683321         4.180770         4.178936   \n",
       "RISK_97              3.415151         4.302146         4.155775   \n",
       "\n",
       "              ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "487_120515           1.799121         2.092121         5.002842   \n",
       "182_120424           1.540571         1.550940         2.956883   \n",
       "193_120424           1.828867         1.722782         3.527224   \n",
       "694_120605           1.555186         3.398263         4.715326   \n",
       "366_120502           2.226500         3.744153         4.861074   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              2.303922         2.713576         5.257081   \n",
       "RISK_9_rerun         1.935287         3.190918         3.444899   \n",
       "RISK_93              2.533047         2.112452         3.869989   \n",
       "RISK_94              2.583869         1.893575         3.806877   \n",
       "RISK_97              2.172324         2.357716         4.245688   \n",
       "\n",
       "              ENSG00000001036  ENSG00000001084  ENSG00000001167  \\\n",
       "487_120515           2.649805         4.190346         4.136761   \n",
       "182_120424           3.285399         5.331494         4.567047   \n",
       "193_120424           3.380979         5.063308         4.345387   \n",
       "694_120605           3.863657         5.749745         4.878878   \n",
       "366_120502           3.422126         5.559446         4.566165   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              3.073116         4.634543         4.281490   \n",
       "RISK_9_rerun         2.681341         4.889645         4.354689   \n",
       "RISK_93              3.460004         5.345419         4.224580   \n",
       "RISK_94              3.441687         5.312824         4.209908   \n",
       "RISK_97              3.409077         5.148801         4.067227   \n",
       "\n",
       "              ENSG00000001460  ...  ENSG00000287978  ENSG00000287985  \\\n",
       "487_120515           4.312964  ...         2.244224         0.946858   \n",
       "182_120424           4.383134  ...         1.688370         1.601382   \n",
       "193_120424           4.671514  ...         1.824380         1.468307   \n",
       "694_120605           3.719107  ...        -1.782687        -0.010839   \n",
       "366_120502           4.274035  ...         2.009806         1.761749   \n",
       "...                       ...  ...              ...              ...   \n",
       "RISK_81              4.083849  ...         1.784520         0.312004   \n",
       "RISK_9_rerun         3.930179  ...        -0.511380        -0.828332   \n",
       "RISK_93              3.864694  ...         1.060206         0.815049   \n",
       "RISK_94              4.203680  ...         0.487801         0.404469   \n",
       "RISK_97              4.173281  ...         2.081118         1.031673   \n",
       "\n",
       "              ENSG00000288011  ENSG00000288025  ENSG00000288033  \\\n",
       "487_120515           1.712583         2.383336        -0.001441   \n",
       "182_120424           1.881198         1.878234        -0.342688   \n",
       "193_120424           2.007384         1.672998        -0.085115   \n",
       "694_120605           1.409716         1.075076        -0.674845   \n",
       "366_120502           1.675437         1.846511         0.172702   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              1.968610         3.432143         1.744969   \n",
       "RISK_9_rerun         0.972381         2.849720         2.417253   \n",
       "RISK_93              2.683152         3.002727         0.631767   \n",
       "RISK_94              2.326239         3.136790         1.882202   \n",
       "RISK_97              2.258343         2.627448         1.634748   \n",
       "\n",
       "              ENSG00000288048  ENSG00000288049  ENSG00000288062  \\\n",
       "487_120515           1.532749        -0.533156         3.458250   \n",
       "182_120424           0.448150         0.563890         4.036977   \n",
       "193_120424          -0.581725        -5.248091         3.881210   \n",
       "694_120605           1.494947        -0.380824         3.377167   \n",
       "366_120502           0.484624        -5.139369         3.740314   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81             -0.881486        -4.839170         3.770227   \n",
       "RISK_9_rerun         1.029323        -5.697212         1.730592   \n",
       "RISK_93              0.502251        -3.785618         4.037104   \n",
       "RISK_94              0.738802        -5.144972         3.357130   \n",
       "RISK_97              0.516400        -2.886333         3.745269   \n",
       "\n",
       "              ENSG00000288075  ENSG00000288107  \n",
       "487_120515           4.136794         2.612982  \n",
       "182_120424           3.648011         2.219072  \n",
       "193_120424           2.879113         1.575236  \n",
       "694_120605           3.231484         0.722272  \n",
       "366_120502           3.348135         1.401988  \n",
       "...                       ...              ...  \n",
       "RISK_81              3.824714         2.717601  \n",
       "RISK_9_rerun         4.241378         0.970021  \n",
       "RISK_93              4.083396         2.015397  \n",
       "RISK_94              3.906274         1.144429  \n",
       "RISK_97              3.466199         2.843279  \n",
       "\n",
       "[951 rows x 16999 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a19e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_before, metadata_before, plot_type='umap', name='after_batch_correction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516517a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(data_before, metadata_before, plot_type='tsne', name='after_batch_correction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ad3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce41c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dd87f67",
   "metadata": {},
   "source": [
    "# Oversampling (the controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e412e13",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c007d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the modeling dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Model and performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e94d09",
   "metadata": {},
   "source": [
    "### Step 2: Create Imbalanced Dataset for Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a849bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Create an imbalanced dataset\n",
    "X, y = make_classification(n_samples=100000, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=[0.995, 0.005], class_sep=0.5, random_state=0)\n",
    "# Convert the data from numpy array to a pandas dataframe\n",
    "df = pd.DataFrame({'feature1': X[:, 0], 'feature2': X[:, 1], 'target': y})\n",
    "# Check the target distribution\n",
    "df['target'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29733e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1.0    0.646688\n",
       "0.0    0.353312\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'sex' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadat = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadat[(df_metadat['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'sex' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Create a new dataframe combining features and target\n",
    "df = pd.concat([X, y.rename('target')], axis=1)\n",
    "\n",
    "# Check the target distribution\n",
    "df['target'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With clinical variables\n",
    "import pandas as pd\n",
    "\n",
    "# Load the gene expression data\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Filter the metadata for the 'ROSMAP' study\n",
    "df_metadata = df_metadata[df_metadata['study'] == 'ROSMAP']\n",
    "\n",
    "# Drop the 'xx' column from the metadata (if it exists)\n",
    "df_metadata = df_metadata.drop(columns=['individualID', 'race', 'spanish'], errors='ignore')\n",
    "\n",
    "# Merge the metadata with the gene expression data based on the SpecimenID and index\n",
    "df_merged = df_features.merge(df_metadata, left_on=df_features.index, right_on='specimenID', how='left')\n",
    "\n",
    "# Select the 'diagnosis' column as the target variable 'y'\n",
    "y = df_merged['diagnosis']\n",
    "\n",
    "# Drop the target variable from the merged dataframe to get the features 'X'\n",
    "X = df_merged.drop(columns=['diagnosis', 'specimenID', 'study', 'ethnicity'])\n",
    "\n",
    "# Create a new dataframe combining features and target\n",
    "df = pd.concat([X, y.rename('target')], axis=1)\n",
    "\n",
    "# Check the target distribution\n",
    "print(df['target'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c2b133e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['specimenID', 'individualID', 'diagnosis', 'tissue', 'race', 'spanish',\n",
       "       'apoe4_allele', 'sex', 'batch', 'pmi', 'RIN', 'RIN2', 'age_death',\n",
       "       'AlignmentSummaryMetrics_PCT_PF_READS_ALIGNED',\n",
       "       'RnaSeqMetrics_PCT_INTRONIC_BASES',\n",
       "       'RnaSeqMetrics_PCT_INTERGENIC_BASES', 'RnaSeqMetrics_PCT_CODING_BASES',\n",
       "       'ethnicity', 'study'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Filter the metadata for the 'ROSMAP' study\n",
    "df_metadata = df_metadata[df_metadata['study'] == 'ROSMAP']\n",
    "df_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x = 'feature1', y = 'feature2', hue = 'target', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your dataset and metadata\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts1_v4.csv'\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "df_metadat = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadat[(df_metadat['study'] == 'ROSMAP')]\n",
    "\n",
    "\n",
    "# Select features and target\n",
    "X = df_features\n",
    "y = df_metadata['diagnosis'] # Adjust the mapping as needed\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame for the reduced data\n",
    "df_umap = pd.DataFrame(embedding, columns=['UMAP1', 'UMAP2'])\n",
    "df_umap['diagnosis'] = y.values  # Add the target variable\n",
    "\n",
    "# Visualize the reduced data\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='diagnosis', data=df_umap, palette=['blue', 'red'])\n",
    "plt.title('UMAP Projection of Dataset')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.legend(title='diagnosis')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c1272",
   "metadata": {},
   "source": [
    "### Step 3: Train Test Split for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f6f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in the training dataset is 713\n",
      "The number of records in the test dataset is 238\n",
      "The training dataset has 264 records for the majority class and 449 records for the minority class.\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# Check the number of records\n",
    "print('The number of records in the training dataset is', X_train.shape[0])\n",
    "print('The number of records in the test dataset is', X_test.shape[0])\n",
    "print(f\"The training dataset has {sorted(Counter(y_train).items())[0][1]} records for the majority class and {sorted(Counter(y_train).items())[1][1]} records for the minority class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8d28d",
   "metadata": {},
   "source": [
    "### Step 4: Decide the Performance Metric for Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2872b",
   "metadata": {},
   "source": [
    "### Step 5: Baseline Random Forest Model for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74117ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first count file (batch removal only) -- using only genes as features\n",
    "\n",
    "# Train the random forest model\n",
    "rf = RandomForestClassifier()\n",
    "baseline_model = rf.fit(X_train, y_train)\n",
    "baseline_prediction = baseline_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, baseline_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also using clincial variables as features\n",
    "rf = RandomForestClassifier()\n",
    "baseline_model = rf.fit(X_train, y_train)\n",
    "baseline_prediction = baseline_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, baseline_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the second batch removal file (residualized)\n",
    "\n",
    "# Train the random forest model\n",
    "rf = RandomForestClassifier()\n",
    "baseline_model = rf.fit(X_train, y_train)\n",
    "baseline_prediction = baseline_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, baseline_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cd301",
   "metadata": {},
   "source": [
    "### Step 6: Random Oversampling for Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly over sample the minority class\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros= ros.fit_resample(X_train, y_train)\n",
    "# Check the number of records after over sampling\n",
    "print(sorted(Counter(y_train_ros).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling with shrinkage parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a918e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly over sample the minority class\n",
    "ros = RandomOverSampler(shrinkage=2, random_state=42)\n",
    "X_train_ros, y_train_ros= ros.fit_resample(X_train, y_train)\n",
    "# Check the number of records after over sampling\n",
    "print(sorted(Counter(y_train_ros).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54923df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming X_train_ros and y_train_ros are your feature matrix and target array after random over-sampling\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding_ros = reducer.fit_transform(X_train_ros)\n",
    "\n",
    "# Create a DataFrame for the reduced data\n",
    "df_umap_ros = pd.DataFrame(embedding_ros, columns=['UMAP1', 'UMAP2'])\n",
    "df_umap_ros['target'] = y_train_ros  # Add the target variable\n",
    "\n",
    "# Visualize the reduced data\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='target', data=df_umap_ros, palette=['blue', 'red'])\n",
    "plt.title('UMAP Projection of Random Over-Sampled Data')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.legend(title='Target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first count file (batch effect)\n",
    "# Train the random forest model\n",
    "# rf = RandomForestClassifier()\n",
    "ros_model = rf.fit(X_train_ros, y_train_ros)\n",
    "ros_prediction = ros_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, ros_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5df543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the second count file (residualized)\n",
    "# Train the random forest model\n",
    "rf = RandomForestClassifier()\n",
    "ros_model = rf.fit(X_train_ros, y_train_ros)\n",
    "ros_prediction = ros_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, ros_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the model with shrinkage (dispersion)\n",
    "rf = RandomForestClassifier()\n",
    "ros_model = rf.fit(X_train_ros, y_train_ros)\n",
    "ros_prediction = ros_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, ros_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341466f",
   "metadata": {},
   "source": [
    "### Step 7: SMOTE Oversampling for Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad8d9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 449), (1, 449)]\n"
     ]
    }
   ],
   "source": [
    "# Randomly over sample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote= smote.fit_resample(X_train, y_train)\n",
    "# Check the number of records after over sampling\n",
    "print(sorted(Counter(y_train_smote).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "df_smote = pd.DataFrame({'feature1': X_train_smote[:, 0], 'feature2': X_train_smote[:, 1], 'target': y_train_smote})\n",
    "# Plot the chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x = 'feature1', y = 'feature2', hue = 'target', data = df_smote)\n",
    "plt.title('SMOTE Over Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62453cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb589ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming X_train_ros and y_train_ros are your feature matrix and target array after random over-sampling\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding_ros = reducer.fit_transform(X_train_smote)\n",
    "\n",
    "# Create a DataFrame for the reduced data\n",
    "df_umap_smote = pd.DataFrame(embedding_ros, columns=['UMAP1', 'UMAP2'])\n",
    "df_umap_smote['target'] = y_train_smote  # Add the target variable\n",
    "\n",
    "# Visualize the reduced data\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='target', data=df_umap_smote, palette=['blue', 'red'])\n",
    "plt.title('UMAP Projection of Random Over-Sampled Data')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.legend(title='Target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a806c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61        72\n",
      "           1       0.83      0.85      0.84       166\n",
      "\n",
      "    accuracy                           0.77       238\n",
      "   macro avg       0.73      0.72      0.73       238\n",
      "weighted avg       0.77      0.77      0.77       238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First count filev (batch effect)\n",
    "# Train the random forest model\n",
    "rf = RandomForestClassifier()\n",
    "smote_model = rf.fit(X_train_smote, y_train_smote)\n",
    "smote_prediction = smote_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, smote_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second count file (residualized)\n",
    "smote_model = rf.fit(X_train_smote, y_train_smote)\n",
    "smote_prediction = smote_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, smote_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d515f5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21081/3115065524.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_resampled['target'] = y_resampled\n",
      "/tmp/ipykernel_21081/3115065524.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_resampled['sample_index'] = sample_indices\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m df_resampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_indices\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Save the resampled dataset to a CSV file\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mdf_resampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mROSMAP_counts_v9_17k_SMOTE.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/formats/csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/formats/csvs.py:271\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/formats/csvs.py:309\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/io/formats/csvs.py:316\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    313\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[1;32m    314\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[0;32m--> 316\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_native_types\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    319\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/internals/managers.py:438\u001b[0m, in \u001b[0;36mBaseBlockManager.to_native_types\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_native_types\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mto_native_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/internals/blocks.py:637\u001b[0m, in \u001b[0;36mBlock.to_native_types\u001b[0;34m(self, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m result \u001b[38;5;241m=\u001b[39m to_native_types(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, na_rep\u001b[38;5;241m=\u001b[39mna_rep, quoting\u001b[38;5;241m=\u001b[39mquoting, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/internals/blocks.py:263\u001b[0m, in \u001b[0;36mBlock.make_block\u001b[0;34m(self, values, placement, refs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m    261\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_block_shape(values, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2400\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, refs)\u001b[0m\n\u001b[1;32m   2388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_block\u001b[39m(\n\u001b[1;32m   2389\u001b[0m     values,\n\u001b[1;32m   2390\u001b[0m     placement: BlockPlacement,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[38;5;66;03m# - check_ndim/ensure_block_shape already checked\u001b[39;00m\n\u001b[1;32m   2398\u001b[0m     \u001b[38;5;66;03m# - maybe_coerce_values already called/unnecessary\u001b[39;00m\n\u001b[1;32m   2399\u001b[0m     klass \u001b[38;5;241m=\u001b[39m get_block_type(values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 2400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use next one\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "# Load the dataset with features\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'diagnosis' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadata[(df_metadata['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'diagnosis' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Store the original indices as strings\n",
    "original_indices = X.index.astype(str)\n",
    "\n",
    "# Apply SMOTE\n",
    "ros = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Create a column for indices, initializing with a placeholder for generated samples\n",
    "sample_indices = np.array([None] * len(X_resampled))\n",
    "\n",
    "# Assign the original indices to the corresponding samples in the resampled dataset\n",
    "sample_indices[:len(original_indices)] = original_indices\n",
    "\n",
    "# Combine the resampled features, target, and sample indices into a DataFrame\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_resampled['target'] = y_resampled\n",
    "df_resampled['sample_index'] = sample_indices\n",
    "\n",
    "# Save the resampled dataset to a CSV file\n",
    "df_resampled.to_csv('ROSMAP_counts_v9_17k_SMOTE.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6532ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE next one!!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Load the dataset with features\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'diagnosis' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadata[(df_metadata['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'diagnosis' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Assign temporary unique names to the generated samples\n",
    "X_resampled.index = X.index.tolist() + [f\"generated_{i}\" for i in range(1, len(X_resampled) - len(X) + 1)]\n",
    "\n",
    "# Create a list to store new metadata rows\n",
    "new_metadata_rows = []\n",
    "\n",
    "# Iterate through the generated samples\n",
    "for idx in X_resampled.index[len(X):]:\n",
    "    # Find the original sample the generated sample was duplicated from (considering only the first 1000 columns)\n",
    "    original_index = next((orig_idx for orig_idx, orig_row in X.iloc[:, :11].iterrows() if (orig_row == X_resampled.iloc[:, :11].loc[idx]).all()), None)\n",
    "    \n",
    "    # Update the index for the generated sample\n",
    "    new_index = f\"{original_index}_{idx}\"\n",
    "    X_resampled.rename(index={idx: new_index}, inplace=True)\n",
    "    \n",
    "    # Create a new row in the metadata with the updated index\n",
    "    new_metadata_row = df_metadata[df_metadata['specimenID'] == original_index].iloc[0].copy()\n",
    "    new_metadata_row['specimenID'] = new_index\n",
    "    new_metadata_rows.append(new_metadata_row)\n",
    "\n",
    "# Concatenate the new metadata rows to the original metadata DataFrame\n",
    "df_metadata = pd.concat([df_metadata] + new_metadata_rows, ignore_index=True)\n",
    "\n",
    "# Save the updated metadata and gene expression datasets\n",
    "df_metadata.to_csv('./metadata_v9_rosmap_SMOTE.csv', index=False)\n",
    "X_resampled.to_csv('ROSMAP_counts_v9_17k_SMOTE.csv', index_label='sample_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the dataset with features\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'diagnosis' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadata[(df_metadata['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'diagnosis' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create the updated metadata based on y_resampled\n",
    "updated_metadata = pd.DataFrame({'specimenID': X_resampled.index, 'diagnosis': y_resampled})\n",
    "\n",
    "# Save the updated metadata and gene expression datasets\n",
    "updated_metadata.to_csv('./metadata_v9_rosmap_SMOTE.csv', index=False)\n",
    "X_resampled.to_csv('ROSMAP_counts_v9_17k_SMOTE.csv', index_label='sample_index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9763add",
   "metadata": {},
   "source": [
    "### Step 8: Random Under-Sampling for Imbalanced Dataset (Not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bf270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly under sample the majority class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(X_train, y_train)\n",
    "# Check the number of records after under sampling\n",
    "print(sorted(Counter(y_train_rus).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data from numpy array to a pandas dataframe\n",
    "df_rus = pd.DataFrame({'feature1': X_train_rus[:, 0], 'feature2': X_train_rus[:, 1], 'target': y_train_rus})\n",
    "# Plot the chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x = 'feature1', y = 'feature2', hue = 'target', data = df_rus)\n",
    "plt.title('Random Under Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the random forest model\n",
    "# rf = RandomForestClassifier()\n",
    "rus_model = rf.fit(X_train_rus, y_train_rus)\n",
    "rus_prediction = rus_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, rus_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d596f",
   "metadata": {},
   "source": [
    "## Random_sampling for my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'sex' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadat = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadat[(df_metadat['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'sex' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the next code\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'X' is a DataFrame and 'y' is a Series or array\n",
    "\n",
    "# Store the original indices\n",
    "original_indices = X.index\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Create a column for indices, initializing with -1 for generated samples\n",
    "sample_indices = np.full(len(X_resampled), -1)\n",
    "\n",
    "# Assign the original indices to the corresponding samples in the resampled dataset\n",
    "sample_indices[:len(original_indices)] = original_indices\n",
    "\n",
    "# Combine the resampled features, target, and sample indices into a DataFrame\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_resampled['target'] = y_resampled\n",
    "df_resampled['sample_index'] = sample_indices\n",
    "\n",
    "# Save the resampled dataset to a CSV file\n",
    "df_resampled.to_csv('ROSMAP_counts_v5_oversamp', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One coherent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0201e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load the dataset with features\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'diagnosis' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadata[(df_metadata['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'diagnosis' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Store the original indices as strings\n",
    "original_indices = X.index.astype(str)\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Create a column for indices, initializing with a placeholder for generated samples\n",
    "sample_indices = np.array([None] * len(X_resampled))\n",
    "\n",
    "# Assign the original indices to the corresponding samples in the resampled dataset\n",
    "sample_indices[:len(original_indices)] = original_indices\n",
    "\n",
    "# Combine the resampled features, target, and sample indices into a DataFrame\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_resampled['target'] = y_resampled\n",
    "df_resampled['sample_index'] = sample_indices\n",
    "\n",
    "# Save the resampled dataset to a CSV file\n",
    "df_resampled.to_csv('ROSMAP_counts_v5_oversamp.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c44c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad1f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new code to try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db21bf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Iterate through the generated samples\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m X_resampled\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;28mlen\u001b[39m(X):]:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Find the original sample the generated sample was duplicated from\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     original_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((orig_idx \u001b[38;5;28;01mfor\u001b[39;00m orig_idx, orig_row \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39miterrows() \u001b[38;5;28;01mif\u001b[39;00m (orig_row \u001b[38;5;241m==\u001b[39m X_resampled\u001b[38;5;241m.\u001b[39mloc[idx])\u001b[38;5;241m.\u001b[39mall()), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Update the index for the generated sample\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Iterate through the generated samples\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m X_resampled\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;28mlen\u001b[39m(X):]:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Find the original sample the generated sample was duplicated from\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     original_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((orig_idx \u001b[38;5;28;01mfor\u001b[39;00m orig_idx, orig_row \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39miterrows() \u001b[38;5;28;01mif\u001b[39;00m (orig_row \u001b[38;5;241m==\u001b[39m \u001b[43mX_resampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mall()), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Update the index for the generated sample\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/generic.py:4256\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4251\u001b[0m     \u001b[38;5;66;03m# if we encounter an array-like and we only have 1 dim\u001b[39;00m\n\u001b[1;32m   4252\u001b[0m     \u001b[38;5;66;03m# that means that their are list/ndarrays inside the Series!\u001b[39;00m\n\u001b[1;32m   4253\u001b[0m     \u001b[38;5;66;03m# so just return them (GH 6394)\u001b[39;00m\n\u001b[1;32m   4254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n\u001b[0;32m-> 4256\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4258\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   4259\u001b[0m result\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex[loc]\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/pandas/core/internals/managers.py:980\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    975\u001b[0m     result \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(result)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, rl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(blk\u001b[38;5;241m.\u001b[39mmgr_locs):\n\u001b[1;32m    981\u001b[0m         result[rl] \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39miget((i, loc))\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load the dataset with features\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'diagnosis' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadata[(df_metadata['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'diagnosis' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Assign temporary unique names to the generated samples\n",
    "X_resampled.index = X.index.tolist() + [f\"generated_{i}\" for i in range(1, len(X_resampled) - len(X) + 1)]\n",
    "\n",
    "# Create a list to store new metadata rows\n",
    "new_metadata_rows = []\n",
    "\n",
    "# Iterate through the generated samples\n",
    "for idx in X_resampled.index[len(X):]:\n",
    "    # Find the original sample the generated sample was duplicated from\n",
    "    original_index = next((orig_idx for orig_idx, orig_row in X.iterrows() if (orig_row == X_resampled.loc[idx]).all()), None)\n",
    "    \n",
    "    # Update the index for the generated sample\n",
    "    new_index = f\"{original_index}_{idx}\"\n",
    "    X_resampled.rename(index={idx: new_index}, inplace=True)\n",
    "    \n",
    "    # Create a new row in the metadata with the updated index\n",
    "    new_metadata_row = df_metadata[df_metadata['specimenID'] == original_index].iloc[0].copy()\n",
    "    new_metadata_row['specimenID'] = new_index\n",
    "    new_metadata_rows.append(new_metadata_row)\n",
    "\n",
    "# Concatenate the new metadata rows to the original metadata DataFrame\n",
    "df_metadata = pd.concat([df_metadata] + new_metadata_rows, ignore_index=True)\n",
    "\n",
    "# Save the updated metadata and gene expression datasets\n",
    "df_metadata.to_csv('./metadata_v6_rosmap.csv', index=False)\n",
    "X_resampled.to_csv('ROSMAP_counts_v6.csv', index_label='sample_index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8cd073",
   "metadata": {},
   "source": [
    "### Oversampling and updating indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A faster approach\n",
    "# USE this one!!\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load the dataset with features\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'diagnosis' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadata[(df_metadata['study'] == 'ROSMAP')]\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'diagnosis' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Assign temporary unique names to the generated samples\n",
    "X_resampled.index = X.index.tolist() + [f\"generated_{i}\" for i in range(1, len(X_resampled) - len(X) + 1)]\n",
    "\n",
    "# Create a list to store new metadata rows\n",
    "new_metadata_rows = []\n",
    "\n",
    "# Iterate through the generated samples\n",
    "for idx in X_resampled.index[len(X):]:\n",
    "    # Find the original sample the generated sample was duplicated from (considering only the first 1000 columns)\n",
    "    original_index = next((orig_idx for orig_idx, orig_row in X.iloc[:, :11].iterrows() if (orig_row == X_resampled.iloc[:, :11].loc[idx]).all()), None)\n",
    "    \n",
    "    # Update the index for the generated sample\n",
    "    new_index = f\"{original_index}_{idx}\"\n",
    "    X_resampled.rename(index={idx: new_index}, inplace=True)\n",
    "    \n",
    "    # Create a new row in the metadata with the updated index\n",
    "    new_metadata_row = df_metadata[df_metadata['specimenID'] == original_index].iloc[0].copy()\n",
    "    new_metadata_row['specimenID'] = new_index\n",
    "    new_metadata_rows.append(new_metadata_row)\n",
    "\n",
    "# Concatenate the new metadata rows to the original metadata DataFrame\n",
    "df_metadata = pd.concat([df_metadata] + new_metadata_rows, ignore_index=True)\n",
    "\n",
    "# Save the updated metadata and gene expression datasets\n",
    "df_metadata.to_csv('./metadata_v6_rosmap.csv', index=False)\n",
    "X_resampled.to_csv('ROSMAP_counts_v6.csv', index_label='sample_index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ebc5b",
   "metadata": {},
   "source": [
    "### Modify the metadata for adding clinical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb0ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pd.read_csv('./metadata_v3.csv')\n",
    "df_metadata = xx[(xx['study'] == 'ROSMAP')]\n",
    "df_gene_expression = pd.read_csv('ROSMAP_counts_v6.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bf7f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Iterate through the indices of the gene expression dataset from slice 950 forward\n",
    "for idx in df_gene_expression.index[950:]:\n",
    "    if '_generated_' in idx:\n",
    "        # Extract the original sample name from the index\n",
    "        original_sample_name = idx.split('_generated_')[0]\n",
    "        \n",
    "        # Find the corresponding row in the metadata\n",
    "        metadata_row = df_metadata[df_metadata['specimenID'] == original_sample_name]\n",
    "        \n",
    "        # If a matching row is found, duplicate it and update the specimenID\n",
    "        if not metadata_row.empty:\n",
    "            new_metadata_row = metadata_row.copy()\n",
    "            new_metadata_row['specimenID'] = idx\n",
    "            df_metadata = pd.concat([df_metadata, new_metadata_row], ignore_index=True)\n",
    "\n",
    "# Save the updated metadata file\n",
    "df_metadata.to_csv('metadata_v6_rosmap.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93951e71",
   "metadata": {},
   "source": [
    "## Adding clinical variable info to the random sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03177298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('metadata_v6_rosmap.csv', index_col=0)\n",
    "x\n",
    "# \"ROSMAP_counts_v5_oversamp.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.index)\n",
    "num_unique_indices = x.index.nunique()\n",
    "print(\"Number of unique indices:\", num_unique_indices)\n",
    "print(x.index[950:963])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[950:960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af46f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the gene expression data\n",
    "df_gene_expr = pd.read_csv(\"ROSMAP_counts_v5_oversamp.csv\", index_col=\"sample_index\")\n",
    "\n",
    "# Remove the 'target' column from the gene expression DataFrame\n",
    "df_gene_expr = df_gene_expr.drop(columns=['target'], errors='ignore')\n",
    "\n",
    "# Create a copy of the gene expression DataFrame with only the first 1000 columns\n",
    "df_gene_expr_subset = df_gene_expr.iloc[:, :1000]\n",
    "\n",
    "# Dictionary to store the count of occurrences for each unique row\n",
    "row_counts = {}\n",
    "\n",
    "# Iterate over the rows in the subset\n",
    "for idx, row in df_gene_expr_subset.iterrows():\n",
    "    # Convert the row to a tuple to make it hashable\n",
    "    row_tuple = tuple(row)\n",
    "    # Increment the count for this row\n",
    "    row_counts[row_tuple] = row_counts.get(row_tuple, 0) + 1\n",
    "\n",
    "# Identify rows that have been duplicated more than once\n",
    "duplicated_rows = {row: count for row, count in row_counts.items() if count > 1}\n",
    "\n",
    "# Print the duplicated rows and their counts\n",
    "print(\"Duplicated rows and their counts:\")\n",
    "# for row, count in duplicated_rows.items():\n",
    "#     print(f\"{row}: {count} times\")\n",
    "\n",
    "# Print the total number of unique rows that have been duplicated\n",
    "print(f\"Total unique rows duplicated more than once: {len(duplicated_rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576c0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6a550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pd.read_csv('metadata_v6_rosmap.csv')\n",
    "df_metadata = xx[(xx['study'] == 'ROSMAP')]\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new code for adding variable info (both files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cc889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce427b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 279\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the gene expression data\n",
    "df = pd.read_csv(\"ROSMAP_counts_v6.csv\", index_col=\"sample_index\")\n",
    "\n",
    "# Check the number of duplicated rows\n",
    "num_duplicated_rows = df.duplicated().sum()\n",
    "\n",
    "# Print the number of duplicated rows\n",
    "print(f\"Number of duplicated rows: {num_duplicated_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cdc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b0ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc20c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c1620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb175d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc1f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38603299",
   "metadata": {},
   "source": [
    "# Select genes set using MAD (mean absolute deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_path = 'ROSMAP_counts_v9_17k_SMOTE.csv'\n",
    "df = pd.read_csv(dataset_path, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025e5b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NULL values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check for NULL values in the dataset\n",
    "null_values_exist = df.isnull().any().any()\n",
    "\n",
    "if null_values_exist:\n",
    "    print(\"There are NULL values in the dataset.\")\n",
    "else:\n",
    "    print(\"There are no NULL values in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70078fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.robust.scale import mad\n",
    "\n",
    "# Calculate the Median Absolute Deviation (MAD) for each gene (column)\n",
    "mad_values = df.apply(mad, axis=0)\n",
    "\n",
    "# Rank the genes based on MAD values from most variable to least variable\n",
    "ranked_genes = mad_values.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "least_variable_genes = ranked_genes[-4000:]\n",
    "most_variable_genes = ranked_genes[:2000]\n",
    "\n",
    "# Print the ranked list of genes\n",
    "print(\"Ranked genes from most variable to least variable:\" )\n",
    "print(ranked_genes)\n",
    "print(\"Least variable:\")\n",
    "print(least_variable_genes)\n",
    "print('Most variable:')\n",
    "print(most_variable_genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For biomart\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.robust.scale import mad\n",
    "\n",
    "# Calculate the Median Absolute Deviation (MAD) for each gene (column)\n",
    "mad_values = df.apply(mad, axis=0)\n",
    "\n",
    "# Rank the genes based on MAD values from most variable to least variable\n",
    "ranked_genes = mad_values.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# Get the least variable and most variable genes\n",
    "least_variable_genes = ranked_genes[-4000:]\n",
    "most_variable_genes = ranked_genes[:2000]\n",
    "\n",
    "# Format the gene names for BioMart\n",
    "least_variable_genes_formatted = ', '.join(least_variable_genes)\n",
    "most_variable_genes_formatted = ', '.join(most_variable_genes)\n",
    "\n",
    "# Print the formatted gene names\n",
    "print(\"Formatted least variable genes for BioMart:\")\n",
    "print(least_variable_genes_formatted)\n",
    "print(\"\\nFormatted most variable genes for BioMart:\")\n",
    "print(most_variable_genes_formatted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6e8a2",
   "metadata": {},
   "source": [
    "## Removing least vareiable genes (4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cf1f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_path = 'ROSMAP_counts_v9_17k_SMOTE.csv'\n",
    "df = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "\n",
    "# Remove the columns corresponding to the genes in the list\n",
    "df_filtered = df.drop(columns=least_variable_genes)\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "new_csv_file_path = 'ROSMAP_counts_v9_13k_SMOTE.csv'\n",
    "df_filtered.to_csv(new_csv_file_path, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f9bdf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000287978</th>\n",
       "      <th>ENSG00000287985</th>\n",
       "      <th>ENSG00000288011</th>\n",
       "      <th>ENSG00000288025</th>\n",
       "      <th>ENSG00000288033</th>\n",
       "      <th>ENSG00000288048</th>\n",
       "      <th>ENSG00000288049</th>\n",
       "      <th>ENSG00000288062</th>\n",
       "      <th>ENSG00000288075</th>\n",
       "      <th>ENSG00000288107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487_120515</th>\n",
       "      <td>2.693056</td>\n",
       "      <td>4.008124</td>\n",
       "      <td>3.843684</td>\n",
       "      <td>1.891460</td>\n",
       "      <td>2.131878</td>\n",
       "      <td>5.089801</td>\n",
       "      <td>2.564877</td>\n",
       "      <td>4.163159</td>\n",
       "      <td>4.105802</td>\n",
       "      <td>4.275373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.892324</td>\n",
       "      <td>0.680168</td>\n",
       "      <td>1.689954</td>\n",
       "      <td>2.831027</td>\n",
       "      <td>0.617244</td>\n",
       "      <td>1.545664</td>\n",
       "      <td>-0.547594</td>\n",
       "      <td>3.269352</td>\n",
       "      <td>4.395686</td>\n",
       "      <td>2.913610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182_120424</th>\n",
       "      <td>2.952038</td>\n",
       "      <td>4.146917</td>\n",
       "      <td>3.819310</td>\n",
       "      <td>1.672045</td>\n",
       "      <td>1.707203</td>\n",
       "      <td>3.071029</td>\n",
       "      <td>3.198746</td>\n",
       "      <td>5.275337</td>\n",
       "      <td>4.577458</td>\n",
       "      <td>4.262465</td>\n",
       "      <td>...</td>\n",
       "      <td>1.396146</td>\n",
       "      <td>1.114917</td>\n",
       "      <td>1.750664</td>\n",
       "      <td>2.448238</td>\n",
       "      <td>0.277121</td>\n",
       "      <td>0.514422</td>\n",
       "      <td>0.597116</td>\n",
       "      <td>3.664030</td>\n",
       "      <td>3.934631</td>\n",
       "      <td>2.502630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193_120424</th>\n",
       "      <td>2.935881</td>\n",
       "      <td>4.394735</td>\n",
       "      <td>4.399317</td>\n",
       "      <td>1.909150</td>\n",
       "      <td>1.711887</td>\n",
       "      <td>3.485700</td>\n",
       "      <td>3.305756</td>\n",
       "      <td>5.022003</td>\n",
       "      <td>4.313655</td>\n",
       "      <td>4.688572</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281214</td>\n",
       "      <td>1.294638</td>\n",
       "      <td>2.047225</td>\n",
       "      <td>1.919104</td>\n",
       "      <td>0.219337</td>\n",
       "      <td>-0.596076</td>\n",
       "      <td>-5.247300</td>\n",
       "      <td>3.774892</td>\n",
       "      <td>3.034315</td>\n",
       "      <td>1.800074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694_120605</th>\n",
       "      <td>3.970723</td>\n",
       "      <td>3.811088</td>\n",
       "      <td>3.519447</td>\n",
       "      <td>1.613139</td>\n",
       "      <td>3.515993</td>\n",
       "      <td>4.746188</td>\n",
       "      <td>3.800684</td>\n",
       "      <td>5.696683</td>\n",
       "      <td>4.843922</td>\n",
       "      <td>3.624694</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.986291</td>\n",
       "      <td>-0.357597</td>\n",
       "      <td>1.358419</td>\n",
       "      <td>1.261599</td>\n",
       "      <td>-0.455351</td>\n",
       "      <td>1.506439</td>\n",
       "      <td>-0.391900</td>\n",
       "      <td>3.188582</td>\n",
       "      <td>3.419970</td>\n",
       "      <td>0.863133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366_120502</th>\n",
       "      <td>3.555162</td>\n",
       "      <td>3.863562</td>\n",
       "      <td>3.737334</td>\n",
       "      <td>2.403238</td>\n",
       "      <td>4.053856</td>\n",
       "      <td>5.039985</td>\n",
       "      <td>3.336166</td>\n",
       "      <td>5.500272</td>\n",
       "      <td>4.573848</td>\n",
       "      <td>4.143737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.707821</td>\n",
       "      <td>1.329693</td>\n",
       "      <td>1.540511</td>\n",
       "      <td>2.377912</td>\n",
       "      <td>0.960361</td>\n",
       "      <td>0.552581</td>\n",
       "      <td>-5.109539</td>\n",
       "      <td>3.378009</td>\n",
       "      <td>3.621923</td>\n",
       "      <td>1.674681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_81</th>\n",
       "      <td>3.480599</td>\n",
       "      <td>4.551965</td>\n",
       "      <td>3.794995</td>\n",
       "      <td>2.044125</td>\n",
       "      <td>2.658725</td>\n",
       "      <td>5.550509</td>\n",
       "      <td>3.364785</td>\n",
       "      <td>4.804389</td>\n",
       "      <td>4.476099</td>\n",
       "      <td>4.117583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.346634</td>\n",
       "      <td>0.917420</td>\n",
       "      <td>1.872746</td>\n",
       "      <td>2.475703</td>\n",
       "      <td>0.227905</td>\n",
       "      <td>-0.805499</td>\n",
       "      <td>-4.915610</td>\n",
       "      <td>4.155401</td>\n",
       "      <td>3.197329</td>\n",
       "      <td>2.047402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_9_rerun</th>\n",
       "      <td>3.033182</td>\n",
       "      <td>3.598383</td>\n",
       "      <td>3.430243</td>\n",
       "      <td>1.701873</td>\n",
       "      <td>2.982793</td>\n",
       "      <td>3.559018</td>\n",
       "      <td>3.009816</td>\n",
       "      <td>5.052380</td>\n",
       "      <td>4.491756</td>\n",
       "      <td>4.041375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084201</td>\n",
       "      <td>0.165583</td>\n",
       "      <td>1.214401</td>\n",
       "      <td>1.854056</td>\n",
       "      <td>0.874431</td>\n",
       "      <td>1.085004</td>\n",
       "      <td>-5.813749</td>\n",
       "      <td>2.268562</td>\n",
       "      <td>3.611761</td>\n",
       "      <td>0.364139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_93</th>\n",
       "      <td>4.234210</td>\n",
       "      <td>4.465530</td>\n",
       "      <td>4.319146</td>\n",
       "      <td>2.264421</td>\n",
       "      <td>2.106420</td>\n",
       "      <td>4.098086</td>\n",
       "      <td>3.708144</td>\n",
       "      <td>5.490788</td>\n",
       "      <td>4.406034</td>\n",
       "      <td>3.908534</td>\n",
       "      <td>...</td>\n",
       "      <td>1.726131</td>\n",
       "      <td>1.341263</td>\n",
       "      <td>2.480019</td>\n",
       "      <td>1.947281</td>\n",
       "      <td>-1.029335</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>-3.861985</td>\n",
       "      <td>4.389101</td>\n",
       "      <td>3.446107</td>\n",
       "      <td>1.381710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_94</th>\n",
       "      <td>4.074123</td>\n",
       "      <td>4.374235</td>\n",
       "      <td>4.164492</td>\n",
       "      <td>2.307973</td>\n",
       "      <td>1.930466</td>\n",
       "      <td>4.041678</td>\n",
       "      <td>3.714398</td>\n",
       "      <td>5.463185</td>\n",
       "      <td>4.406323</td>\n",
       "      <td>4.232183</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195124</td>\n",
       "      <td>0.974912</td>\n",
       "      <td>2.112795</td>\n",
       "      <td>2.120084</td>\n",
       "      <td>0.340579</td>\n",
       "      <td>0.772254</td>\n",
       "      <td>-5.215149</td>\n",
       "      <td>3.750806</td>\n",
       "      <td>3.277829</td>\n",
       "      <td>0.504551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_97</th>\n",
       "      <td>3.805448</td>\n",
       "      <td>4.535813</td>\n",
       "      <td>4.182196</td>\n",
       "      <td>1.922559</td>\n",
       "      <td>2.291532</td>\n",
       "      <td>4.440045</td>\n",
       "      <td>3.657504</td>\n",
       "      <td>5.298593</td>\n",
       "      <td>4.229520</td>\n",
       "      <td>4.230607</td>\n",
       "      <td>...</td>\n",
       "      <td>2.565061</td>\n",
       "      <td>1.592915</td>\n",
       "      <td>2.186214</td>\n",
       "      <td>1.556285</td>\n",
       "      <td>0.104856</td>\n",
       "      <td>0.567986</td>\n",
       "      <td>-2.976356</td>\n",
       "      <td>4.127463</td>\n",
       "      <td>2.843571</td>\n",
       "      <td>2.187553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows  12999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ENSG00000000003  ENSG00000000419  ENSG00000000457  \\\n",
       "487_120515           2.693056         4.008124         3.843684   \n",
       "182_120424           2.952038         4.146917         3.819310   \n",
       "193_120424           2.935881         4.394735         4.399317   \n",
       "694_120605           3.970723         3.811088         3.519447   \n",
       "366_120502           3.555162         3.863562         3.737334   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              3.480599         4.551965         3.794995   \n",
       "RISK_9_rerun         3.033182         3.598383         3.430243   \n",
       "RISK_93              4.234210         4.465530         4.319146   \n",
       "RISK_94              4.074123         4.374235         4.164492   \n",
       "RISK_97              3.805448         4.535813         4.182196   \n",
       "\n",
       "              ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "487_120515           1.891460         2.131878         5.089801   \n",
       "182_120424           1.672045         1.707203         3.071029   \n",
       "193_120424           1.909150         1.711887         3.485700   \n",
       "694_120605           1.613139         3.515993         4.746188   \n",
       "366_120502           2.403238         4.053856         5.039985   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              2.044125         2.658725         5.550509   \n",
       "RISK_9_rerun         1.701873         2.982793         3.559018   \n",
       "RISK_93              2.264421         2.106420         4.098086   \n",
       "RISK_94              2.307973         1.930466         4.041678   \n",
       "RISK_97              1.922559         2.291532         4.440045   \n",
       "\n",
       "              ENSG00000001036  ENSG00000001084  ENSG00000001167  \\\n",
       "487_120515           2.564877         4.163159         4.105802   \n",
       "182_120424           3.198746         5.275337         4.577458   \n",
       "193_120424           3.305756         5.022003         4.313655   \n",
       "694_120605           3.800684         5.696683         4.843922   \n",
       "366_120502           3.336166         5.500272         4.573848   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              3.364785         4.804389         4.476099   \n",
       "RISK_9_rerun         3.009816         5.052380         4.491756   \n",
       "RISK_93              3.708144         5.490788         4.406034   \n",
       "RISK_94              3.714398         5.463185         4.406323   \n",
       "RISK_97              3.657504         5.298593         4.229520   \n",
       "\n",
       "              ENSG00000001460  ...  ENSG00000287978  ENSG00000287985  \\\n",
       "487_120515           4.275373  ...         1.892324         0.680168   \n",
       "182_120424           4.262465  ...         1.396146         1.114917   \n",
       "193_120424           4.688572  ...         1.281214         1.294638   \n",
       "694_120605           3.624694  ...        -2.986291        -0.357597   \n",
       "366_120502           4.143737  ...         1.707821         1.329693   \n",
       "...                       ...  ...              ...              ...   \n",
       "RISK_81              4.117583  ...         2.346634         0.917420   \n",
       "RISK_9_rerun         4.041375  ...         0.084201         0.165583   \n",
       "RISK_93              3.908534  ...         1.726131         1.341263   \n",
       "RISK_94              4.232183  ...         1.195124         0.974912   \n",
       "RISK_97              4.230607  ...         2.565061         1.592915   \n",
       "\n",
       "              ENSG00000288011  ENSG00000288025  ENSG00000288033  \\\n",
       "487_120515           1.689954         2.831027         0.617244   \n",
       "182_120424           1.750664         2.448238         0.277121   \n",
       "193_120424           2.047225         1.919104         0.219337   \n",
       "694_120605           1.358419         1.261599        -0.455351   \n",
       "366_120502           1.540511         2.377912         0.960361   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81              1.872746         2.475703         0.227905   \n",
       "RISK_9_rerun         1.214401         1.854056         0.874431   \n",
       "RISK_93              2.480019         1.947281        -1.029335   \n",
       "RISK_94              2.112795         2.120084         0.340579   \n",
       "RISK_97              2.186214         1.556285         0.104856   \n",
       "\n",
       "              ENSG00000288048  ENSG00000288049  ENSG00000288062  \\\n",
       "487_120515           1.545664        -0.547594         3.269352   \n",
       "182_120424           0.514422         0.597116         3.664030   \n",
       "193_120424          -0.596076        -5.247300         3.774892   \n",
       "694_120605           1.506439        -0.391900         3.188582   \n",
       "366_120502           0.552581        -5.109539         3.378009   \n",
       "...                       ...              ...              ...   \n",
       "RISK_81             -0.805499        -4.915610         4.155401   \n",
       "RISK_9_rerun         1.085004        -5.813749         2.268562   \n",
       "RISK_93              0.544776        -3.861985         4.389101   \n",
       "RISK_94              0.772254        -5.215149         3.750806   \n",
       "RISK_97              0.567986        -2.976356         4.127463   \n",
       "\n",
       "              ENSG00000288075  ENSG00000288107  \n",
       "487_120515           4.395686         2.913610  \n",
       "182_120424           3.934631         2.502630  \n",
       "193_120424           3.034315         1.800074  \n",
       "694_120605           3.419970         0.863133  \n",
       "366_120502           3.621923         1.674681  \n",
       "...                       ...              ...  \n",
       "RISK_81              3.197329         2.047402  \n",
       "RISK_9_rerun         3.611761         0.364139  \n",
       "RISK_93              3.446107         1.381710  \n",
       "RISK_94              3.277829         0.504551  \n",
       "RISK_97              2.843571         2.187553  \n",
       "\n",
       "[951 rows x 12999 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_path = 'ROSMAP_counts_v8_original_13k.csv'\n",
    "df = pd.read_csv(dataset_path, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df925621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aed71b3",
   "metadata": {},
   "source": [
    "# ML model (use the next section!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d7bd45",
   "metadata": {},
   "source": [
    "## Only genes as features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17f822",
   "metadata": {},
   "source": [
    "### Old RF model (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "041d759a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.5\n",
       "1    0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/metadata_v6_rosmap.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'sex' column\n",
    "metadata_path = './metadata_v6_rosmap.csv'\n",
    "df_metadata = pd.read_csv(metadata_path, index_col=\"specimenID\")\n",
    "\n",
    "# Select features from the dataset file\n",
    "X = df_features\n",
    "\n",
    "# Select the 'sex' column from the metadata file as 'y'\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Create a new dataframe combining features and target\n",
    "df = pd.concat([X, y.rename('target')], axis=1)\n",
    "\n",
    "# Check the target distribution\n",
    "df['target'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702edd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bf068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With clinical variables\n",
    "import pandas as pd\n",
    "\n",
    "# Load the gene expression data\n",
    "dataset_path = './AMP_AD_datasets/ROSMAP_counts_v4.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Filter the metadata for the 'ROSMAP' study\n",
    "df_metadata = df_metadata[df_metadata['study'] == 'ROSMAP']\n",
    "\n",
    "# Drop the 'xx' column from the metadata (if it exists)\n",
    "df_metadata = df_metadata.drop(columns=['individualID', 'race', 'spanish'], errors='ignore')\n",
    "\n",
    "# Merge the metadata with the gene expression data based on the SpecimenID and index\n",
    "df_merged = df_features.merge(df_metadata, left_on=df_features.index, right_on='specimenID', how='left')\n",
    "\n",
    "# Select the 'diagnosis' column as the target variable 'y'\n",
    "y = df_merged['diagnosis']\n",
    "\n",
    "# Drop the target variable from the merged dataframe to get the features 'X'\n",
    "X = df_merged.drop(columns=['diagnosis', 'specimenID', 'study', 'ethnicity'])\n",
    "\n",
    "# Create a new dataframe combining features and target\n",
    "df = pd.concat([X, y.rename('target')], axis=1)\n",
    "\n",
    "# Check the target distribution\n",
    "print(df['target'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f9fe0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train test split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Check the number of records\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of records in the training dataset is\u001b[39m\u001b[38;5;124m'\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Check the number of records\n",
    "print('The number of records in the training dataset is', X_train.shape[0])\n",
    "print('The number of records in the test dataset is', X_test.shape[0])\n",
    "print(f\"The training dataset has {sorted(Counter(y_train).items())[0][1]} records for the majority class and {sorted(Counter(y_train).items())[1][1]} records for the minority class.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the random forest model (without clincial)\n",
    "rf = RandomForestClassifier()\n",
    "baseline_model = rf.fit(X_train, y_train)\n",
    "baseline_prediction = baseline_model.predict(X_test)\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, baseline_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339986f5",
   "metadata": {},
   "source": [
    "# ML model (RF) -- baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9b761",
   "metadata": {},
   "source": [
    "## Baseline RF for comparison (w cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea63e8",
   "metadata": {},
   "source": [
    "### 1. Without clinical vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42b05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the modeling dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Model and performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and metadata\n",
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v7.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44e32d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique indices: 1230\n"
     ]
    }
   ],
   "source": [
    "num_unique_indices = df_features.index.nunique()\n",
    "print(\"Number of unique indices:\", num_unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352f24c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata_v6_rosmap.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# This seems to be the same as dataset_path, double-check if this is correct\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(metadata_path, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_metadata\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "metadata_path = 'metadata_v6_rosmap.csv'  # This seems to be the same as dataset_path, double-check if this is correct\n",
    "df_metadata = pd.read_csv(metadata_path, index_col=0)\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e91ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['individualID', 'diagnosis', 'tissue', 'race', 'spanish',\n",
       "       'apoe4_allele', 'sex', 'batch', 'pmi', 'RIN', 'RIN2', 'age_death',\n",
       "       'AlignmentSummaryMetrics_PCT_PF_READS_ALIGNED',\n",
       "       'RnaSeqMetrics_PCT_INTRONIC_BASES',\n",
       "       'RnaSeqMetrics_PCT_INTERGENIC_BASES', 'RnaSeqMetrics_PCT_CODING_BASES',\n",
       "       'ethnicity', 'study'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffc74df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique indices: 1230\n"
     ]
    }
   ],
   "source": [
    "num_unique_indices = df_metadata.index.nunique()\n",
    "print(\"Number of unique indices:\", num_unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d3d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e19474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Select features and target\n",
    "X = df_features\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "# Create a new dataframe combining features and target\n",
    "df = pd.concat([X, y.rename('target')], axis=1)\n",
    "\n",
    "# Check the target distribution\n",
    "print(df['target'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5873491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV recall: 0.760946589106293\n",
      "\n",
      "Mean CV f1: 0.8105418223415881\n",
      "\n",
      "Mean CV accuracy: 0.8203252032520325\n",
      "\n",
      "Mean CV precision: 0.8770813086178112\n",
      "\n",
      "Mean CV roc_auc: 0.9327868852459016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without any clinical\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Initialize the random forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the metrics to use\n",
    "scoring_metrics = ['recall', 'f1', 'accuracy', 'precision', 'roc_auc']\n",
    "\n",
    "# Perform 4-fold cross-validation with multiple metrics\n",
    "cv_results = cross_validate(rf, X, y, cv=10, scoring=scoring_metrics)\n",
    "\n",
    "# Print the cross-validation results for each metric\n",
    "for metric in scoring_metrics:\n",
    "    #print(f\"10-fold CV {metric}: {cv_results['test_' + metric]}\")\n",
    "    print(f\"Mean CV {metric}: {cv_results['test_' + metric].mean()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b793c5d",
   "metadata": {},
   "source": [
    "### 2. With clinical vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "854b3e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### With clinical variables\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the gene expression data\n",
    "dataset_path = 'ROSMAP_counts_v6.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file\n",
    "metadata_path = 'metadata_v6_rosmap.csv'\n",
    "df_metadata = pd.read_csv(metadata_path, index_col=0)\n",
    "\n",
    "\n",
    "# Drop the 'xx' column from the metadata (if it exists)\n",
    "df_metadata = df_metadata.drop(columns=['individualID', 'race', 'spanish', 'pmi', \"RIN\", 'study', 'ethnicity','AlignmentSummaryMetrics_PCT_PF_READS_ALIGNED',\n",
    "       'RnaSeqMetrics_PCT_INTRONIC_BASES',\n",
    "       'RnaSeqMetrics_PCT_INTERGENIC_BASES', 'RnaSeqMetrics_PCT_CODING_BASES',\n",
    "       'ethnicity', 'study'], errors='ignore')\n",
    "\n",
    "# Merge the metadata with the gene expression data based on the SpecimenID and index\n",
    "df_merged = df_features.merge(df_metadata, left_on=df_features.index, right_on='specimenID', how='left')\n",
    "\n",
    "# Select the 'diagnosis' column as the target variable 'y'\n",
    "y = df_merged['diagnosis']\n",
    "\n",
    "# Drop the target variable from the merged dataframe to get the features 'X'\n",
    "X = df_merged.drop(columns=['diagnosis', 'specimenID'])\n",
    "\n",
    "# Create a new dataframe combining features and target\n",
    "df = pd.concat([X, y.rename('target')], axis=1)\n",
    "\n",
    "# Check the target distribution\n",
    "print(df['target'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa1e8378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV recall: 0.7690375462718138\n",
      "\n",
      "Mean CV f1: 0.8200242502359938\n",
      "\n",
      "Mean CV accuracy: 0.8308943089430894\n",
      "\n",
      "Mean CV precision: 0.8877675229370962\n",
      "\n",
      "Mean CV roc_auc: 0.934690639873083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### With clinical variables\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Initialize the random forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the metrics to use\n",
    "scoring_metrics = ['recall', 'f1', 'accuracy', 'precision', 'roc_auc']\n",
    "\n",
    "# Perform 4-fold cross-validation with multiple metrics\n",
    "cv_results = cross_validate(rf, X, y, cv=10, scoring=scoring_metrics)\n",
    "\n",
    "# Print the cross-validation results for each metric\n",
    "for metric in scoring_metrics:\n",
    "    #print(f\"10-fold CV {metric}: {cv_results['test_' + metric]}\")\n",
    "    print(f\"Mean CV {metric}: {cv_results['test_' + metric].mean()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed486ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89831764",
   "metadata": {},
   "source": [
    "### Improvement of baseline RF (Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3e513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa095c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50329925",
   "metadata": {},
   "source": [
    "## Creating small dataset for test (10 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f783d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v6.csv'\n",
    "df = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Select the first 5 rows\n",
    "first_five = df.head(6)\n",
    "last_five = df.tail(6)\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "concatenated_main_df = pd.concat([first_five, last_five])\n",
    "\n",
    "df_diagnosis = pd.read_csv('metadata_v6_rosmap.csv', index_col=0)\n",
    "\n",
    "# Select the first 5 rows and the last 5 rows of the 'diagnosis' column\n",
    "first_five_diagnosis = df_diagnosis[['diagnosis']].head(6)\n",
    "last_five_diagnosis = df_diagnosis[['diagnosis']].tail(6)\n",
    "\n",
    "# Concatenate the two subsets from the diagnosis DataFrame\n",
    "concatenated_diagnosis_df = pd.concat([first_five_diagnosis, last_five_diagnosis])\n",
    "\n",
    "# Combine the subsets from the main and diagnosis DataFrames\n",
    "# Make sure to reset the index to allow proper horizontal concatenation\n",
    "final_df = pd.concat([concatenated_main_df.reset_index(drop=True), \n",
    "                      concatenated_diagnosis_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# Export the new DataFrame to a CSV file\n",
    "final_df.to_csv('test_11samples_v6.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_11samples_v6.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1a5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17a918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5738bc6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e468b9",
   "metadata": {},
   "source": [
    "# RF, Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b1d6d",
   "metadata": {},
   "source": [
    "## First try on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0a2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('test_11samples_v6.csv', index_col=0)\n",
    "y = dataset['diagnosis']\n",
    "X = dataset.drop('diagnosis', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cec136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Fold Number: 0\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 1\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 2\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 3\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 4\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 5\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 6\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 7\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 8\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 9\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 10\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 11\n",
      "Correctly Classified: True\n"
     ]
    }
   ],
   "source": [
    "# First try\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)  # Reproducibility\n",
    "\n",
    "shap_values_per_sample = dict()\n",
    "CV = LeaveOneOut()\n",
    "\n",
    "for fold_num, (train_ix, test_ix) in enumerate(CV.split(X)):\n",
    "    print('\\n------ Fold Number:', fold_num)\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    fit = model.fit(X_train, y_train)\n",
    "    y_pred = fit.predict(X_test)\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    shap_values_per_sample[test_ix[0]] = {'correct': correct, 'label': y_test.iloc[0], 'shap_values': shap_values[1] if y_pred[0] == 1 else shap_values[0]}\n",
    "\n",
    "    print('Correctly Classified:', correct)\n",
    "\n",
    "# Filter the dictionary for correctly classified samples\n",
    "# correct_shap_values = {sample: info for sample, info in shap_values_per_sample.items() if info['correct']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "621c2f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(shap_values_per_sample[1]['shap_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40f81829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero SHAP values and their indices: [(710, -0.007272727272727273), (1059, 0.004545454545454546), (1144, 0.004545454545454546), (1471, 0.0018181818181818177), (1603, 0.004545454545454546), (1608, 0.002727272727272727), (2072, 0.0009090909090909094), (2141, -0.008181818181818182), (2160, 0.0009090909090909094), (2347, 0.0036363636363636364), (2419, 0.0036363636363636364), (2492, -0.008181818181818182), (2556, -0.008181818181818182), (2739, -0.0004545454545454545), (2860, 0.005454545454545454), (2901, -0.007272727272727273), (3091, 0.0018181818181818177), (3317, -0.007272727272727273), (3392, -0.007272727272727273), (3584, -0.008181818181818182), (3657, 0.005818181818181819), (3774, 0.004545454545454546), (4146, -0.008181818181818182), (4202, 0.002727272727272727), (5101, 0.004545454545454546), (5171, -0.007272727272727273), (5217, 0.0036363636363636364), (5405, -0.005454545454545454), (5431, -0.006363636363636364), (5630, 0.002727272727272727), (5713, 0.006363636363636364), (5980, -0.006363636363636364), (6096, 0.0018181818181818177), (6285, 0.002727272727272727), (6587, 0.0036363636363636364), (7021, 0.0036363636363636364), (7133, 0.004545454545454546), (7241, -0.005454545454545454), (7588, -0.006363636363636364), (7840, 0.0018181818181818177), (8148, 0.0036363636363636364), (8323, -0.008181818181818182), (8403, 0.0009090909090909094), (8439, 0.004545454545454546), (8628, -0.007272727272727273), (8708, -0.006363636363636364), (8986, -0.008181818181818182), (9022, 0.0036363636363636364), (9932, 0.0036363636363636364), (10240, 0.0036363636363636364), (10406, 0.0009090909090909094), (10456, 0.0018181818181818177), (10512, 0.004545454545454546), (10754, 0.002727272727272727), (11031, 0.0036363636363636364), (11036, 0.002727272727272727), (11200, 0.002727272727272727), (11429, -0.006363636363636364), (11856, 0.0022727272727272726), (11959, -0.005454545454545454), (12021, 0.0036363636363636364), (12118, -0.006363636363636364), (12341, -0.006363636363636364), (12417, -0.002386363636363637), (12419, 0.0018181818181818177), (12604, 0.0018181818181818177), (12678, 0.0036363636363636364), (12744, -0.008181818181818182), (12759, -0.008181818181818182), (13011, 0.002727272727272727), (13153, -0.007272727272727273), (13292, -0.005454545454545454), (13357, -0.005454545454545454), (13696, 0.0018181818181818177), (13700, 0.0009090909090909094), (13818, 0.006931818181818181), (14069, 0.0018181818181818177), (14176, -0.006363636363636364), (14195, -0.007272727272727273), (14246, 0.0036363636363636364), (14426, -0.005454545454545454), (14589, -0.008181818181818182), (15013, 0.0018181818181818177), (15230, -0.0021818181818181815), (15310, 0.002727272727272727), (15495, -0.006363636363636364), (15566, 0.002727272727272727), (15887, 0.0018181818181818177), (15915, -0.005454545454545454), (15961, 0.004545454545454546), (16153, 0.002727272727272727), (16168, -0.004545454545454545), (16601, 0.0009090909090909094), (16615, 0.0018181818181818177), (16757, 0.0018181818181818177), (16760, 0.002727272727272727), (16839, 0.002727272727272727)]\n"
     ]
    }
   ],
   "source": [
    "sample_index = 3\n",
    "shap_values_for_sample = shap_values_per_sample[sample_index]['shap_values']\n",
    "\n",
    "# Find non-zero SHAP values and their indices\n",
    "if shap_values_for_sample is not None:\n",
    "    non_zero_shap_values = [(index, value) for index, value in enumerate(shap_values_for_sample[0]) if value != 0]\n",
    "    print(\"Non-zero SHAP values and their indices:\", non_zero_shap_values)\n",
    "else:\n",
    "    print(\"SHAP values are None for this sample.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd4736c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "print(len(non_zero_shap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac782fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of features with the largest SHAP values: [12759  3584  4146  2141  2492 12744  2556  8323  8986 14589  8628  3317\n",
      "  5171  2901 14195   710  3392 13153 13818  8708  5713 12118  5980 11429\n",
      " 12341  7588 15495  5431 14176  3657 15915  7241 13292 14426  2860  5405\n",
      " 13357 11959 15961  1059  8439  1144  3774  7133 10512  1603  5101 16168\n",
      "  9022  9932 12021 12678  8148 14246  2347  2419  5217 10240  6587  7021\n",
      " 11031 16839 15566  1608  6285  4202  5630 11036 16760 11200 16153 15310\n",
      " 10754 13011 12417 11856 15230 16615  3091 15013 12604  7840 12419  6096\n",
      "  1471 15887 10456 14069 13696 16757 13700 10406  2160 16601  2072  8403\n",
      "  2739 11335 11333 11334]\n"
     ]
    }
   ],
   "source": [
    "sample_index = 3\n",
    "shap_values_for_sample = shap_values_per_sample[sample_index]['shap_values']\n",
    "\n",
    "# Find indices of features with the largest SHAP values\n",
    "if shap_values_for_sample is not None:\n",
    "    # Get absolute values of SHAP values\n",
    "    abs_shap_values = np.abs(shap_values_for_sample[0])\n",
    "\n",
    "    # Find the indices of the features with the largest SHAP values\n",
    "    largest_shap_indices = np.argsort(-abs_shap_values)[:100]  # Change 20 to the number of features you want\n",
    "\n",
    "    print(\"Indices of features with the largest SHAP values:\", largest_shap_indices)\n",
    "else:\n",
    "    print(\"SHAP values are None for this sample.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9528307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3552d0f",
   "metadata": {},
   "source": [
    "#### With accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49819a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('test_11samples_v6.csv', index_col=0)\n",
    "y = dataset['diagnosis']\n",
    "X = dataset.drop('diagnosis', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e890b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Fold Number: 0\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 1\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 2\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 3\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 4\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 5\n",
      "Correctly Classified: False\n",
      "\n",
      "------ Fold Number: 6\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 7\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 8\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 9\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 10\n",
      "Correctly Classified: True\n",
      "\n",
      "------ Fold Number: 11\n",
      "Correctly Classified: True\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.73      0.89      0.80         9\n",
      "          AD       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.36      0.44      0.40        12\n",
      "weighted avg       0.55      0.67      0.60        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import classification_report\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)  # Reproducibility\n",
    "\n",
    "shap_values_per_sample = dict()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "CV = LeaveOneOut()\n",
    "\n",
    "for fold_num, (train_ix, test_ix) in enumerate(CV.split(X)):\n",
    "    print('\\n------ Fold Number:', fold_num)\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    fit = model.fit(X_train, y_train)\n",
    "    y_pred = fit.predict(X_test)\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    shap_values_per_sample[test_ix[0]] = {'correct': correct, 'label': y_test.iloc[0], 'shap_values': shap_values[1] if y_pred[0] == 1 else shap_values[0]}\n",
    "    true_labels.append(y_test.iloc[0])\n",
    "    predicted_labels.append(y_pred[0])\n",
    "\n",
    "    print('Correctly Classified:', correct)\n",
    "\n",
    "# Print classification report\n",
    "print()\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Control', 'AD'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478ec95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "352d8d39",
   "metadata": {},
   "source": [
    "#### With predictive score for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64aba709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('test_11samples_v6.csv', index_col=0)\n",
    "y = dataset['diagnosis']\n",
    "X = dataset.drop('diagnosis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68718815",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v6.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('metadata_v6_rosmap.csv', index_col=0)\n",
    "y = metadata[['diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a52604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specimenID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487_120515</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182_120424</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193_120424</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694_120605</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366_120502</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_R3633816-DLPFC_generated_275</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_R4841941-AC_generated_276</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152_120419_generated_277</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_R9598418-AC_generated_278</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174_120424_generated_279</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     diagnosis\n",
       "specimenID                                    \n",
       "487_120515                                   0\n",
       "182_120424                                   0\n",
       "193_120424                                   1\n",
       "694_120605                                   0\n",
       "366_120502                                   1\n",
       "...                                        ...\n",
       "Sample_R3633816-DLPFC_generated_275          0\n",
       "Sample_R4841941-AC_generated_276             0\n",
       "152_120419_generated_277                     0\n",
       "Sample_R9598418-AC_generated_278             0\n",
       "174_120424_generated_279                     0\n",
       "\n",
       "[1230 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f77e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold Number: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_ix], y\u001b[38;5;241m.\u001b[39miloc[test_ix]\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to 1D array\u001b[39;00m\n\u001b[1;32m     31\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     32\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get the probability estimates for each class\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Modified\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import classification_report\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v6.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('metadata_v6_rosmap.csv', index_col=0)\n",
    "y = metadata['diagnosis']  # Convert to 1D array\n",
    "\n",
    "\n",
    "np.random.seed(1)  # Reproducibility\n",
    "\n",
    "shap_values_per_sample = dict()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "CV = LeaveOneOut()\n",
    "\n",
    "for fold_num, (train_ix, test_ix) in enumerate(CV.split(X)):\n",
    "    print('--- Fold Number:', fold_num)\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    fit = model.fit(X_train, y_train.ravel())  # Convert to 1D array\n",
    "    y_pred = fit.predict(X_test)\n",
    "    y_proba = fit.predict_proba(X_test)[0]  # Get the probability estimates for each class\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    shap_values_per_sample[test_ix[0]] = {\n",
    "        'correct': correct,\n",
    "        'label': y_test.iloc[0],\n",
    "        'shap_values': shap_values[1] if y_pred[0] == 1 else shap_values[0],\n",
    "        'predictive_score': y_proba[1]  # Probability estimate for the positive class (AD)\n",
    "    }\n",
    "    true_labels.append(y_test.iloc[0])\n",
    "    predicted_labels.append(y_pred[0])\n",
    "\n",
    "    #print('Correctly Classified:', correct)\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Control', 'AD'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a6a434f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': True,\n",
       " 'label': 0,\n",
       " 'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'predictive_score': 0.35}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values_per_sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d274e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b4926ee",
   "metadata": {},
   "source": [
    "#### Optimizing the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f14153",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v7.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('metadata_v6_rosmap.csv', index_col=0)\n",
    "y = metadata['diagnosis']  # Convert to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Create a precision scorer\n",
    "precision_scorer = make_scorer(precision_score, pos_label=1)\n",
    "\n",
    "# Set up the random search with 5-fold cross-validation and 100 iterations\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, scoring=precision_scorer, cv=5, n_iter=100, verbose=2, n_jobs=3, random_state=1)\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best precision score\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best precision score:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0ea6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfb1ef48",
   "metadata": {},
   "source": [
    "## Final RF model and SHAP on large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce0d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'ROSMAP_counts_v9_13k_SMOTE.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0).reset_index(drop=True)\n",
    "\n",
    "metadata = pd.read_csv('metadata_v9_rosmap_SMOTE.csv', index_col=0).reset_index(drop=True)\n",
    "y = metadata['diagnosis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1eb23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      diagnosis\n",
       "0             0\n",
       "1             0\n",
       "2             1\n",
       "3             0\n",
       "4             1\n",
       "...         ...\n",
       "1225          0\n",
       "1226          0\n",
       "1227          0\n",
       "1228          0\n",
       "1229          0\n",
       "\n",
       "[1230 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84886bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a6942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "178110f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v7.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9602bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4b32f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold Number: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Apply the best hyperparameters\u001b[39;00m\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m     28\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     29\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to 1D array\u001b[39;00m\n\u001b[1;32m     35\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     36\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get the probability estimates for each class\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import classification_report\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v7.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('/home/vmottaqi/rnaseq_synapse/metadata_v6_rosmap.csv', index_col=0)\n",
    "y = metadata['diagnosis']  # Convert to 1D array\n",
    "\n",
    "np.random.seed(1)  # Reproducibility\n",
    "\n",
    "shap_values_per_sample = dict()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "CV = LeaveOneOut()\n",
    "\n",
    "for fold_num, (train_ix, test_ix) in enumerate(CV.split(X)):\n",
    "    print('--- Fold Number:', fold_num)\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    # Apply the best hyperparameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=20,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=1\n",
    "    )\n",
    "    fit = model.fit(X_train, y_train.ravel())  # Convert to 1D array\n",
    "    y_pred = fit.predict(X_test)\n",
    "    y_proba = fit.predict_proba(X_test)[0]  # Get the probability estimates for each class\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    shap_values_per_sample[test_ix[0]] = {\n",
    "        'correct': correct,\n",
    "        'label': y_test.iloc[0],\n",
    "        'shap_values': shap_values[1] if y_pred[0] == 1 else shap_values[0],\n",
    "        'predictive_score': y_proba[1]  # Probability estimate for the positive class (AD)\n",
    "    }\n",
    "    true_labels.append(y_test.iloc[0])\n",
    "    predicted_labels.append(y_pred[0])\n",
    "\n",
    "    #print('Correctly Classified:', correct)\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Control', 'AD'])\n",
    "print(report)\n",
    "\n",
    "\n",
    "with open('shap_values_per_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values_per_sample, f)\n",
    "\n",
    "print('SHAP values dictionary saved to shap_values_per_sample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe4a17",
   "metadata": {},
   "source": [
    "### W parallelization (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd1de524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 0 completed\n",
      "Fold number 1 completed\n",
      "Fold number 2 completed\n",
      "Fold number 4 completed\n",
      "Fold number 3 completed\n",
      "Fold number 5 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m CV \u001b[38;5;241m=\u001b[39m LeaveOneOut()\n\u001b[0;32m---> 48\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m shap_values_per_sample \u001b[38;5;241m=\u001b[39m {result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_num\u001b[39m\u001b[38;5;124m'\u001b[39m]: result \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results}\n\u001b[1;32m     51\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m [result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mcf7/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import classification_report\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_fold(train_ix, test_ix, X, y):\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=6,\n",
    "        random_state=1\n",
    "    )\n",
    "    fit = model.fit(X_train, y_train.ravel())\n",
    "    y_pred = fit.predict(X_test)\n",
    "    y_proba = fit.predict_proba(X_test)[0]\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    print('Fold number {} completed'.format(test_ix[0]))  # Print the completed fold number\n",
    "\n",
    "    return {\n",
    "        'fold_num': test_ix[0],\n",
    "        'correct': correct,\n",
    "        'label': y_test.iloc[0],  # Keeping only 'label' for the true label\n",
    "        'shap_values': shap_values[1] if y_pred[0] == 1 else shap_values[0],\n",
    "        'predictive_score': y_proba[1],\n",
    "        'predicted_label': y_pred[0]\n",
    "    }\n",
    "\n",
    "dataset_path = '/home/vmottaqi/rnaseq_synapse/ROSMAP_counts_v7_9k.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "metadata = pd.read_csv('metadata_v6_rosmap.csv', index_col=0)\n",
    "y = metadata['diagnosis']\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "CV = LeaveOneOut()\n",
    "results = Parallel(n_jobs=4)(delayed(process_fold)(train_ix, test_ix, X, y) for train_ix, test_ix in CV.split(X))\n",
    "\n",
    "shap_values_per_sample = {result['fold_num']: result for result in results}\n",
    "true_labels = [result['label'] for result in results]\n",
    "predicted_labels = [result['predicted_label'] for result in results]\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Control', 'AD'])\n",
    "print(report)\n",
    "\n",
    "with open('shap_values_9_9k.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values_per_sample, f)\n",
    "\n",
    "print('SHAP values dictionary saved to shap_values_9.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on original dataset (13k genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d3c4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'ROSMAP_counts_v8_original_13k.csv'\n",
    "df_features = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Load the metadata file with the 'sex' column\n",
    "metadata_path = './metadata_v3.csv'\n",
    "df_metadat = pd.read_csv(metadata_path)\n",
    "df_metadata = df_metadat[(df_metadat['study'] == 'ROSMAP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae40c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import classification_report\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_fold(train_ix, test_ix, X, y):\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    fit = model.fit(X_train, y_train.ravel())\n",
    "    y_pred = fit.predict(X_test)\n",
    "    y_proba = fit.predict_proba(X_test)[0]\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    print('Fold number {} completed'.format(test_ix[0]))  # Print the completed fold number\n",
    "\n",
    "    return {\n",
    "        'fold_num': test_ix[0],\n",
    "        'correct': correct,\n",
    "        'label': y_test.iloc[0],  # Keeping only 'label' for the true label\n",
    "        'shap_values': shap_values[1] if y_pred[0] == 1 else shap_values[0],\n",
    "        'predictive_score': y_proba[1],\n",
    "        'predicted_label': y_pred[0]\n",
    "    }\n",
    "\n",
    "\n",
    "dataset_path = 'ROSMAP_counts_v8_original_13k.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('./metadata_v3.csv', index_col=0)\n",
    "df_metadata = metadata[(metadata['study'] == 'ROSMAP')]\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "CV = LeaveOneOut()\n",
    "results = Parallel(n_jobs=4)(delayed(process_fold)(train_ix, test_ix, X, y) for train_ix, test_ix in CV.split(X))\n",
    "\n",
    "shap_values_per_sample = {result['fold_num']: result for result in results}\n",
    "true_labels = [result['label'] for result in results]\n",
    "predicted_labels = [result['predicted_label'] for result in results]\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Control', 'AD'])\n",
    "print(report)\n",
    "\n",
    "with open('shap_values_10_orginal_13k.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values_per_sample, f)\n",
    "\n",
    "print('SHAP values dictionary saved to shap_values_9.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92819d",
   "metadata": {},
   "source": [
    "## Revised code (1) for imbalanced data (March 22/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fff941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "def process_fold(train_ix, test_ix, X, y):\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=6,\n",
    "        random_state=1,\n",
    "        class_weight='balanced')  # Adjusting for class imbalance\n",
    "    fit = model.fit(X_train, y_train.ravel())\n",
    "    y_pred = fit.predict(X_test)\n",
    "    y_proba = fit.predict_proba(X_test)[0]\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Collecting the SHAP values for the predicted class\n",
    "    relevant_shap_values = shap_values[1] if y_pred[0] == 1 else shap_values[0]\n",
    "\n",
    "    print(f'Fold number {test_ix[0]} completed')  # Print the completed fold number\n",
    "    return {\n",
    "        'fold_num': test_ix[0],\n",
    "        'correct': correct,\n",
    "        'label': y_test.iloc[0],\n",
    "        'shap_values': {X.columns[i]: relevant_shap_values[0][i] for i in range(len(X.columns))},  # SHAP values for each feature\n",
    "        'predictive_score': y_proba[1] if y_pred[0] == 1 else y_proba[0],  # Predictive score for the test sample\n",
    "        'predicted_label': y_pred[0]\n",
    "    }\n",
    "\n",
    "dataset_path = 'ROSMAP_counts_v8_original_13k.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('./metadata_v3.csv', index_col=0)\n",
    "df_metadata = metadata[(metadata['study'] == 'ROSMAP')]\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "loo = LeaveOneOut()\n",
    "results = Parallel(n_jobs=6)(delayed(process_fold)(train_ix, test_ix, X, y) for train_ix, test_ix in loo.split(X))\n",
    "\n",
    "# Calculate overall model performance\n",
    "y_true = [result['label'] for result in results]\n",
    "y_pred = [result['predicted_label'] for result in results]\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Overall model accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['Control', 'AD'])\n",
    "print(report)\n",
    "\n",
    "# Save SHAP values dictionary\n",
    "shap_values_per_sample = {result['fold_num']: result for result in results}\n",
    "with open('shap_values_11_orginal_13k.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values_per_sample, f)\n",
    "print('SHAP values dictionary saved to shap_values_10_orginal_13k.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef831f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bca214f0",
   "metadata": {},
   "source": [
    "# SHAPley values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5dbe50",
   "metadata": {},
   "source": [
    "## Checking the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8636a624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "specimenID\n",
       "487_120515                             0\n",
       "182_120424                             0\n",
       "193_120424                             1\n",
       "694_120605                             0\n",
       "366_120502                             1\n",
       "                                      ..\n",
       "Sample_R3633816-DLPFC_generated_275    0\n",
       "Sample_R4841941-AC_generated_276       0\n",
       "152_120419_generated_277               0\n",
       "Sample_R9598418-AC_generated_278       0\n",
       "174_120424_generated_279               0\n",
       "Name: diagnosis, Length: 1230, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('metadata_v6_rosmap.csv', index_col=0)\n",
    "y = metadata['diagnosis']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf36603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values dictionary loaded from shap_values_per_sample.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('shap_values_8_11k.pkl', 'rb') as f:\n",
    "    loaded_shap_values = pickle.load(f)\n",
    "\n",
    "print('SHAP values dictionary loaded from shap_values_per_sample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df54d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'fold_num': 0,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.16834119e-05, -3.61013854e-05,  9.94698850e-06, ...,\n",
       "           0.00000000e+00,  2.67243450e-05,  1.17824741e-05]]),\n",
       "  'predictive_score': 0.4422454889881361,\n",
       "  'predicted_label': 0},\n",
       " 1: {'fold_num': 1,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.16834119e-05, -6.57685815e-05, -4.59969513e-04, ...,\n",
       "           0.00000000e+00,  6.56649578e-05,  3.63478134e-05]]),\n",
       "  'predictive_score': 0.055286061161061155,\n",
       "  'predicted_label': 0},\n",
       " 2: {'fold_num': 2,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.16834119e-05, -4.02565876e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.96994873e-05,  2.60885802e-05]]),\n",
       "  'predictive_score': 0.4806438908313908,\n",
       "  'predicted_label': 0},\n",
       " 3: {'fold_num': 3,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.41353774e-05,  3.69217567e-04, -1.48455652e-05, ...,\n",
       "          -1.94926487e-05, -1.96994873e-05,  8.24053949e-05]]),\n",
       "  'predictive_score': 0.4500970719167314,\n",
       "  'predicted_label': 0},\n",
       " 4: {'fold_num': 4,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.45638526e-04, -2.83018789e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  2.71130376e-04, -8.24053949e-05]]),\n",
       "  'predictive_score': 0.7260821873671935,\n",
       "  'predicted_label': 1},\n",
       " 5: {'fold_num': 5,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.41921315e-04,  0.00000000e+00, -9.90054536e-05, ...,\n",
       "           0.00000000e+00,  1.50711096e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7779446059401556,\n",
       "  'predicted_label': 1},\n",
       " 6: {'fold_num': 6,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.11188819e-05,  0.00000000e+00,  3.03841374e-05, ...,\n",
       "           0.00000000e+00, -4.09912805e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.9061329075336431,\n",
       "  'predicted_label': 1},\n",
       " 7: {'fold_num': 7,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.16834119e-05,  2.87432664e-06,  9.70270458e-06, ...,\n",
       "           2.12191323e-05,  1.84851021e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.619712098359157,\n",
       "  'predicted_label': 1},\n",
       " 8: {'fold_num': 8,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.16834119e-05,  1.35030678e-05, -1.48499803e-05, ...,\n",
       "           0.00000000e+00, -2.76563056e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.45187362637362627,\n",
       "  'predicted_label': 0},\n",
       " 9: {'fold_num': 9,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "           0.0000000e+00, -1.7681157e-05,  0.0000000e+00]]),\n",
       "  'predictive_score': 0.39501507475900055,\n",
       "  'predicted_label': 0},\n",
       " 10: {'fold_num': 10,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -3.71666789e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.47024172076203824,\n",
       "  'predicted_label': 0},\n",
       " 11: {'fold_num': 11,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.71293514e-06, ...,\n",
       "           0.00000000e+00, -1.83169899e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.26596879601736406,\n",
       "  'predicted_label': 0},\n",
       " 12: {'fold_num': 12,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.67464816e-05,  0.00000000e+00, -1.46191132e-05, ...,\n",
       "           0.00000000e+00, -1.96743660e-05,  1.12929101e-05]]),\n",
       "  'predictive_score': 0.4472716846062434,\n",
       "  'predicted_label': 0},\n",
       " 13: {'fold_num': 13,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.54107837e-05, -1.01085542e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  3.29288348e-05, -1.79848419e-05]]),\n",
       "  'predictive_score': 0.6749782603447463,\n",
       "  'predicted_label': 1},\n",
       " 14: {'fold_num': 14,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.40881838e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.864865628652393,\n",
       "  'predicted_label': 1},\n",
       " 15: {'fold_num': 15,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.33906510e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  5.38181004e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5994220757312865,\n",
       "  'predicted_label': 1},\n",
       " 16: {'fold_num': 16,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.64276240e-06,  0.00000000e+00, -2.08694909e-06, ...,\n",
       "           0.00000000e+00, -1.43421696e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8942874702052331,\n",
       "  'predicted_label': 1},\n",
       " 17: {'fold_num': 17,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.08445216e-05,  3.29368251e-06, ...,\n",
       "           0.00000000e+00,  2.64908769e-04,  1.10281807e-06]]),\n",
       "  'predictive_score': 0.4236473885591532,\n",
       "  'predicted_label': 0},\n",
       " 18: {'fold_num': 18,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.23894959e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  2.64359641e-05]]),\n",
       "  'predictive_score': 0.45156460877331794,\n",
       "  'predicted_label': 0},\n",
       " 19: {'fold_num': 19,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.20033231e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.71966199e-05]]),\n",
       "  'predictive_score': 0.7154100256039109,\n",
       "  'predicted_label': 1},\n",
       " 20: {'fold_num': 20,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.87360794e-06,  0.00000000e+00, -5.53580699e-06, ...,\n",
       "           2.03937824e-05,  5.11002482e-05,  1.32645989e-05]]),\n",
       "  'predictive_score': 0.10864902662696782,\n",
       "  'predicted_label': 0},\n",
       " 21: {'fold_num': 21,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.62254402e-06, ...,\n",
       "           0.00000000e+00,  1.15364098e-05,  9.08417428e-07]]),\n",
       "  'predictive_score': 0.4946073113977526,\n",
       "  'predicted_label': 0},\n",
       " 22: {'fold_num': 22,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -6.98820018e-05, ...,\n",
       "          -8.42236597e-06, -6.67342350e-06, -7.50567997e-07]]),\n",
       "  'predictive_score': 0.6949182984198462,\n",
       "  'predicted_label': 1},\n",
       " 23: {'fold_num': 23,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.39842033e-06, ...,\n",
       "          -2.08118587e-05, -2.16474524e-05,  5.91195410e-05]]),\n",
       "  'predictive_score': 0.5321186297362768,\n",
       "  'predicted_label': 1},\n",
       " 24: {'fold_num': 24,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.03950471e-05,  0.00000000e+00,  3.01228070e-05, ...,\n",
       "          -2.10365699e-05,  0.00000000e+00, -1.06466369e-04]]),\n",
       "  'predictive_score': 0.5542131329927382,\n",
       "  'predicted_label': 1},\n",
       " 25: {'fold_num': 25,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.24224348e-04,  0.00000000e+00, -4.55996079e-05, ...,\n",
       "           1.91614330e-05,  0.00000000e+00,  5.72051631e-05]]),\n",
       "  'predictive_score': 0.427040440338815,\n",
       "  'predicted_label': 0},\n",
       " 26: {'fold_num': 26,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.09412677e-04,  0.00000000e+00,  1.96925336e-06, ...,\n",
       "           6.11501885e-05,  0.00000000e+00,  6.72896506e-05]]),\n",
       "  'predictive_score': 0.20907131615940963,\n",
       "  'predicted_label': 0},\n",
       " 27: {'fold_num': 27,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.32322653e-05,  0.00000000e+00, -3.88191599e-06, ...,\n",
       "          -9.70661617e-06,  0.00000000e+00,  5.30782096e-05]]),\n",
       "  'predictive_score': 0.8257969232564819,\n",
       "  'predicted_label': 1},\n",
       " 28: {'fold_num': 28,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.55153572e-05,  0.00000000e+00,  4.32991545e-05, ...,\n",
       "          -2.72440725e-05,  0.00000000e+00,  1.30333173e-04]]),\n",
       "  'predictive_score': 0.707769783944126,\n",
       "  'predicted_label': 1},\n",
       " 29: {'fold_num': 29,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.78917493e-05,  0.00000000e+00,  3.85304237e-05, ...,\n",
       "           1.94705557e-06,  2.00971353e-06, -3.20367729e-05]]),\n",
       "  'predictive_score': 0.9122269891701008,\n",
       "  'predicted_label': 1},\n",
       " 30: {'fold_num': 30,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.83784008e-05,  0.00000000e+00, -8.47597583e-04, ...,\n",
       "          -2.61166439e-04, -2.92555782e-06, -3.19782936e-05]]),\n",
       "  'predictive_score': 0.6114057323395559,\n",
       "  'predicted_label': 1},\n",
       " 31: {'fold_num': 31,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.39354297e-05,  0.00000000e+00,  4.34334268e-05, ...,\n",
       "          -2.71441256e-04,  1.05043418e-06, -2.81743751e-05]]),\n",
       "  'predictive_score': 0.8395073145808442,\n",
       "  'predicted_label': 1},\n",
       " 32: {'fold_num': 32,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.93911464e-05,  0.00000000e+00, -5.53580699e-06, ...,\n",
       "           1.79419472e-05, -1.83210508e-06, -5.85776386e-06]]),\n",
       "  'predictive_score': 0.2583158597938009,\n",
       "  'predicted_label': 0},\n",
       " 33: {'fold_num': 33,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -8.25506766e-04, ...,\n",
       "          -5.75873606e-05,  3.26512797e-06, -1.30099572e-04]]),\n",
       "  'predictive_score': 0.5357650454121042,\n",
       "  'predicted_label': 1},\n",
       " 34: {'fold_num': 34,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.87452303e-04,  0.00000000e+00,  4.59886761e-05, ...,\n",
       "          -2.59389783e-04,  1.83056493e-06,  5.93446289e-05]]),\n",
       "  'predictive_score': 0.6892906015553073,\n",
       "  'predicted_label': 1},\n",
       " 35: {'fold_num': 35,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.62812736e-06, ...,\n",
       "          -1.11271382e-06,  2.45053767e-06,  4.28164198e-04]]),\n",
       "  'predictive_score': 0.19128381559960506,\n",
       "  'predicted_label': 0},\n",
       " 36: {'fold_num': 36,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.62812736e-06, ...,\n",
       "           9.94164615e-06, -1.05023043e-06,  2.45633654e-05]]),\n",
       "  'predictive_score': 0.31474074244468975,\n",
       "  'predicted_label': 0},\n",
       " 37: {'fold_num': 37,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  8.45893152e-06, ...,\n",
       "           5.27073460e-06, -1.16340045e-04, -3.83914072e-05]]),\n",
       "  'predictive_score': 0.912208374958375,\n",
       "  'predicted_label': 1},\n",
       " 38: {'fold_num': 38,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.63732089e-06, ...,\n",
       "          -7.05183372e-06,  8.77911948e-04,  3.51096777e-05]]),\n",
       "  'predictive_score': 0.46656423448412604,\n",
       "  'predicted_label': 0},\n",
       " 39: {'fold_num': 39,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.63732089e-06, ...,\n",
       "          -8.41922069e-07,  9.47822723e-06,  1.43774164e-05]]),\n",
       "  'predictive_score': 0.4396732544416371,\n",
       "  'predicted_label': 0},\n",
       " 40: {'fold_num': 40,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.78705856e-05, 6.08550174e-05, 9.63732089e-06, ...,\n",
       "          0.00000000e+00, 1.05023043e-06, 1.03014169e-04]]),\n",
       "  'predictive_score': 0.7853407838291737,\n",
       "  'predicted_label': 1},\n",
       " 41: {'fold_num': 41,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.19973474e-05,  3.69622501e-05,  1.43887768e-05, ...,\n",
       "           2.13739739e-06,  1.03200025e-05, -3.16055571e-05]]),\n",
       "  'predictive_score': 0.8145929122047542,\n",
       "  'predicted_label': 1},\n",
       " 42: {'fold_num': 42,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.42730280e-05,  0.00000000e+00, -5.54146030e-06, ...,\n",
       "          -8.41922069e-07, -8.96682874e-06,  1.02040325e-04]]),\n",
       "  'predictive_score': 0.3612110646061884,\n",
       "  'predicted_label': 0},\n",
       " 43: {'fold_num': 43,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.15551734e-05,  0.00000000e+00,  4.61155434e-05, ...,\n",
       "           5.28351885e-06, -2.45069549e-06,  1.14626333e-04]]),\n",
       "  'predictive_score': 0.8320679152718625,\n",
       "  'predicted_label': 1},\n",
       " 44: {'fold_num': 44,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.92160732e-05,  0.00000000e+00,  4.61155434e-05, ...,\n",
       "          -9.12830141e-06, -2.40501408e-05, -1.61899663e-05]]),\n",
       "  'predictive_score': 0.8726715380208028,\n",
       "  'predicted_label': 1},\n",
       " 45: {'fold_num': 45,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.74405304e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.54486915e-06,  2.45069549e-06,  1.43036474e-05]]),\n",
       "  'predictive_score': 0.4750035802690602,\n",
       "  'predicted_label': 0},\n",
       " 46: {'fold_num': 46,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.11305012e-06,  0.00000000e+00,  2.47825165e-05]]),\n",
       "  'predictive_score': 0.39934920475233776,\n",
       "  'predicted_label': 0},\n",
       " 47: {'fold_num': 47,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -7.79135083e-06,  0.00000000e+00, -9.68917734e-06]]),\n",
       "  'predictive_score': 0.579907597540918,\n",
       "  'predicted_label': 1},\n",
       " 48: {'fold_num': 48,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -7.63980660e-05, ...,\n",
       "           1.29507649e-06,  1.16842641e-05,  1.87577081e-06]]),\n",
       "  'predictive_score': 0.5692783658120342,\n",
       "  'predicted_label': 1},\n",
       " 49: {'fold_num': 49,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  7.66276259e-05, ...,\n",
       "          -8.41922069e-07,  0.00000000e+00, -6.84835009e-06]]),\n",
       "  'predictive_score': 0.3488489794519207,\n",
       "  'predicted_label': 0},\n",
       " 50: {'fold_num': 50,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.18506783e-05, ...,\n",
       "           1.11213415e-06,  6.75606284e-06, -5.43634928e-06]]),\n",
       "  'predictive_score': 0.5391253591180062,\n",
       "  'predicted_label': 1},\n",
       " 51: {'fold_num': 51,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  7.81242127e-05, -2.75231881e-05, ...,\n",
       "           1.95441331e-06,  1.70207982e-05,  8.92408890e-06]]),\n",
       "  'predictive_score': 0.8213741324035441,\n",
       "  'predicted_label': 1},\n",
       " 52: {'fold_num': 52,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.41357714e-05,  0.00000000e+00, ...,\n",
       "           5.29164552e-06,  5.85694737e-05, -1.14376712e-05]]),\n",
       "  'predictive_score': 0.8940313575313575,\n",
       "  'predicted_label': 1},\n",
       " 53: {'fold_num': 53,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.41357714e-05,  0.00000000e+00, ...,\n",
       "           6.20019923e-06,  5.85694737e-05,  8.92408890e-06]]),\n",
       "  'predictive_score': 0.8921528522002591,\n",
       "  'predicted_label': 1},\n",
       " 54: {'fold_num': 54,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.39705790e-04,  0.00000000e+00, ...,\n",
       "          -1.02176333e-06, -1.07280793e-05, -1.49539245e-05]]),\n",
       "  'predictive_score': 0.2028838620529798,\n",
       "  'predicted_label': 0},\n",
       " 55: {'fold_num': 55,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-5.06251539e-06,  2.81835022e-05,  0.00000000e+00, ...,\n",
       "           5.29810992e-06,  5.87637748e-05,  8.94742294e-06]]),\n",
       "  'predictive_score': 0.9021203405083046,\n",
       "  'predicted_label': 1},\n",
       " 56: {'fold_num': 56,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.61972883e-06, -1.29582456e-05,  0.00000000e+00, ...,\n",
       "           1.95611768e-06,  5.87637748e-05, -2.08773202e-05]]),\n",
       "  'predictive_score': 0.778779598261216,\n",
       "  'predicted_label': 1},\n",
       " 57: {'fold_num': 57,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.71954666e-05,  1.19412583e-05,  0.00000000e+00, ...,\n",
       "          -6.78058042e-07, -1.26249258e-05,  9.05079543e-06]]),\n",
       "  'predictive_score': 0.4402899657532011,\n",
       "  'predicted_label': 0},\n",
       " 58: {'fold_num': 58,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -4.02661446e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.26249258e-05,  1.12404810e-05]]),\n",
       "  'predictive_score': 0.2111981598767589,\n",
       "  'predicted_label': 0},\n",
       " 59: {'fold_num': 59,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 1.17327980e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.26249258e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.770000395845984,\n",
       "  'predicted_label': 1},\n",
       " 60: {'fold_num': 60,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 1.17327980e-05, 4.56870912e-05, ...,\n",
       "          0.00000000e+00, 1.26249258e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8220577759658643,\n",
       "  'predicted_label': 1},\n",
       " 61: {'fold_num': 61,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 2.14591450e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.26249258e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5174865355233002,\n",
       "  'predicted_label': 1},\n",
       " 62: {'fold_num': 62,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 1.29049108e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.84083657e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8459781793498897,\n",
       "  'predicted_label': 1},\n",
       " 63: {'fold_num': 63,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 3.15938497e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.81856898e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8786730426436309,\n",
       "  'predicted_label': 1},\n",
       " 64: {'fold_num': 64,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.52926155e-05, -9.67277318e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.44787424e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2025854901892054,\n",
       "  'predicted_label': 0},\n",
       " 65: {'fold_num': 65,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-5.45824084e-05,  1.28561270e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.69709272e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5813360034573269,\n",
       "  'predicted_label': 1},\n",
       " 66: {'fold_num': 66,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.45057010e-05, -3.15215610e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.44787424e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.37766779726551397,\n",
       "  'predicted_label': 0},\n",
       " 67: {'fold_num': 67,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.45057010e-05,  2.02398937e-05,  0.00000000e+00, ...,\n",
       "           1.66909306e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5932639786683905,\n",
       "  'predicted_label': 1},\n",
       " 68: {'fold_num': 68,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-9.05807121e-05,  2.03487190e-04,  0.00000000e+00, ...,\n",
       "          -1.66909306e-05, -4.10073107e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.41721453956690013,\n",
       "  'predicted_label': 0},\n",
       " 69: {'fold_num': 69,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.82748452e-05,  2.15194919e-04,  0.00000000e+00, ...,\n",
       "          -7.60163492e-06,  2.32861354e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3625621143562319,\n",
       "  'predicted_label': 0},\n",
       " 70: {'fold_num': 70,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.75962350e-06,  2.44292555e-05,  0.00000000e+00, ...,\n",
       "          -1.45598732e-05,  9.52642273e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.870338356088356,\n",
       "  'predicted_label': 1},\n",
       " 71: {'fold_num': 71,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.46253631e-05, -1.57219604e-05,  0.00000000e+00, ...,\n",
       "          -1.01319918e-05,  2.09697994e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.356233241676624,\n",
       "  'predicted_label': 0},\n",
       " 72: {'fold_num': 72,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.31436276e-05,  3.41712150e-05,  0.00000000e+00, ...,\n",
       "          -9.41303925e-06, -3.69148881e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.9269705572205573,\n",
       "  'predicted_label': 1},\n",
       " 73: {'fold_num': 73,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.11210892e-05, -2.82051485e-05,  0.00000000e+00, ...,\n",
       "          -1.01396324e-05, -4.10085868e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2797439039718451,\n",
       "  'predicted_label': 0},\n",
       " 74: {'fold_num': 74,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.45024958e-05, -1.16850492e-05,  0.00000000e+00, ...,\n",
       "           1.01859538e-05, -6.00300596e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.19669315944427837,\n",
       "  'predicted_label': 0},\n",
       " 75: {'fold_num': 75,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.57099605e-05,  1.94682914e-06, ...,\n",
       "          -7.62563849e-06, -9.47394519e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.46872984654234673,\n",
       "  'predicted_label': 0},\n",
       " 76: {'fold_num': 76,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.41712150e-05,  0.00000000e+00, ...,\n",
       "          -2.33928824e-05,  1.58998649e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8775728495360849,\n",
       "  'predicted_label': 1},\n",
       " 77: {'fold_num': 77,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.54979580e-05,  1.62898556e-04, ...,\n",
       "          -6.67173590e-06,  1.01852603e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.9073996836496838,\n",
       "  'predicted_label': 1},\n",
       " 78: {'fold_num': 78,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.28597841e-04, -5.67706424e-05, ...,\n",
       "          -1.84811785e-05, -3.87056278e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.737211689862425,\n",
       "  'predicted_label': 1},\n",
       " 79: {'fold_num': 79,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -3.18080552e-05,  0.00000000e+00, ...,\n",
       "          -1.84811785e-05,  1.49131658e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.44928252487966125,\n",
       "  'predicted_label': 0},\n",
       " 80: {'fold_num': 80,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.83186373e-06,  0.00000000e+00, -5.83266630e-05, ...,\n",
       "           0.00000000e+00, -2.74751622e-05,  2.56294034e-05]]),\n",
       "  'predictive_score': 0.8075343337218337,\n",
       "  'predicted_label': 1},\n",
       " 81: {'fold_num': 81,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.57479084e-05, ...,\n",
       "           0.00000000e+00, -1.58903329e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.515563505938506,\n",
       "  'predicted_label': 1},\n",
       " 82: {'fold_num': 82,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[5.44243458e-05, 0.00000000e+00, 2.16119687e-04, ...,\n",
       "          0.00000000e+00, 1.15757873e-06, 2.03088977e-05]]),\n",
       "  'predictive_score': 0.5908642831841362,\n",
       "  'predicted_label': 1},\n",
       " 83: {'fold_num': 83,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.77126578e-05,  1.39412188e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.58903329e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.35367282083671403,\n",
       "  'predicted_label': 0},\n",
       " 84: {'fold_num': 84,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.39400750e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.57870876e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.40233033924280065,\n",
       "  'predicted_label': 0},\n",
       " 85: {'fold_num': 85,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.12889184e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.43652112e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.9350828823953825,\n",
       "  'predicted_label': 1},\n",
       " 86: {'fold_num': 86,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.97421912e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.10060401e-06, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5426581071706075,\n",
       "  'predicted_label': 1},\n",
       " 87: {'fold_num': 87,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-8.00327031e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.84355802e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.21280591389287043,\n",
       "  'predicted_label': 0},\n",
       " 88: {'fold_num': 88,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.12889184e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.62032597e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8815669934640522,\n",
       "  'predicted_label': 1},\n",
       " 89: {'fold_num': 89,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.41156301e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.57471645e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6044611185383245,\n",
       "  'predicted_label': 1},\n",
       " 90: {'fold_num': 90,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.31523913e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.68868531e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6780746716518774,\n",
       "  'predicted_label': 1},\n",
       " 91: {'fold_num': 91,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.57951468e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.43195688e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.227011550949051,\n",
       "  'predicted_label': 0},\n",
       " 92: {'fold_num': 92,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.88934782e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.98766176e-05,  2.67072677e-05]]),\n",
       "  'predictive_score': 0.5072458129750329,\n",
       "  'predicted_label': 1},\n",
       " 93: {'fold_num': 93,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[2.15416256e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.28299941e-06, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.4730811420047102,\n",
       "  'predicted_label': 0},\n",
       " 94: {'fold_num': 94,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.03884802e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.18406729e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3402533223999942,\n",
       "  'predicted_label': 0},\n",
       " 95: {'fold_num': 95,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.38415375e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8928218901196843,\n",
       "  'predicted_label': 1},\n",
       " 96: {'fold_num': 96,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.15357799e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.9272541253680963,\n",
       "  'predicted_label': 1},\n",
       " 97: {'fold_num': 97,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.50054888e-05, ...,\n",
       "           0.00000000e+00,  5.41448497e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4643488594738596,\n",
       "  'predicted_label': 0},\n",
       " 98: {'fold_num': 98,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.44107113e-05,  2.49218310e-06]]),\n",
       "  'predictive_score': 0.2852938707459588,\n",
       "  'predicted_label': 0},\n",
       " 99: {'fold_num': 99,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.6353033144952144,\n",
       "  'predicted_label': 1},\n",
       " 100: {'fold_num': 100,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.14797311e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.30594587043503446,\n",
       "  'predicted_label': 0},\n",
       " 101: {'fold_num': 101,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.        , 0.        , 0.        , ..., 0.        , 0.00015198,\n",
       "          0.        ]]),\n",
       "  'predictive_score': 0.7152540139598967,\n",
       "  'predicted_label': 1},\n",
       " 102: {'fold_num': 102,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           1.47468604e-03, -2.91792494e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.27203312077499375,\n",
       "  'predicted_label': 0},\n",
       " 103: {'fold_num': 103,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.74430331e-05, 2.00972672e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8611413814943225,\n",
       "  'predicted_label': 1},\n",
       " 104: {'fold_num': 104,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 1.74288031e-05, ...,\n",
       "          9.73749159e-06, 1.64396351e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5669941504573858,\n",
       "  'predicted_label': 1},\n",
       " 105: {'fold_num': 105,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 2.64668831e-05, ...,\n",
       "          0.00000000e+00, 2.73957553e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6134586614366029,\n",
       "  'predicted_label': 1},\n",
       " 106: {'fold_num': 106,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00010265, 0.        , 0.        , ..., 0.        , 0.00013434,\n",
       "          0.        ]]),\n",
       "  'predictive_score': 0.5491872648550282,\n",
       "  'predicted_label': 1},\n",
       " 107: {'fold_num': 107,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.25594442e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -3.59520328e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6639581774864283,\n",
       "  'predicted_label': 1},\n",
       " 108: {'fold_num': 108,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[1.75498419e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.82706121e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.15991697818865,\n",
       "  'predicted_label': 0},\n",
       " 109: {'fold_num': 109,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.33113269e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  8.38450576e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8391563477372301,\n",
       "  'predicted_label': 1},\n",
       " 110: {'fold_num': 110,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.48004108e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  8.73695008e-06,  7.83186595e-06]]),\n",
       "  'predictive_score': 0.5321524689191097,\n",
       "  'predicted_label': 1},\n",
       " 111: {'fold_num': 111,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.75888157e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.25233276e-05, -2.36141804e-06]]),\n",
       "  'predictive_score': 0.11735868012706245,\n",
       "  'predicted_label': 0},\n",
       " 112: {'fold_num': 112,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-5.72151860e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.13942949e-05,  2.95423485e-06]]),\n",
       "  'predictive_score': 0.6621624500155846,\n",
       "  'predicted_label': 1},\n",
       " 113: {'fold_num': 113,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.00675814e-04, -1.20767101e-05,  0.00000000e+00, ...,\n",
       "           1.28309282e-05,  1.34090581e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3790615707392022,\n",
       "  'predicted_label': 0},\n",
       " 114: {'fold_num': 114,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.61402849e-05, 5.57245485e-06, 0.00000000e+00, ...,\n",
       "          1.31061028e-05, 1.57394526e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5046024950711484,\n",
       "  'predicted_label': 1},\n",
       " 115: {'fold_num': 115,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.38747740e-05,  5.57245485e-06,  0.00000000e+00, ...,\n",
       "           2.70987566e-05,  2.27939494e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8394437376349143,\n",
       "  'predicted_label': 1},\n",
       " 116: {'fold_num': 116,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[5.95852530e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.54272192e-05, 4.67776432e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6761532576900222,\n",
       "  'predicted_label': 1},\n",
       " 117: {'fold_num': 117,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.34124363e-04,  1.62733930e-06,  4.85896182e-05, ...,\n",
       "          -1.05422050e-06,  4.57211759e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6076374507845094,\n",
       "  'predicted_label': 1},\n",
       " 118: {'fold_num': 118,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.75986062e-04,  0.00000000e+00, -3.73752017e-05, ...,\n",
       "           1.72351186e-06, -1.07698112e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8560200516717542,\n",
       "  'predicted_label': 1},\n",
       " 119: {'fold_num': 119,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.12793509e-04,  0.00000000e+00,  2.21119049e-04, ...,\n",
       "           2.22833317e-06,  1.67444053e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6823000573772633,\n",
       "  'predicted_label': 1},\n",
       " 120: {'fold_num': 120,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.59515537e-04,  0.00000000e+00, -2.93145003e-05, ...,\n",
       "          -1.99227583e-06, -2.13731151e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3549434331578295,\n",
       "  'predicted_label': 0},\n",
       " 121: {'fold_num': 121,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.12799160e-04,  0.00000000e+00,  2.10842776e-05, ...,\n",
       "          -2.29877629e-06, -2.09623701e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.46879409316174014,\n",
       "  'predicted_label': 0},\n",
       " 122: {'fold_num': 122,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 8.16266124e-05,  1.87052376e-03, -3.00194457e-07, ...,\n",
       "          -1.31506926e-05, -2.19476053e-05,  1.23867462e-05]]),\n",
       "  'predictive_score': 0.21451802912000273,\n",
       "  'predicted_label': 0},\n",
       " 123: {'fold_num': 123,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.17326921e-04, -5.14083165e-05,  4.67136327e-05, ...,\n",
       "           1.63231256e-05, -3.42291646e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4273023336312811,\n",
       "  'predicted_label': 0},\n",
       " 124: {'fold_num': 124,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  2.54036625e-04, ...,\n",
       "          -7.29200631e-06, -2.34987950e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.24771197878918474,\n",
       "  'predicted_label': 0},\n",
       " 125: {'fold_num': 125,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -4.37099639e-05, ...,\n",
       "           1.31506926e-05, -5.75004191e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6437873197064371,\n",
       "  'predicted_label': 1},\n",
       " 126: {'fold_num': 126,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -4.94539260e-05, ...,\n",
       "           0.00000000e+00, -4.76188914e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.28516969386822333,\n",
       "  'predicted_label': 0},\n",
       " 127: {'fold_num': 127,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -3.22054394e-04, ...,\n",
       "           0.00000000e+00, -2.34987950e-05,  9.36278500e-05]]),\n",
       "  'predictive_score': 0.36390179632459035,\n",
       "  'predicted_label': 0},\n",
       " 128: {'fold_num': 128,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.52076698e-06,  2.41763214e-04, -2.16597683e-04, ...,\n",
       "           0.00000000e+00, -1.64935621e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4161021813154165,\n",
       "  'predicted_label': 0},\n",
       " 129: {'fold_num': 129,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[6.77989278e-06, 1.26062248e-03, 7.43155265e-05, ...,\n",
       "          2.28308683e-04, 6.19188041e-06, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.7837011466560619,\n",
       "  'predicted_label': 1},\n",
       " 130: {'fold_num': 130,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  1.35363365e-06, ...,\n",
       "          -4.94951277e-06,  1.97442317e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.761607434232434,\n",
       "  'predicted_label': 1},\n",
       " 131: {'fold_num': 131,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.04597632e-05,  3.43021325e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5495610926311393,\n",
       "  'predicted_label': 1},\n",
       " 132: {'fold_num': 132,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.8413333051752171,\n",
       "  'predicted_label': 1},\n",
       " 133: {'fold_num': 133,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.07417362498612497,\n",
       "  'predicted_label': 0},\n",
       " 134: {'fold_num': 134,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.5073671303112094,\n",
       "  'predicted_label': 1},\n",
       " 135: {'fold_num': 135,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.5374441659346847,\n",
       "  'predicted_label': 1},\n",
       " 136: {'fold_num': 136,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -7.78427271e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.07529480e-05]]),\n",
       "  'predictive_score': 0.6577964812964815,\n",
       "  'predicted_label': 1},\n",
       " 137: {'fold_num': 137,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.        , -0.00013405,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]),\n",
       "  'predictive_score': 0.6388075781717424,\n",
       "  'predicted_label': 1},\n",
       " 138: {'fold_num': 138,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 3.45258352e-05, 1.29187191e-06, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5924508767376415,\n",
       "  'predicted_label': 1},\n",
       " 139: {'fold_num': 139,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 7.38568386e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6059565683499506,\n",
       "  'predicted_label': 1},\n",
       " 140: {'fold_num': 140,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -4.43165422e-05, -1.11084614e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.09707301113918759,\n",
       "  'predicted_label': 0},\n",
       " 141: {'fold_num': 141,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 4.24979651e-05, 5.81918831e-06, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8774703702730019,\n",
       "  'predicted_label': 1},\n",
       " 142: {'fold_num': 142,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.87945694e-05, -9.11781633e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8626167582417584,\n",
       "  'predicted_label': 1},\n",
       " 143: {'fold_num': 143,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 3.45258352e-05, 0.00000000e+00, ...,\n",
       "          3.63152402e-05, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5168676513544935,\n",
       "  'predicted_label': 1},\n",
       " 144: {'fold_num': 144,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.0000000e+00, -2.7503206e-05,  0.0000000e+00, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]),\n",
       "  'predictive_score': 0.28364768399385265,\n",
       "  'predicted_label': 0},\n",
       " 145: {'fold_num': 145,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "          0.0000000e+00, 1.1767063e-05]]),\n",
       "  'predictive_score': 0.48349337652801294,\n",
       "  'predicted_label': 0},\n",
       " 146: {'fold_num': 146,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.5843362741274892,\n",
       "  'predicted_label': 1},\n",
       " 147: {'fold_num': 147,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.8445247826004405,\n",
       "  'predicted_label': 1},\n",
       " 148: {'fold_num': 148,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.16484174e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.75966669e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4517742105675542,\n",
       "  'predicted_label': 0},\n",
       " 149: {'fold_num': 149,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  7.72248801e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -8.56826847e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.9257761817430935,\n",
       "  'predicted_label': 1},\n",
       " 150: {'fold_num': 150,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -3.21238832e-05, -2.31646104e-05, ...,\n",
       "           2.05356206e-05,  1.54412439e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.40638423324478085,\n",
       "  'predicted_label': 0},\n",
       " 151: {'fold_num': 151,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.61259121e-05, -2.65111787e-05, ...,\n",
       "           2.71474058e-05,  1.51912941e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.40941111395484475,\n",
       "  'predicted_label': 0},\n",
       " 152: {'fold_num': 152,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  1.54339659e-05, ...,\n",
       "          -2.05356206e-05,  2.87134237e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8386484903984904,\n",
       "  'predicted_label': 1},\n",
       " 153: {'fold_num': 153,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.79741986e-04, -1.67982986e-05, ...,\n",
       "           6.93329407e-05, -6.27128984e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2523625421276349,\n",
       "  'predicted_label': 0},\n",
       " 154: {'fold_num': 154,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -3.00686401e-05, -2.14023961e-05, ...,\n",
       "           7.74525457e-05,  0.00000000e+00,  8.64372875e-06]]),\n",
       "  'predictive_score': 0.3434512705431823,\n",
       "  'predicted_label': 0},\n",
       " 155: {'fold_num': 155,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.77019915e-05,  6.24060877e-05, ...,\n",
       "          -1.26543009e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5350415972701189,\n",
       "  'predicted_label': 1},\n",
       " 156: {'fold_num': 156,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.66073624e-05,  0.00000000e+00, ...,\n",
       "          -7.21868628e-06,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.49845305307437665,\n",
       "  'predicted_label': 0},\n",
       " 157: {'fold_num': 157,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.13561153e-05,  0.00000000e+00, ...,\n",
       "          -3.70941280e-06,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.16892654333540552,\n",
       "  'predicted_label': 0},\n",
       " 158: {'fold_num': 158,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.24146056e-05,  0.00000000e+00, ...,\n",
       "          -3.73382593e-06,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1986953724380195,\n",
       "  'predicted_label': 0},\n",
       " 159: {'fold_num': 159,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.15851357e-05,  0.00000000e+00, ...,\n",
       "          -3.73382593e-06,  4.39626753e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.25081157718270713,\n",
       "  'predicted_label': 0},\n",
       " 160: {'fold_num': 160,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-7.87031656e-06,  5.40978367e-06,  0.00000000e+00, ...,\n",
       "           3.64698932e-06,  9.25018848e-05,  8.46758777e-06]]),\n",
       "  'predictive_score': 0.6405726356976357,\n",
       "  'predicted_label': 1},\n",
       " 161: {'fold_num': 161,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 7.04420471e-06, -4.66545935e-05,  0.00000000e+00, ...,\n",
       "          -3.73382593e-06,  4.39626753e-06,  1.33901919e-06]]),\n",
       "  'predictive_score': 0.1946739206570863,\n",
       "  'predicted_label': 0},\n",
       " 162: {'fold_num': 162,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[7.32948455e-06, 3.78314288e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.68710712e-05]]),\n",
       "  'predictive_score': 0.5602235215120277,\n",
       "  'predicted_label': 1},\n",
       " 163: {'fold_num': 163,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.76219102e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.77733117e-05]]),\n",
       "  'predictive_score': 0.48493042455910107,\n",
       "  'predicted_label': 0},\n",
       " 164: {'fold_num': 164,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.48938713e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.39626753e-06, -3.83248777e-06]]),\n",
       "  'predictive_score': 0.4476328150049127,\n",
       "  'predicted_label': 0},\n",
       " 165: {'fold_num': 165,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-5.28885273e-06,  3.16058960e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -9.01654987e-06, -2.71363249e-06]]),\n",
       "  'predictive_score': 0.8634436454068808,\n",
       "  'predicted_label': 1},\n",
       " 166: {'fold_num': 166,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.97285023e-05, -7.28699551e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.88709196e-05, -6.48326197e-06]]),\n",
       "  'predictive_score': 0.4774725801159626,\n",
       "  'predicted_label': 0},\n",
       " 167: {'fold_num': 167,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.42741734e-05, -3.16058960e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.98561749e-06, -1.34449291e-05]]),\n",
       "  'predictive_score': 0.40439663114663094,\n",
       "  'predicted_label': 0},\n",
       " 168: {'fold_num': 168,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.59546779e-05, -4.34298808e-06,  8.31718253e-06, ...,\n",
       "           0.00000000e+00,  9.20608606e-05,  4.46625659e-06]]),\n",
       "  'predictive_score': 0.733649505100163,\n",
       "  'predicted_label': 1},\n",
       " 169: {'fold_num': 169,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.75075154e-05, -5.42154064e-06, -4.16813712e-05, ...,\n",
       "           0.00000000e+00,  1.22247747e-04,  7.84125676e-06]]),\n",
       "  'predictive_score': 0.8715184709296553,\n",
       "  'predicted_label': 1},\n",
       " 170: {'fold_num': 170,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.56837072e-04, -2.95344912e-05,  8.31718253e-06, ...,\n",
       "           0.00000000e+00,  2.83862522e-04,  4.30045218e-06]]),\n",
       "  'predictive_score': 0.6287462844817722,\n",
       "  'predicted_label': 1},\n",
       " 171: {'fold_num': 171,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-7.87031656e-06,  3.16192445e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.27345133e-05,  5.97589475e-06]]),\n",
       "  'predictive_score': 0.5662792346542345,\n",
       "  'predicted_label': 1},\n",
       " 172: {'fold_num': 172,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.09001965e-05,  2.08203705e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.12964388e-04, -2.04504364e-06]]),\n",
       "  'predictive_score': 0.9004808659477775,\n",
       "  'predicted_label': 1},\n",
       " 173: {'fold_num': 173,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.84327173e-06, -3.16192445e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.38518544e-06, -8.13988713e-06]]),\n",
       "  'predictive_score': 0.3352626271432388,\n",
       "  'predicted_label': 0},\n",
       " 174: {'fold_num': 174,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.20321519e-06, -7.31530717e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.04023052e-04, -1.83381068e-05]]),\n",
       "  'predictive_score': 0.41415371709044285,\n",
       "  'predicted_label': 0},\n",
       " 175: {'fold_num': 175,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.87031656e-06,  5.76109809e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.16483054e-04, -5.62070873e-06]]),\n",
       "  'predictive_score': 0.6611601439066608,\n",
       "  'predicted_label': 1},\n",
       " 176: {'fold_num': 176,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-5.28885273e-06,  2.72515966e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  2.42233973e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.923709589022089,\n",
       "  'predicted_label': 1},\n",
       " 177: {'fold_num': 177,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.25467860e-06, 3.84188324e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.61931017e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.86581607975358,\n",
       "  'predicted_label': 1},\n",
       " 178: {'fold_num': 178,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-7.87031656e-06,  3.56562235e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  5.27102911e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8837976753638518,\n",
       "  'predicted_label': 1},\n",
       " 179: {'fold_num': 179,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.72767607e-04,  7.30761178e-05,  4.28892880e-05, ...,\n",
       "          -8.16445883e-06,  2.57495955e-05, -8.09391658e-06]]),\n",
       "  'predictive_score': 0.6002267812749907,\n",
       "  'predicted_label': 1},\n",
       " 180: {'fold_num': 180,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.12169119e-05,  3.87536561e-05,  4.72737886e-05, ...,\n",
       "          -2.25373289e-05,  3.38041569e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5189893190959369,\n",
       "  'predicted_label': 1},\n",
       " 181: {'fold_num': 181,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.24928438e-05,  3.50893244e-05,  3.96874250e-04, ...,\n",
       "          -7.23122849e-05,  6.95822005e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.537331259877893,\n",
       "  'predicted_label': 1},\n",
       " 182: {'fold_num': 182,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[2.28551685e-05, 1.18308153e-04, 0.00000000e+00, ...,\n",
       "          9.24191058e-06, 1.55231996e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.42782021219521227,\n",
       "  'predicted_label': 0},\n",
       " 183: {'fold_num': 183,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.58057527e-04,  3.39127089e-05, -2.77244881e-05, ...,\n",
       "           0.00000000e+00,  1.91637352e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.838788356872596,\n",
       "  'predicted_label': 1},\n",
       " 184: {'fold_num': 184,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.34107424e-05,  1.70793634e-04, -6.10359580e-05, ...,\n",
       "           0.00000000e+00,  5.02226493e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8609350118835414,\n",
       "  'predicted_label': 1},\n",
       " 185: {'fold_num': 185,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.56221771e-05, 1.11953333e-05, 7.70410858e-05, ...,\n",
       "          0.00000000e+00, 6.30984005e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.7816464670949966,\n",
       "  'predicted_label': 1},\n",
       " 186: {'fold_num': 186,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.13860603e-05, -5.48356614e-05,  6.66493238e-05, ...,\n",
       "           0.00000000e+00,  4.92999567e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3776975058180554,\n",
       "  'predicted_label': 0},\n",
       " 187: {'fold_num': 187,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[9.49204331e-06, 7.86670368e-05, 3.32638915e-05, ...,\n",
       "          0.00000000e+00, 6.06072098e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.9460818833943834,\n",
       "  'predicted_label': 1},\n",
       " 188: {'fold_num': 188,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.70312577e-05, -3.32362303e-04, -3.67593941e-04, ...,\n",
       "           0.00000000e+00, -7.12174746e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.48619908347100776,\n",
       "  'predicted_label': 0},\n",
       " 189: {'fold_num': 189,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -8.81557710e-05,  2.32775234e-05, ...,\n",
       "           0.00000000e+00, -9.04502667e-06, -7.78898466e-06]]),\n",
       "  'predictive_score': 0.48930044261294275,\n",
       "  'predicted_label': 0},\n",
       " 190: {'fold_num': 190,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.10765476e-04,  7.94123849e-05, -3.59187747e-05, ...,\n",
       "          -1.68280265e-05,  7.37715689e-06,  2.01998043e-05]]),\n",
       "  'predictive_score': 0.6549774955007153,\n",
       "  'predicted_label': 1},\n",
       " 191: {'fold_num': 191,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.32361915e-04,  1.01010254e-04, ...,\n",
       "           1.81938408e-05,  0.00000000e+00, -3.40897232e-08]]),\n",
       "  'predictive_score': 0.46693171132702865,\n",
       "  'predicted_label': 0},\n",
       " 192: {'fold_num': 192,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.08947934e-05,  6.53017487e-05, -2.63474959e-05, ...,\n",
       "          -6.18978549e-06,  0.00000000e+00,  1.03737525e-05]]),\n",
       "  'predictive_score': 0.9553675491175493,\n",
       "  'predicted_label': 1},\n",
       " 193: {'fold_num': 193,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.65958797e-05, -7.25720450e-06,  4.14235642e-04, ...,\n",
       "           2.05943665e-05,  0.00000000e+00,  6.49082055e-05]]),\n",
       "  'predictive_score': 0.45535697878402975,\n",
       "  'predicted_label': 0},\n",
       " 194: {'fold_num': 194,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.09931328e-05,  1.12690157e-05, -9.36572536e-06, ...,\n",
       "          -2.29593219e-05,  0.00000000e+00,  1.76063480e-05]]),\n",
       "  'predictive_score': 0.5934208525392735,\n",
       "  'predicted_label': 1},\n",
       " 195: {'fold_num': 195,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.55763316e-06, -4.24906946e-06,  0.00000000e+00, ...,\n",
       "           2.06126255e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4156288389972601,\n",
       "  'predicted_label': 0},\n",
       " 196: {'fold_num': 196,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.44227831e-05, -4.24906946e-06, -1.27754897e-04, ...,\n",
       "           8.30959046e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.17465576994814608,\n",
       "  'predicted_label': 0},\n",
       " 197: {'fold_num': 197,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.59191727e-05,  5.81932152e-05,  0.00000000e+00, ...,\n",
       "          -9.83927731e-06,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6997565490065492,\n",
       "  'predicted_label': 1},\n",
       " 198: {'fold_num': 198,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.43272554e-05,  2.34194897e-04, -8.08451271e-05, ...,\n",
       "          -1.23073082e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6961232288093743,\n",
       "  'predicted_label': 1},\n",
       " 199: {'fold_num': 199,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.59191727e-05,  2.62775775e-05, -1.17417289e-04, ...,\n",
       "           2.32197713e-05, -4.48803624e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6932512499755146,\n",
       "  'predicted_label': 1},\n",
       " 200: {'fold_num': 200,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.59191727e-05,  1.36161820e-04,  0.00000000e+00, ...,\n",
       "          -8.22066699e-05,  3.44100347e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5149615532815998,\n",
       "  'predicted_label': 1},\n",
       " 201: {'fold_num': 201,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.26361518e-05, -2.34717496e-04,  0.00000000e+00, ...,\n",
       "           3.25844055e-05,  3.91656794e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4960186534311922,\n",
       "  'predicted_label': 0},\n",
       " 202: {'fold_num': 202,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.83300938e-05,  3.31610742e-05, ...,\n",
       "          -1.35153286e-05, -1.05326723e-05, -1.48682434e-05]]),\n",
       "  'predictive_score': 0.6499642910194379,\n",
       "  'predicted_label': 1},\n",
       " 203: {'fold_num': 203,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.06068025e-05,  9.89965039e-05, -8.90513452e-06, ...,\n",
       "          -1.67282899e-05, -2.63085868e-05,  5.61703075e-06]]),\n",
       "  'predictive_score': 0.5102822516535751,\n",
       "  'predicted_label': 1},\n",
       " 204: {'fold_num': 204,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.31314440e-05,  1.35080932e-04, -1.08063451e-05, ...,\n",
       "          -2.11353976e-05, -1.69811520e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5119086591513061,\n",
       "  'predicted_label': 1},\n",
       " 205: {'fold_num': 205,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -6.35503782e-05, -6.94521230e-05, ...,\n",
       "          -3.49145591e-05,  1.04625991e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.534382711414832,\n",
       "  'predicted_label': 1},\n",
       " 206: {'fold_num': 206,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -8.49959780e-05, -9.83721839e-05, ...,\n",
       "           1.83264017e-04,  4.59443236e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.478225390472101,\n",
       "  'predicted_label': 0},\n",
       " 207: {'fold_num': 207,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  4.61521939e-05, -2.57700487e-05, ...,\n",
       "           2.12390367e-05,  7.58801040e-05,  3.35285419e-05]]),\n",
       "  'predictive_score': 0.850359148913522,\n",
       "  'predicted_label': 1},\n",
       " 208: {'fold_num': 208,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.58982368e-05, -7.14430532e-04, -2.36076639e-05, ...,\n",
       "          -2.09405209e-05, -2.43109777e-04, -2.11626705e-05]]),\n",
       "  'predictive_score': 0.45889746038275453,\n",
       "  'predicted_label': 0},\n",
       " 209: {'fold_num': 209,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.29398692e-05,  4.36029704e-05,  3.12658214e-05, ...,\n",
       "           1.13738079e-05,  5.27872162e-05,  3.35285419e-05]]),\n",
       "  'predictive_score': 0.8988665110689105,\n",
       "  'predicted_label': 1},\n",
       " 210: {'fold_num': 210,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -5.76757367e-04,  0.00000000e+00, ...,\n",
       "          -1.83183655e-04, -4.20251423e-05,  2.84087787e-05]]),\n",
       "  'predictive_score': 0.5349194380181225,\n",
       "  'predicted_label': 1},\n",
       " 211: {'fold_num': 211,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.12104045e-05, -3.57876704e-05,  0.00000000e+00, ...,\n",
       "          -7.30695778e-06,  2.23427367e-05, -2.84087787e-05]]),\n",
       "  'predictive_score': 0.2106267726296752,\n",
       "  'predicted_label': 0},\n",
       " 212: {'fold_num': 212,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.51645615e-05, -5.72947364e-04,  0.00000000e+00, ...,\n",
       "          -5.43609326e-06,  2.09633301e-05, -2.11626705e-05]]),\n",
       "  'predictive_score': 0.4792779302740604,\n",
       "  'predicted_label': 0},\n",
       " 213: {'fold_num': 213,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  4.32174745e-05,  0.00000000e+00, ...,\n",
       "          -1.78848806e-04,  1.15814519e-05,  2.84087787e-05]]),\n",
       "  'predictive_score': 0.7040574614154338,\n",
       "  'predicted_label': 1},\n",
       " 214: {'fold_num': 214,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -5.83911748e-04,  0.00000000e+00, ...,\n",
       "          -1.23902851e-04, -9.49136829e-06,  3.07456550e-05]]),\n",
       "  'predictive_score': 0.7044898494823032,\n",
       "  'predicted_label': 1},\n",
       " 215: {'fold_num': 215,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.43976312e-05, -9.33510210e-05,  0.00000000e+00, ...,\n",
       "           1.26614252e-04,  7.34575625e-04,  1.82466915e-05]]),\n",
       "  'predictive_score': 0.47207984342369014,\n",
       "  'predicted_label': 0},\n",
       " 216: {'fold_num': 216,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.32346001e-05,  1.08065905e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.61537020e-04, -1.05166834e-05]]),\n",
       "  'predictive_score': 0.6328587951006682,\n",
       "  'predicted_label': 1},\n",
       " 217: {'fold_num': 217,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.69236202e-06,  9.95105309e-05,  0.00000000e+00, ...,\n",
       "           1.03439580e-05, -1.49938424e-04,  3.02511108e-07]]),\n",
       "  'predictive_score': 0.6058491760647334,\n",
       "  'predicted_label': 1},\n",
       " 218: {'fold_num': 218,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.73605353e-05, -1.44631164e-04,  2.14521875e-05, ...,\n",
       "           2.65909551e-05,  4.19826108e-05,  1.34054995e-05]]),\n",
       "  'predictive_score': 0.41693327220165455,\n",
       "  'predicted_label': 0},\n",
       " 219: {'fold_num': 219,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.32346001e-05,  2.44671621e-04, -3.94921674e-04, ...,\n",
       "          -1.72030133e-05, -2.51566414e-05,  5.10834101e-05]]),\n",
       "  'predictive_score': 0.7236644382019769,\n",
       "  'predicted_label': 1},\n",
       " 220: {'fold_num': 220,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.02970609e-06,  7.15889488e-05,  0.00000000e+00, ...,\n",
       "           7.14495527e-06,  2.39552492e-05,  2.84087787e-05]]),\n",
       "  'predictive_score': 0.5395603923295487,\n",
       "  'predicted_label': 1},\n",
       " 221: {'fold_num': 221,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.15770090e-06,  2.51850117e-04, -4.79640855e-05, ...,\n",
       "           5.40205115e-05,  2.27410298e-05,  3.21215092e-05]]),\n",
       "  'predictive_score': 0.8112393301143302,\n",
       "  'predicted_label': 1},\n",
       " 222: {'fold_num': 222,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.64308367e-05,  1.01002905e-04,  0.00000000e+00, ...,\n",
       "          -1.35523241e-04,  1.18443208e-05,  2.83713660e-05]]),\n",
       "  'predictive_score': 0.6057847411231695,\n",
       "  'predicted_label': 1},\n",
       " 223: {'fold_num': 223,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.72877927e-05,  2.18980092e-04,  0.00000000e+00, ...,\n",
       "          -1.35550591e-05,  5.69122491e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.22576971016599515,\n",
       "  'predicted_label': 0},\n",
       " 224: {'fold_num': 224,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.00778608e-05, -1.04803729e-04,  0.00000000e+00, ...,\n",
       "          -1.13258838e-05,  8.74606262e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.48412396631146637,\n",
       "  'predicted_label': 0},\n",
       " 225: {'fold_num': 225,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.43137500e-04, -9.30447667e-04,  0.00000000e+00, ...,\n",
       "           1.34758295e-04,  3.48478695e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3387386547491037,\n",
       "  'predicted_label': 0},\n",
       " 226: {'fold_num': 226,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.41608927e-05,  1.17007303e-04,  0.00000000e+00, ...,\n",
       "          -1.21599458e-04, -4.77906236e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6860769810255103,\n",
       "  'predicted_label': 1},\n",
       " 227: {'fold_num': 227,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.80265189e-06,  9.17183265e-05,  0.00000000e+00, ...,\n",
       "          -1.86582415e-05,  6.93492730e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8865148658531009,\n",
       "  'predicted_label': 1},\n",
       " 228: {'fold_num': 228,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.58877569e-05,  1.16729637e-04,  0.00000000e+00, ...,\n",
       "           1.65898876e-05, -5.80033881e-08,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5079012266543227,\n",
       "  'predicted_label': 1},\n",
       " 229: {'fold_num': 229,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.85352707e-05, -8.80239634e-05,  0.00000000e+00, ...,\n",
       "           1.05155332e-04, -5.91222176e-06, -3.18842097e-05]]),\n",
       "  'predictive_score': 0.26482640975930793,\n",
       "  'predicted_label': 0},\n",
       " 230: {'fold_num': 230,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.17058563e-05, -4.12746670e-04,  0.00000000e+00, ...,\n",
       "          -1.16571632e-03, -5.75029615e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.42428510586850376,\n",
       "  'predicted_label': 0},\n",
       " 231: {'fold_num': 231,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.71310833e-05, -3.04789414e-04,  0.00000000e+00, ...,\n",
       "           3.78909481e-04, -1.16282375e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7503636433011432,\n",
       "  'predicted_label': 1},\n",
       " 232: {'fold_num': 232,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.55286768e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.76174183e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5856856199356197,\n",
       "  'predicted_label': 1},\n",
       " 233: {'fold_num': 233,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 1.30065614e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.30381624e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8108063839755012,\n",
       "  'predicted_label': 1},\n",
       " 234: {'fold_num': 234,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[8.62023366e-05, 1.30157620e-04, 1.77322463e-05, ...,\n",
       "          0.00000000e+00, 4.39728529e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.4185843025438613,\n",
       "  'predicted_label': 0},\n",
       " 235: {'fold_num': 235,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.08322313e-04,  1.32397949e-04, -1.16212540e-05, ...,\n",
       "           0.00000000e+00, -1.76174183e-05, -1.82283283e-05]]),\n",
       "  'predictive_score': 0.7659075733348178,\n",
       "  'predicted_label': 1},\n",
       " 236: {'fold_num': 236,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.31879539e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.07748141e-06, -4.06079171e-05]]),\n",
       "  'predictive_score': 0.5655343537181775,\n",
       "  'predicted_label': 1},\n",
       " 237: {'fold_num': 237,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 4.56251399e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.37381564e-04, 1.23726476e-04]]),\n",
       "  'predictive_score': 0.7506700937950939,\n",
       "  'predicted_label': 1},\n",
       " 238: {'fold_num': 238,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.71744131e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.36576502e-05,  5.33256348e-05]]),\n",
       "  'predictive_score': 0.3266757475195942,\n",
       "  'predicted_label': 0},\n",
       " 239: {'fold_num': 239,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.05134439e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -9.24613552e-05,  2.71358375e-05]]),\n",
       "  'predictive_score': 0.41457275140150524,\n",
       "  'predicted_label': 0},\n",
       " 240: {'fold_num': 240,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.52108716e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  3.71543543e-04, -8.08484975e-06]]),\n",
       "  'predictive_score': 0.812150876900877,\n",
       "  'predicted_label': 1},\n",
       " 241: {'fold_num': 241,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.93828800e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.86018933e-06,  1.27425201e-04]]),\n",
       "  'predictive_score': 0.4867743122245832,\n",
       "  'predicted_label': 0},\n",
       " 242: {'fold_num': 242,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.55559206e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  9.05329473e-04, -1.95556365e-05]]),\n",
       "  'predictive_score': 0.40734116120377734,\n",
       "  'predicted_label': 0},\n",
       " 243: {'fold_num': 243,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 7.62645540e-05,  8.66729245e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.21491664e-04, -2.54292027e-05]]),\n",
       "  'predictive_score': 0.5534696871755694,\n",
       "  'predicted_label': 1},\n",
       " 244: {'fold_num': 244,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.00382906e-05,  1.18224911e-04, -1.06075015e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -2.78153952e-05]]),\n",
       "  'predictive_score': 0.8218827165481577,\n",
       "  'predicted_label': 1},\n",
       " 245: {'fold_num': 245,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-8.30798501e-05, -1.01195120e-04, -2.93271415e-04, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  2.20497736e-04]]),\n",
       "  'predictive_score': 0.4167815097913784,\n",
       "  'predicted_label': 0},\n",
       " 246: {'fold_num': 246,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.47227251e-05, -1.19276749e-06, -7.21994740e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  4.36578863e-05]]),\n",
       "  'predictive_score': 0.19251761310584845,\n",
       "  'predicted_label': 0},\n",
       " 247: {'fold_num': 247,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.40764566e-04, -3.89056912e-05,  2.97004239e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.65493931e-04]]),\n",
       "  'predictive_score': 0.35203175565404665,\n",
       "  'predicted_label': 0},\n",
       " 248: {'fold_num': 248,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.65233286e-05, -4.05321079e-05,  1.02884889e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  7.76443764e-06]]),\n",
       "  'predictive_score': 0.41263596138983155,\n",
       "  'predicted_label': 0},\n",
       " 249: {'fold_num': 249,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.39740797e-05,  2.96299265e-05, -6.08081281e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -7.76443764e-06]]),\n",
       "  'predictive_score': 0.7354531073931229,\n",
       "  'predicted_label': 1},\n",
       " 250: {'fold_num': 250,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.22168409e-05, -1.25906183e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.31700846e-05]]),\n",
       "  'predictive_score': 0.49254085190695096,\n",
       "  'predicted_label': 0},\n",
       " 251: {'fold_num': 251,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 6.15687964e-05, -1.06819833e-03, -5.00998198e-05, ...,\n",
       "           0.00000000e+00, -2.47517156e-05,  3.20798782e-05]]),\n",
       "  'predictive_score': 0.21372274545629807,\n",
       "  'predicted_label': 0},\n",
       " 252: {'fold_num': 252,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.22371162e-05, -3.67035364e-04,  0.00000000e+00, ...,\n",
       "           1.32453313e-05, -3.91781517e-05,  3.80067555e-05]]),\n",
       "  'predictive_score': 0.4527987323134382,\n",
       "  'predicted_label': 0},\n",
       " 253: {'fold_num': 253,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.95063587e-05,  2.55871912e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.06709916e-05,  3.80067555e-05]]),\n",
       "  'predictive_score': 0.38669171607116665,\n",
       "  'predicted_label': 0},\n",
       " 254: {'fold_num': 254,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.05002487e-04, -1.28853503e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.21191848e-05,  3.20798782e-05]]),\n",
       "  'predictive_score': 0.3012109557539125,\n",
       "  'predicted_label': 0},\n",
       " 255: {'fold_num': 255,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.40961533e-04, -4.02620082e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.48202271e-05,  1.73082545e-04]]),\n",
       "  'predictive_score': 0.07533867983867981,\n",
       "  'predicted_label': 0},\n",
       " 256: {'fold_num': 256,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.67715005e-06,  8.83125343e-06,  0.00000000e+00, ...,\n",
       "          -6.08414708e-06,  9.69832292e-05, -7.75207937e-06]]),\n",
       "  'predictive_score': 0.7702179533429535,\n",
       "  'predicted_label': 1},\n",
       " 257: {'fold_num': 257,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 6.08187980e-06, -1.41879446e-06,  0.00000000e+00, ...,\n",
       "           9.75659033e-05, -4.99612838e-05,  1.31496348e-05]]),\n",
       "  'predictive_score': 0.30428752089413863,\n",
       "  'predicted_label': 0},\n",
       " 258: {'fold_num': 258,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.41486824e-05,  9.86467373e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  2.93638800e-04, -1.31496348e-05]]),\n",
       "  'predictive_score': 0.8293322580197584,\n",
       "  'predicted_label': 1},\n",
       " 259: {'fold_num': 259,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.39173847e-06, -2.28184609e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.21095373e-05,  1.58498192e-05]]),\n",
       "  'predictive_score': 0.17225878941320116,\n",
       "  'predicted_label': 0},\n",
       " 260: {'fold_num': 260,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 8.64702593e-06,  4.59124801e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  7.00112587e-05, -5.73288966e-06]]),\n",
       "  'predictive_score': 0.5620082004253056,\n",
       "  'predicted_label': 1},\n",
       " 261: {'fold_num': 261,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.41911299e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           1.22748911e-04, -9.89355467e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.21846493661567196,\n",
       "  'predicted_label': 0},\n",
       " 262: {'fold_num': 262,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.41936842e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.70036787e-05,  0.00000000e+00,  1.26483279e-04]]),\n",
       "  'predictive_score': 0.7811454142262968,\n",
       "  'predicted_label': 1},\n",
       " 263: {'fold_num': 263,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.87085454e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.76976569e-04]]),\n",
       "  'predictive_score': 0.3064967667995919,\n",
       "  'predicted_label': 0},\n",
       " 264: {'fold_num': 264,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.50254160e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  5.20778549e-06, -1.60519287e-05]]),\n",
       "  'predictive_score': 0.8234774569470779,\n",
       "  'predicted_label': 1},\n",
       " 265: {'fold_num': 265,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.65520989e-06, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.42247472e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8110851521844168,\n",
       "  'predicted_label': 1},\n",
       " 266: {'fold_num': 266,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.45106192e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           3.19614860e-05,  4.61023158e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5169463684750063,\n",
       "  'predicted_label': 1},\n",
       " 267: {'fold_num': 267,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.62714717e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -8.70323141e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2099505494505495,\n",
       "  'predicted_label': 0},\n",
       " 268: {'fold_num': 268,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.77140596e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.33395835e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.535637425074925,\n",
       "  'predicted_label': 1},\n",
       " 269: {'fold_num': 269,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.60521809e-05,  8.75322272e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.86242666e-05,  3.21901654e-05]]),\n",
       "  'predictive_score': 0.4838276825298882,\n",
       "  'predicted_label': 0},\n",
       " 270: {'fold_num': 270,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.62714717e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           1.68884748e-05,  1.75884901e-05,  5.74379695e-05]]),\n",
       "  'predictive_score': 0.2527392406887544,\n",
       "  'predicted_label': 0},\n",
       " 271: {'fold_num': 271,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.47397087e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           1.17640436e-06,  1.75884901e-05,  1.29407467e-04]]),\n",
       "  'predictive_score': 0.37114689398746825,\n",
       "  'predicted_label': 0},\n",
       " 272: {'fold_num': 272,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[2.92570485e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.73550114e-06, 1.75884901e-05, 1.35566831e-04]]),\n",
       "  'predictive_score': 0.4565406205636468,\n",
       "  'predicted_label': 0},\n",
       " 273: {'fold_num': 273,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[6.97431129e-06, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.35862307e-05, 4.36646885e-05]]),\n",
       "  'predictive_score': 0.41932293645896584,\n",
       "  'predicted_label': 0},\n",
       " 274: {'fold_num': 274,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.44830535e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.16203240e-05, -5.42223676e-05]]),\n",
       "  'predictive_score': 0.8468640229477827,\n",
       "  'predicted_label': 1},\n",
       " 275: {'fold_num': 275,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.16148809e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.75781771e-05, -3.84579964e-05]]),\n",
       "  'predictive_score': 0.5329859188369251,\n",
       "  'predicted_label': 1},\n",
       " 276: {'fold_num': 276,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.71453166e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.75781771e-05, -9.40340923e-05]]),\n",
       "  'predictive_score': 0.7583689092340409,\n",
       "  'predicted_label': 1},\n",
       " 277: {'fold_num': 277,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.36849114e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.50513090e-05, -5.42223676e-05]]),\n",
       "  'predictive_score': 0.824481660088278,\n",
       "  'predicted_label': 1},\n",
       " 278: {'fold_num': 278,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.06044605e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.68283695e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5297191814678268,\n",
       "  'predicted_label': 1},\n",
       " 279: {'fold_num': 279,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.16127516e-05,  0.00000000e+00, -1.84736597e-05, ...,\n",
       "           0.00000000e+00,  2.29868470e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5046065266432914,\n",
       "  'predicted_label': 1},\n",
       " 280: {'fold_num': 280,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.60899264e-05, -4.16766001e-05, -1.71990956e-05, ...,\n",
       "           0.00000000e+00, -1.02355945e-04, -7.10497638e-07]]),\n",
       "  'predictive_score': 0.5648990262833142,\n",
       "  'predicted_label': 1},\n",
       " 281: {'fold_num': 281,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.14122182e-05,  9.37971326e-05, -2.92305301e-05, ...,\n",
       "           0.00000000e+00,  2.15848201e-05, -2.14524822e-06]]),\n",
       "  'predictive_score': 0.6705521113947971,\n",
       "  'predicted_label': 1},\n",
       " 282: {'fold_num': 282,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.05346130e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.42664843e-05,  8.47807596e-07]]),\n",
       "  'predictive_score': 0.49649681160342934,\n",
       "  'predicted_label': 0},\n",
       " 283: {'fold_num': 283,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.14161046e-05,  3.30368808e-04,  2.30492877e-05, ...,\n",
       "           0.00000000e+00, -2.05827071e-05,  2.50936783e-06]]),\n",
       "  'predictive_score': 0.42992373353770413,\n",
       "  'predicted_label': 0},\n",
       " 284: {'fold_num': 284,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.09822996e-04,  2.48283350e-05, -7.04284031e-06, ...,\n",
       "           0.00000000e+00,  3.08215478e-05,  7.16994975e-05]]),\n",
       "  'predictive_score': 0.7643646406697876,\n",
       "  'predicted_label': 1},\n",
       " 285: {'fold_num': 285,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.23040979e-05,  3.58491040e-05, -1.27883697e-05, ...,\n",
       "           0.00000000e+00, -1.40451597e-05, -4.66467400e-06]]),\n",
       "  'predictive_score': 0.8103677128684867,\n",
       "  'predicted_label': 1},\n",
       " 286: {'fold_num': 286,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.14180364e-05, -1.99154222e-05, -7.65987350e-06, ...,\n",
       "           0.00000000e+00,  2.15099860e-04, -1.07787257e-06]]),\n",
       "  'predictive_score': 0.8466790358334477,\n",
       "  'predicted_label': 1},\n",
       " 287: {'fold_num': 287,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.78349987e-05, -4.34706679e-05,  5.19573090e-06, ...,\n",
       "           0.00000000e+00,  2.11667706e-04,  1.64891681e-06]]),\n",
       "  'predictive_score': 0.47980503328800517,\n",
       "  'predicted_label': 0},\n",
       " 288: {'fold_num': 288,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.98006350e-05, -1.35555911e-05,  1.22545350e-05, ...,\n",
       "           0.00000000e+00,  6.01037774e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.44795908503261445,\n",
       "  'predicted_label': 0},\n",
       " 289: {'fold_num': 289,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.96161120e-05, -7.32302685e-06,  6.57175114e-06, ...,\n",
       "           0.00000000e+00,  7.42890623e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2728105268914093,\n",
       "  'predicted_label': 0},\n",
       " 290: {'fold_num': 290,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.68360719e-05,  1.58934421e-04, -1.57639551e-05, ...,\n",
       "           0.00000000e+00,  3.39025964e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8991098880694467,\n",
       "  'predicted_label': 1},\n",
       " 291: {'fold_num': 291,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.00373787e-05, -9.76403580e-06,  5.27362678e-06, ...,\n",
       "           1.12852533e-05,  1.75781771e-05, -2.03722360e-04]]),\n",
       "  'predictive_score': 0.4587743157638415,\n",
       "  'predicted_label': 0},\n",
       " 292: {'fold_num': 292,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.19037817e-05,  0.00000000e+00,  9.22385266e-06, ...,\n",
       "           1.37179953e-06,  1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.38094815601065596,\n",
       "  'predicted_label': 0},\n",
       " 293: {'fold_num': 293,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.57162704e-05,  0.00000000e+00,  5.20625590e-06, ...,\n",
       "           1.13546026e-05, -1.33850082e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.07181376793141499,\n",
       "  'predicted_label': 0},\n",
       " 294: {'fold_num': 294,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.06774198e-04,  6.23892260e-05, -2.93369747e-05, ...,\n",
       "          -4.08197961e-06, -1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5189293068043068,\n",
       "  'predicted_label': 1},\n",
       " 295: {'fold_num': 295,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54386568e-05,  2.67148257e-05, -2.19153111e-05, ...,\n",
       "           0.00000000e+00,  2.29868470e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6680874533962771,\n",
       "  'predicted_label': 1},\n",
       " 296: {'fold_num': 296,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54386568e-05,  2.22027541e-05, -2.00859812e-04, ...,\n",
       "           0.00000000e+00, -1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6229731073450115,\n",
       "  'predicted_label': 1},\n",
       " 297: {'fold_num': 297,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54386568e-05,  1.87759171e-05, -4.88052260e-05, ...,\n",
       "           0.00000000e+00, -1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6970826476155423,\n",
       "  'predicted_label': 1},\n",
       " 298: {'fold_num': 298,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.01046220e-04,  4.38681937e-05, -1.15102034e-05, ...,\n",
       "           0.00000000e+00, -1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5699669537978362,\n",
       "  'predicted_label': 1},\n",
       " 299: {'fold_num': 299,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.41840331e-05, -7.81168720e-05,  2.14541635e-05, ...,\n",
       "           0.00000000e+00,  1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4742760801290211,\n",
       "  'predicted_label': 0},\n",
       " 300: {'fold_num': 300,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.57564996e-05, -3.77523610e-05,  6.58441871e-06, ...,\n",
       "           0.00000000e+00,  1.75781771e-05,  1.35880088e-05]]),\n",
       "  'predictive_score': 0.47179600832174357,\n",
       "  'predicted_label': 0},\n",
       " 301: {'fold_num': 301,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54426293e-05,  2.67192224e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.16203240e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7328065637063316,\n",
       "  'predicted_label': 1},\n",
       " 302: {'fold_num': 302,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54426293e-05, 2.67192224e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.51958084e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.7875431359576097,\n",
       "  'predicted_label': 1},\n",
       " 303: {'fold_num': 303,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.53663367e-05,  2.68692085e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.02355945e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5940279867191631,\n",
       "  'predicted_label': 1},\n",
       " 304: {'fold_num': 304,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54426293e-05,  2.67192224e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7231455448146622,\n",
       "  'predicted_label': 1},\n",
       " 305: {'fold_num': 305,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.80355860e-05,  3.85446272e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.16203240e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7950854284604283,\n",
       "  'predicted_label': 1},\n",
       " 306: {'fold_num': 306,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.61452061e-05,  4.62996398e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.75781771e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5291153217912121,\n",
       "  'predicted_label': 1},\n",
       " 307: {'fold_num': 307,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.80355860e-05, -7.65843520e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.29868470e-05,  1.18770508e-05]]),\n",
       "  'predictive_score': 0.3540608909064791,\n",
       "  'predicted_label': 0},\n",
       " 308: {'fold_num': 308,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54426293e-05, 1.37764026e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.77387426e-05, 9.81028519e-06]]),\n",
       "  'predictive_score': 0.7178399618816818,\n",
       "  'predicted_label': 1},\n",
       " 309: {'fold_num': 309,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[9.06068373e-05, 1.18097109e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.31315716e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8679590687090685,\n",
       "  'predicted_label': 1},\n",
       " 310: {'fold_num': 310,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.80568656e-05,  1.13269096e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  8.70738840e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4577708455759925,\n",
       "  'predicted_label': 0},\n",
       " 311: {'fold_num': 311,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.04097168e-05, -5.39308154e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.72929138e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1364242864978159,\n",
       "  'predicted_label': 0},\n",
       " 312: {'fold_num': 312,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.77750595e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.38379302e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5569042144860642,\n",
       "  'predicted_label': 1},\n",
       " 313: {'fold_num': 313,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.27331453e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -9.32190985e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7041229705751765,\n",
       "  'predicted_label': 1},\n",
       " 314: {'fold_num': 314,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.06956150e-04,  1.12800610e-04, -4.93143052e-05, ...,\n",
       "           0.00000000e+00,  1.07438873e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5392799025020388,\n",
       "  'predicted_label': 1},\n",
       " 315: {'fold_num': 315,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.02504768e-05, -1.43406588e-03,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.28649549e-04,  1.56277773e-05]]),\n",
       "  'predictive_score': 0.5553156350013936,\n",
       "  'predicted_label': 1},\n",
       " 316: {'fold_num': 316,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[9.64289442e-05, 2.97805520e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.30328834e-04, 9.81369295e-06]]),\n",
       "  'predictive_score': 0.9121119325935502,\n",
       "  'predicted_label': 1},\n",
       " 317: {'fold_num': 317,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.28545070e-05, 2.97805520e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.08664017e-04, 1.56277773e-05]]),\n",
       "  'predictive_score': 0.8093173007548008,\n",
       "  'predicted_label': 1},\n",
       " 318: {'fold_num': 318,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.07542413e-04,  8.91372931e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.71950138e-04, -9.81369295e-06]]),\n",
       "  'predictive_score': 0.43084443334443334,\n",
       "  'predicted_label': 0},\n",
       " 319: {'fold_num': 319,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.05247022e-05,  4.78347195e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.04822522e-04,  9.81369295e-06]]),\n",
       "  'predictive_score': 0.5030902224495489,\n",
       "  'predicted_label': 1},\n",
       " 320: {'fold_num': 320,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.01319168e-04, 1.51544708e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.12584831e-04, 1.55594178e-05]]),\n",
       "  'predictive_score': 0.6007223009833303,\n",
       "  'predicted_label': 1},\n",
       " 321: {'fold_num': 321,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54386568e-05, 7.55941339e-06, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.90741339e-05, 5.28227149e-06]]),\n",
       "  'predictive_score': 0.5028046744062613,\n",
       "  'predicted_label': 1},\n",
       " 322: {'fold_num': 322,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[9.14619559e-05, 5.38626070e-06, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.52334021e-04, 9.81369295e-06]]),\n",
       "  'predictive_score': 0.9330972895568486,\n",
       "  'predicted_label': 1},\n",
       " 323: {'fold_num': 323,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.54386568e-05,  3.92973678e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.61174087e-05, -4.64141764e-05]]),\n",
       "  'predictive_score': 0.5217157612769068,\n",
       "  'predicted_label': 1},\n",
       " 324: {'fold_num': 324,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.57300835e-05, -5.51660545e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.36321678e-05,  1.79867984e-05]]),\n",
       "  'predictive_score': 0.4708472961635887,\n",
       "  'predicted_label': 0},\n",
       " 325: {'fold_num': 325,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.80143685e-05, -1.45820397e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -9.02780536e-05, -8.04955080e-06]]),\n",
       "  'predictive_score': 0.3945865357982231,\n",
       "  'predicted_label': 0},\n",
       " 326: {'fold_num': 326,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54346969e-05,  3.83589512e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.13086308e-04, -6.43528622e-05]]),\n",
       "  'predictive_score': 0.6883455417131888,\n",
       "  'predicted_label': 1},\n",
       " 327: {'fold_num': 327,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54346969e-05, 5.56984907e-06, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.38192471e-04, 2.54984368e-06]]),\n",
       "  'predictive_score': 0.9300416135796571,\n",
       "  'predicted_label': 1},\n",
       " 328: {'fold_num': 328,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54346969e-05, 3.99650951e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.40703705e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5505332265773444,\n",
       "  'predicted_label': 1},\n",
       " 329: {'fold_num': 329,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54346969e-05,  2.03211804e-05,  0.00000000e+00, ...,\n",
       "          -1.08913962e-05,  2.96060749e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7329801224102696,\n",
       "  'predicted_label': 1},\n",
       " 330: {'fold_num': 330,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.79932127e-05, -2.79025361e-05,  0.00000000e+00, ...,\n",
       "           1.08913962e-05, -2.91285541e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.22208168139050496,\n",
       "  'predicted_label': 0},\n",
       " 331: {'fold_num': 331,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[9.15504470e-05, 2.98034899e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.80781116e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6367843349460994,\n",
       "  'predicted_label': 1},\n",
       " 332: {'fold_num': 332,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.51653504e-05, -1.25397805e-04,  0.00000000e+00, ...,\n",
       "          -5.81228358e-06,  3.87168165e-05, -4.18005558e-05]]),\n",
       "  'predictive_score': 0.5662771705633547,\n",
       "  'predicted_label': 1},\n",
       " 333: {'fold_num': 333,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.41152523e-05, -5.68815090e-05,  0.00000000e+00, ...,\n",
       "           2.75354244e-05,  0.00000000e+00,  3.37914556e-05]]),\n",
       "  'predictive_score': 0.2691651281295244,\n",
       "  'predicted_label': 0},\n",
       " 334: {'fold_num': 334,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.79932127e-05, -4.29730815e-04,  0.00000000e+00, ...,\n",
       "           2.75354244e-05, -5.31096121e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4261521867365519,\n",
       "  'predicted_label': 0},\n",
       " 335: {'fold_num': 335,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.79932127e-05, -3.67694666e-05,  0.00000000e+00, ...,\n",
       "          -3.39093693e-06, -6.70883026e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.25900985012430033,\n",
       "  'predicted_label': 0},\n",
       " 336: {'fold_num': 336,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.57213294e-05, -7.60614475e-05,  0.00000000e+00, ...,\n",
       "           2.75354244e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.33113865995116,\n",
       "  'predicted_label': 0},\n",
       " 337: {'fold_num': 337,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.54307497e-05, -5.32807729e-05,  0.00000000e+00, ...,\n",
       "           1.09050833e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.19838080669330665,\n",
       "  'predicted_label': 0},\n",
       " 338: {'fold_num': 338,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.54307497e-05, -2.04938649e-05,  0.00000000e+00, ...,\n",
       "          -3.39137775e-06,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.32065026966497556,\n",
       "  'predicted_label': 0},\n",
       " 339: {'fold_num': 339,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.79721184e-05, -1.40480360e-05,  1.08294776e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.40130774495112725,\n",
       "  'predicted_label': 0},\n",
       " 340: {'fold_num': 340,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.57126007e-05, -6.49003294e-05,  2.09337501e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.23389867281411403,\n",
       "  'predicted_label': 0},\n",
       " 341: {'fold_num': 341,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[1.57126007e-05, 1.29432312e-04, 4.21812818e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.39657954096557047,\n",
       "  'predicted_label': 0},\n",
       " 342: {'fold_num': 342,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54268150e-05,  5.44248141e-05, -1.67482879e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5212907239819005,\n",
       "  'predicted_label': 1},\n",
       " 343: {'fold_num': 343,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54268150e-05,  1.61817449e-05, -1.67482879e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8582203507277039,\n",
       "  'predicted_label': 1},\n",
       " 344: {'fold_num': 344,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54268150e-05,  3.48716392e-05, -3.27809093e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6696186105561107,\n",
       "  'predicted_label': 1},\n",
       " 345: {'fold_num': 345,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.26975305e-05,  2.54037185e-05, -6.46708424e-05, ...,\n",
       "           0.00000000e+00, -5.63062662e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6573198259643696,\n",
       "  'predicted_label': 1},\n",
       " 346: {'fold_num': 346,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54268150e-05, 2.54037185e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.16883426e-05, 6.00382386e-05]]),\n",
       "  'predictive_score': 0.5692234235492749,\n",
       "  'predicted_label': 1},\n",
       " 347: {'fold_num': 347,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54268150e-05,  2.15488980e-05,  0.00000000e+00, ...,\n",
       "          -3.07651186e-06,  1.65687959e-05,  3.52619744e-05]]),\n",
       "  'predictive_score': 0.8420205541147879,\n",
       "  'predicted_label': 1},\n",
       " 348: {'fold_num': 348,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.41853688e-05,  3.48716392e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -3.73605653e-05, -4.36380557e-06]]),\n",
       "  'predictive_score': 0.6892616880668352,\n",
       "  'predicted_label': 1},\n",
       " 349: {'fold_num': 349,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.79721184e-05, -7.34605910e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  6.95268970e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.09668065472109591,\n",
       "  'predicted_label': 0},\n",
       " 350: {'fold_num': 350,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54268150e-05, 2.54037185e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.39550076e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5436025849365633,\n",
       "  'predicted_label': 1},\n",
       " 351: {'fold_num': 351,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.05214407e-05, -5.42136374e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.53406581e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.22733276035539976,\n",
       "  'predicted_label': 0},\n",
       " 352: {'fold_num': 352,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.57126007e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  3.11167782e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6132544428610606,\n",
       "  'predicted_label': 1},\n",
       " 353: {'fold_num': 353,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.54307497e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8968281395891691,\n",
       "  'predicted_label': 1},\n",
       " 354: {'fold_num': 354,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.54307497e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.22997316e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1222692515817516,\n",
       "  'predicted_label': 0},\n",
       " 355: {'fold_num': 355,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.05230688e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.18788123e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5736530308142149,\n",
       "  'predicted_label': 1},\n",
       " 356: {'fold_num': 356,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.57300835e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.22785973e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7708697232634927,\n",
       "  'predicted_label': 1},\n",
       " 357: {'fold_num': 357,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.76891635e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.93609453e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.0761983481989287,\n",
       "  'predicted_label': 0},\n",
       " 358: {'fold_num': 358,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.81328050e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.95290338e-05, -1.88485068e-05]]),\n",
       "  'predictive_score': 0.41858915418087234,\n",
       "  'predicted_label': 0},\n",
       " 359: {'fold_num': 359,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -3.05910787e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.501199156107051,\n",
       "  'predicted_label': 1},\n",
       " 360: {'fold_num': 360,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.11749232e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8630726703851701,\n",
       "  'predicted_label': 1},\n",
       " 361: {'fold_num': 361,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 7.08305277e-06, 1.86116416e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.44394747572688753,\n",
       "  'predicted_label': 0},\n",
       " 362: {'fold_num': 362,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 8.01661737e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.12096344178697115,\n",
       "  'predicted_label': 0},\n",
       " 363: {'fold_num': 363,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54346969e-05,  0.00000000e+00, -7.40717908e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8804312174753351,\n",
       "  'predicted_label': 1},\n",
       " 364: {'fold_num': 364,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 1.51157686e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.3263776827747417,\n",
       "  'predicted_label': 0},\n",
       " 365: {'fold_num': 365,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.        ,  0.        ,  0.00013837, ...,  0.        ,\n",
       "          -0.00050795,  0.        ]]),\n",
       "  'predictive_score': 0.68314443848635,\n",
       "  'predicted_label': 1},\n",
       " 366: {'fold_num': 366,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -7.40717908e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8568533231474409,\n",
       "  'predicted_label': 1},\n",
       " 367: {'fold_num': 367,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.0000000e+00, 0.0000000e+00, 1.1257797e-05, ..., 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00]]),\n",
       "  'predictive_score': 0.3488803012862611,\n",
       "  'predicted_label': 0},\n",
       " 368: {'fold_num': 368,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.51157686e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8518184242228359,\n",
       "  'predicted_label': 1},\n",
       " 369: {'fold_num': 369,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.52758896e-04,  1.85278793e-05, ...,\n",
       "           0.00000000e+00, -2.28340677e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.45619117372135937,\n",
       "  'predicted_label': 0},\n",
       " 370: {'fold_num': 370,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.22750311e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.43790577216041604,\n",
       "  'predicted_label': 0},\n",
       " 371: {'fold_num': 371,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.03285174e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.68809160e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.30322132833626636,\n",
       "  'predicted_label': 0},\n",
       " 372: {'fold_num': 372,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  4.32725896e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.57532333e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2252851180682064,\n",
       "  'predicted_label': 0},\n",
       " 373: {'fold_num': 373,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.97642824e-07,  7.22238536e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.11979558e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5919724022967061,\n",
       "  'predicted_label': 1},\n",
       " 374: {'fold_num': 374,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.63265482e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.42532041e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5543462443344409,\n",
       "  'predicted_label': 1},\n",
       " 375: {'fold_num': 375,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.12140943e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.00297491e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.24814250047338274,\n",
       "  'predicted_label': 0},\n",
       " 376: {'fold_num': 376,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  5.34871213e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.04943891e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.13261201167683373,\n",
       "  'predicted_label': 0},\n",
       " 377: {'fold_num': 377,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.04176220e-05, -1.94572415e-05, ...,\n",
       "           0.00000000e+00,  8.94378749e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7484301551132043,\n",
       "  'predicted_label': 1},\n",
       " 378: {'fold_num': 378,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -3.18282411e-06, -1.35004250e-04, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.39141213131983243,\n",
       "  'predicted_label': 0},\n",
       " 379: {'fold_num': 379,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -6.51659665e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7127700026581607,\n",
       "  'predicted_label': 1},\n",
       " 380: {'fold_num': 380,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 1.42124062e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.38540023582910415,\n",
       "  'predicted_label': 0},\n",
       " 381: {'fold_num': 381,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -8.11303759e-06, ...,\n",
       "           0.00000000e+00,  2.28005129e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7548850626497685,\n",
       "  'predicted_label': 1},\n",
       " 382: {'fold_num': 382,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -9.47533690e-06, ...,\n",
       "           0.00000000e+00,  1.38730418e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6022310411251972,\n",
       "  'predicted_label': 1},\n",
       " 383: {'fold_num': 383,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'predictive_score': 0.15201370851370846,\n",
       "  'predicted_label': 0},\n",
       " 384: {'fold_num': 384,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -3.45509441e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.64282687e-05]]),\n",
       "  'predictive_score': 0.7966322023564669,\n",
       "  'predicted_label': 1},\n",
       " 385: {'fold_num': 385,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -5.27970966e-06, ...,\n",
       "           0.00000000e+00,  9.96627617e-06,  6.26923400e-05]]),\n",
       "  'predictive_score': 0.7362279298144236,\n",
       "  'predicted_label': 1},\n",
       " 386: {'fold_num': 386,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -3.81883426e-06, ...,\n",
       "           0.00000000e+00,  9.96627617e-06,  2.49995318e-05]]),\n",
       "  'predictive_score': 0.887170556417267,\n",
       "  'predicted_label': 1},\n",
       " 387: {'fold_num': 387,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  5.78498493e-05,  7.22365979e-06, ...,\n",
       "           0.00000000e+00,  1.73975909e-04, -2.98486209e-05]]),\n",
       "  'predictive_score': 0.3593580655240873,\n",
       "  'predicted_label': 0},\n",
       " 388: {'fold_num': 388,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.51215984e-05,  4.45151074e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -4.48042343e-05]]),\n",
       "  'predictive_score': 0.22673212767624526,\n",
       "  'predicted_label': 0},\n",
       " 389: {'fold_num': 389,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.46110367e-05, -1.93948769e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  6.33603077e-05]]),\n",
       "  'predictive_score': 0.5881169594294593,\n",
       "  'predicted_label': 1},\n",
       " 390: {'fold_num': 390,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 4.63884428e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.50184419e-05]]),\n",
       "  'predictive_score': 0.8144509914105504,\n",
       "  'predicted_label': 1},\n",
       " 391: {'fold_num': 391,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.04422697e-05, -2.15239093e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.65792647e-05]]),\n",
       "  'predictive_score': 0.4581737894458483,\n",
       "  'predicted_label': 0},\n",
       " 392: {'fold_num': 392,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-7.52269444e-06, -2.34827665e-05,  9.08830495e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  2.76837473e-05]]),\n",
       "  'predictive_score': 0.3682218361647627,\n",
       "  'predicted_label': 0},\n",
       " 393: {'fold_num': 393,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 5.13130965e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.97137379e-06]]),\n",
       "  'predictive_score': 0.5939471953699893,\n",
       "  'predicted_label': 1},\n",
       " 394: {'fold_num': 394,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  7.25897522e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -5.86442971e-04]]),\n",
       "  'predictive_score': 0.822995536412332,\n",
       "  'predicted_label': 1},\n",
       " 395: {'fold_num': 395,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 6.92445396e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.46811611e-04]]),\n",
       "  'predictive_score': 0.8316515845265843,\n",
       "  'predicted_label': 1},\n",
       " 396: {'fold_num': 396,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.        , -0.00030345,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.00015819]]),\n",
       "  'predictive_score': 0.5419672302886311,\n",
       "  'predicted_label': 1},\n",
       " 397: {'fold_num': 397,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.43457604e-04, -4.35569143e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  2.49214499e-05]]),\n",
       "  'predictive_score': 0.31279574469648,\n",
       "  'predicted_label': 0},\n",
       " 398: {'fold_num': 398,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.51459260e-05, -4.33682443e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.50668880e-05]]),\n",
       "  'predictive_score': 0.4462497162140368,\n",
       "  'predicted_label': 0},\n",
       " 399: {'fold_num': 399,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.35825003e-04, 5.73342484e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.50668880e-05]]),\n",
       "  'predictive_score': 0.5423722293451901,\n",
       "  'predicted_label': 1},\n",
       " 400: {'fold_num': 400,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.37445221e-05, -1.07636212e-03,  0.00000000e+00, ...,\n",
       "          -3.34974398e-06,  0.00000000e+00, -6.27724713e-05]]),\n",
       "  'predictive_score': 0.49717165473415464,\n",
       "  'predicted_label': 0},\n",
       " 401: {'fold_num': 401,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.44060438e-04,  4.29981386e-05,  6.70571151e-06, ...,\n",
       "           1.70677723e-06, -1.49873600e-05,  8.33694899e-06]]),\n",
       "  'predictive_score': 0.645948338018191,\n",
       "  'predicted_label': 1},\n",
       " 402: {'fold_num': 402,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.00178263e-05,  0.00000000e+00, -3.62442884e-05, ...,\n",
       "           1.35318449e-06, -2.16494105e-05,  1.67296362e-05]]),\n",
       "  'predictive_score': 0.6941985538970832,\n",
       "  'predicted_label': 1},\n",
       " 403: {'fold_num': 403,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.27604313e-05, ...,\n",
       "           0.00000000e+00,  3.80427642e-05,  1.11852858e-05]]),\n",
       "  'predictive_score': 0.6223516630428396,\n",
       "  'predicted_label': 1},\n",
       " 404: {'fold_num': 404,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[7.07962314e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.11507735e-05, 8.60946791e-07, 5.44150004e-05]]),\n",
       "  'predictive_score': 0.8326689631747684,\n",
       "  'predicted_label': 1},\n",
       " 405: {'fold_num': 405,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.70794345e-05,  0.00000000e+00,  4.45258317e-05, ...,\n",
       "          -3.05664755e-04,  1.13664253e-04,  1.50723611e-05]]),\n",
       "  'predictive_score': 0.517804027757588,\n",
       "  'predicted_label': 1},\n",
       " 406: {'fold_num': 406,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.15287784e-04,  1.08266482e-05, -4.29736035e-05, ...,\n",
       "          -5.86394800e-06, -2.42147171e-05,  5.47887600e-05]]),\n",
       "  'predictive_score': 0.6368804948276695,\n",
       "  'predicted_label': 1},\n",
       " 407: {'fold_num': 407,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.85681949e-05, -2.53027536e-05,  3.26816251e-05, ...,\n",
       "          -4.15999703e-06,  2.19484654e-04, -1.40002323e-04]]),\n",
       "  'predictive_score': 0.3478830834198481,\n",
       "  'predicted_label': 0},\n",
       " 408: {'fold_num': 408,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  5.30872637e-06,  3.25488366e-05, ...,\n",
       "          -3.21461056e-06, -2.32410599e-05,  1.50723611e-05]]),\n",
       "  'predictive_score': 0.6176265907295317,\n",
       "  'predicted_label': 1},\n",
       " 409: {'fold_num': 409,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -3.25488366e-05, ...,\n",
       "           3.21461056e-06, -3.72493650e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.47018767753630286,\n",
       "  'predicted_label': 0},\n",
       " 410: {'fold_num': 410,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  8.57750431e-06, ...,\n",
       "          -6.43667825e-06, -1.18794838e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5365584707697271,\n",
       "  'predicted_label': 1},\n",
       " 411: {'fold_num': 411,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.58118321e-06, ...,\n",
       "          -2.19840745e-05,  3.31845086e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8217876773209594,\n",
       "  'predicted_label': 1},\n",
       " 412: {'fold_num': 412,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.88042157e-05, ...,\n",
       "          -6.18218239e-06,  1.37036824e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.829501560939061,\n",
       "  'predicted_label': 1},\n",
       " 413: {'fold_num': 413,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -6.81285844e-06, ...,\n",
       "           3.21461056e-06,  1.74159501e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4158556903837478,\n",
       "  'predicted_label': 0},\n",
       " 414: {'fold_num': 414,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.73389909e-05, ...,\n",
       "          -7.69223193e-05,  3.31825673e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7187114272036872,\n",
       "  'predicted_label': 1},\n",
       " 415: {'fold_num': 415,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  3.60230877e-05, ...,\n",
       "          -2.18388987e-05,  3.51098340e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7024991232623584,\n",
       "  'predicted_label': 1},\n",
       " 416: {'fold_num': 416,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 1.13177047e-05, ...,\n",
       "          5.76847762e-06, 1.69036552e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.12722065999446028,\n",
       "  'predicted_label': 0},\n",
       " 417: {'fold_num': 417,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.96659541e-05, -5.61719346e-05,  6.37392329e-06, ...,\n",
       "           1.11188287e-05,  1.69683154e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5219410001762944,\n",
       "  'predicted_label': 1},\n",
       " 418: {'fold_num': 418,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.44485191e-05, -9.31920995e-06,  2.24221927e-05, ...,\n",
       "           4.25246846e-06, -1.10657391e-04,  5.91947949e-06]]),\n",
       "  'predictive_score': 0.4995963652360711,\n",
       "  'predicted_label': 0},\n",
       " 419: {'fold_num': 419,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.84820263e-05,  4.37604344e-05, ...,\n",
       "           1.11859997e-05, -1.98192341e-05, -5.10650301e-06]]),\n",
       "  'predictive_score': 0.8077012693189167,\n",
       "  'predicted_label': 1},\n",
       " 420: {'fold_num': 420,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.84820263e-05,  0.00000000e+00, ...,\n",
       "          -1.28664040e-04, -2.68027945e-05, -1.56235941e-06]]),\n",
       "  'predictive_score': 0.8189355436230435,\n",
       "  'predicted_label': 1},\n",
       " 421: {'fold_num': 421,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.46312177e-05, -5.42552875e-06,  0.00000000e+00, ...,\n",
       "           1.30744911e-05,  3.34537593e-05,  1.16161573e-06]]),\n",
       "  'predictive_score': 0.4783657458597473,\n",
       "  'predicted_label': 0},\n",
       " 422: {'fold_num': 422,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -4.45508923e-06,  0.00000000e+00, ...,\n",
       "           3.99726088e-05, -9.68246744e-05,  1.71474066e-06]]),\n",
       "  'predictive_score': 0.4121942346868817,\n",
       "  'predicted_label': 0},\n",
       " 423: {'fold_num': 423,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -4.82180344e-06,  0.00000000e+00, ...,\n",
       "           3.15121767e-06,  2.16000223e-05,  9.84029024e-04]]),\n",
       "  'predictive_score': 0.47430185182814133,\n",
       "  'predicted_label': 0},\n",
       " 424: {'fold_num': 424,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.06182576e-05,  0.00000000e+00, ...,\n",
       "          -1.10245384e-05, -6.70386766e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.48416062295977164,\n",
       "  'predicted_label': 0},\n",
       " 425: {'fold_num': 425,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.69939589e-06,  0.00000000e+00, ...,\n",
       "           5.90325477e-05, -2.36371939e-05, -1.67174613e-04]]),\n",
       "  'predictive_score': 0.37595387822961357,\n",
       "  'predicted_label': 0},\n",
       " 426: {'fold_num': 426,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  7.85149632e-05,  0.00000000e+00, ...,\n",
       "          -2.35758380e-05,  4.86751170e-05,  2.73690040e-05]]),\n",
       "  'predictive_score': 0.6739013472624156,\n",
       "  'predicted_label': 1},\n",
       " 427: {'fold_num': 427,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.53331587e-05,  0.00000000e+00, ...,\n",
       "           1.19964616e-06,  1.97923452e-05, -5.93957134e-04]]),\n",
       "  'predictive_score': 0.3274660822064073,\n",
       "  'predicted_label': 0},\n",
       " 428: {'fold_num': 428,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.13669300e-04, -1.01533041e-05, ...,\n",
       "          -3.59772936e-04, -7.43042539e-05, -1.31415567e-04]]),\n",
       "  'predictive_score': 0.7560602281705223,\n",
       "  'predicted_label': 1},\n",
       " 429: {'fold_num': 429,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.29446148e-05,  0.00000000e+00, ...,\n",
       "           3.93195642e-05,  1.44808614e-05, -1.33480916e-04]]),\n",
       "  'predictive_score': 0.47184229974961384,\n",
       "  'predicted_label': 0},\n",
       " 430: {'fold_num': 430,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.29266800e-05, -3.90766523e-05, -1.26821791e-05, ...,\n",
       "           6.33648074e-06,  1.70531281e-04,  1.08404925e-05]]),\n",
       "  'predictive_score': 0.48967465554597916,\n",
       "  'predicted_label': 0},\n",
       " 431: {'fold_num': 431,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54368590e-05,  2.94221807e-04,  1.78637338e-06, ...,\n",
       "          -1.30441992e-05, -1.31386917e-05, -1.24711960e-05]]),\n",
       "  'predictive_score': 0.8800503276178587,\n",
       "  'predicted_label': 1},\n",
       " 432: {'fold_num': 432,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.40926166e-05, -1.44952568e-04, -1.94763562e-05, ...,\n",
       "           6.22303740e-05,  2.65584550e-05,  2.60071890e-05]]),\n",
       "  'predictive_score': 0.41967682317682337,\n",
       "  'predicted_label': 0},\n",
       " 433: {'fold_num': 433,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.57332809e-04,  7.99193778e-05,  0.00000000e+00, ...,\n",
       "          -1.70317521e-05, -2.36082653e-05, -4.55708188e-06]]),\n",
       "  'predictive_score': 0.6492959852325179,\n",
       "  'predicted_label': 1},\n",
       " 434: {'fold_num': 434,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.51208676e-05, -6.72575331e-05,  1.30458426e-05, ...,\n",
       "           1.44401966e-04,  2.44753583e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.37739962729912546,\n",
       "  'predicted_label': 0},\n",
       " 435: {'fold_num': 435,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.41105207e-05,  7.00627535e-05,  1.79044825e-04, ...,\n",
       "           5.83592770e-06,  3.29311096e-05,  6.14070803e-06]]),\n",
       "  'predictive_score': 0.07692782622438338,\n",
       "  'predicted_label': 0},\n",
       " 436: {'fold_num': 436,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.16759318e-05,  5.53624933e-05, -1.45784296e-05, ...,\n",
       "           1.16050061e-05, -3.34914660e-05, -4.55708188e-06]]),\n",
       "  'predictive_score': 0.7463563993196345,\n",
       "  'predicted_label': 1},\n",
       " 437: {'fold_num': 437,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54368590e-05,  0.00000000e+00, -7.38453748e-06, ...,\n",
       "           1.77060487e-07, -2.62026506e-05, -6.97250182e-06]]),\n",
       "  'predictive_score': 0.8156923346261583,\n",
       "  'predicted_label': 1},\n",
       " 438: {'fold_num': 438,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.54368590e-05,  0.00000000e+00,  1.23570527e-05, ...,\n",
       "           9.58078298e-05, -6.41034411e-05,  1.78698862e-05]]),\n",
       "  'predictive_score': 0.16277388379594263,\n",
       "  'predicted_label': 0},\n",
       " 439: {'fold_num': 439,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.24950233e-05,  0.00000000e+00, -7.59293066e-06, ...,\n",
       "           9.77352606e-08,  1.98847930e-05, -4.35736230e-05]]),\n",
       "  'predictive_score': 0.6633611368206958,\n",
       "  'predicted_label': 1},\n",
       " 440: {'fold_num': 440,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[1.48831282e-05, 0.00000000e+00, 1.87203245e-05, ...,\n",
       "          7.55737421e-06, 7.42343787e-05, 9.29068302e-06]]),\n",
       "  'predictive_score': 0.26837792477130706,\n",
       "  'predicted_label': 0},\n",
       " 441: {'fold_num': 441,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.14476130e-05,  0.00000000e+00,  3.56487345e-05, ...,\n",
       "           4.35313263e-06, -6.53335477e-06,  2.90596304e-06]]),\n",
       "  'predictive_score': 0.1477439370270252,\n",
       "  'predicted_label': 0},\n",
       " 442: {'fold_num': 442,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.11311341e-05,  0.00000000e+00,  1.30190685e-05, ...,\n",
       "          -3.42680103e-06,  1.99707879e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4842950466501164,\n",
       "  'predicted_label': 0},\n",
       " 443: {'fold_num': 443,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[1.36996868e-05, 0.00000000e+00, 1.30190685e-05, ...,\n",
       "          2.36230787e-05, 1.23727503e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.18807186767480882,\n",
       "  'predicted_label': 0},\n",
       " 444: {'fold_num': 444,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.82960804e-04,  0.00000000e+00,  7.59141477e-06, ...,\n",
       "          -4.51193138e-06,  6.05683085e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.45611200970082566,\n",
       "  'predicted_label': 0},\n",
       " 445: {'fold_num': 445,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  3.99754999e-05, ...,\n",
       "          -6.40598440e-06, -1.12732578e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2161226543064779,\n",
       "  'predicted_label': 0},\n",
       " 446: {'fold_num': 446,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  4.41390336e-05, ...,\n",
       "           2.35785796e-05, -1.74790820e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4795802037015274,\n",
       "  'predicted_label': 0},\n",
       " 447: {'fold_num': 447,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.57558498e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.35313263e-06, 5.23532084e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.41295012422218313,\n",
       "  'predicted_label': 0},\n",
       " 448: {'fold_num': 448,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54567630e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.28194626e-05, -1.34013591e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7366021951904306,\n",
       "  'predicted_label': 1},\n",
       " 449: {'fold_num': 449,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.12335294e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.35785796e-05, -3.18286362e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8563740741113034,\n",
       "  'predicted_label': 1},\n",
       " 450: {'fold_num': 450,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54567630e-05,  3.17537811e-06,  0.00000000e+00, ...,\n",
       "          -4.35313263e-06, -6.70153167e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5378163936167031,\n",
       "  'predicted_label': 1},\n",
       " 451: {'fold_num': 451,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54567630e-05, -1.34524850e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.40115833e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6977782768701887,\n",
       "  'predicted_label': 1},\n",
       " 452: {'fold_num': 452,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.80766369e-05,  5.55977601e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.27484219e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.29198454871152235,\n",
       "  'predicted_label': 0},\n",
       " 453: {'fold_num': 453,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.80766369e-05, -1.37372951e-05,  0.00000000e+00, ...,\n",
       "          -3.20156395e-06,  7.26283225e-06,  1.01042332e-05]]),\n",
       "  'predictive_score': 0.4499059729185502,\n",
       "  'predicted_label': 0},\n",
       " 454: {'fold_num': 454,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.54567630e-05,  3.88678319e-06, -1.95556728e-05, ...,\n",
       "          -2.34001060e-05,  5.54916846e-05,  3.00451988e-05]]),\n",
       "  'predictive_score': 0.2688999540621058,\n",
       "  'predicted_label': 0},\n",
       " 455: {'fold_num': 455,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54567630e-05,  1.65827362e-05, -1.93466614e-05, ...,\n",
       "           3.15207498e-05, -7.79610822e-06, -7.59124083e-06]]),\n",
       "  'predictive_score': 0.7776853142772258,\n",
       "  'predicted_label': 1},\n",
       " 456: {'fold_num': 456,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.54567630e-05, -7.86102346e-06,  2.05667819e-05, ...,\n",
       "          -7.88018745e-05, -9.30164303e-05, -3.00451988e-05]]),\n",
       "  'predictive_score': 0.5507019495382497,\n",
       "  'predicted_label': 1},\n",
       " 457: {'fold_num': 457,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.29750752e-04,  1.37372951e-05, -8.68862507e-06, ...,\n",
       "           5.47349735e-04, -1.75739279e-04, -1.43034980e-05]]),\n",
       "  'predictive_score': 0.770838909864645,\n",
       "  'predicted_label': 1},\n",
       " 458: {'fold_num': 458,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.07454014e-04,  2.63725634e-05, -1.26159449e-05, ...,\n",
       "           3.15207498e-05, -9.38645466e-04, -7.59124083e-06]]),\n",
       "  'predictive_score': 0.7747066801662393,\n",
       "  'predicted_label': 1},\n",
       " 459: {'fold_num': 459,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-9.25852954e-05,  3.55599540e-05,  3.70275839e-05, ...,\n",
       "          -1.30301876e-05,  1.77871408e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.22908528971028982,\n",
       "  'predicted_label': 0},\n",
       " 460: {'fold_num': 460,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[7.98164643e-05, 2.62660485e-05, 4.03424691e-05, ...,\n",
       "          2.34001060e-05, 5.55041298e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.9304871492886196,\n",
       "  'predicted_label': 1},\n",
       " 461: {'fold_num': 461,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.65776329e-05, -9.36952798e-06,  0.00000000e+00, ...,\n",
       "           2.34001060e-05, -1.66418200e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8017343081754851,\n",
       "  'predicted_label': 1},\n",
       " 462: {'fold_num': 462,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.03385917e-05,  1.31999124e-05,  3.71923886e-05, ...,\n",
       "          -1.36165058e-05,  4.03232734e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.09397766530854768,\n",
       "  'predicted_label': 0},\n",
       " 463: {'fold_num': 463,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.46017726e-05,  4.68376664e-06,  1.22506051e-05, ...,\n",
       "           3.13991291e-05, -5.54869906e-05, -1.38577645e-05]]),\n",
       "  'predictive_score': 0.7258144400534106,\n",
       "  'predicted_label': 1},\n",
       " 464: {'fold_num': 464,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.93990826e-05, -1.07829197e-05,  0.00000000e+00, ...,\n",
       "           7.77770571e-06,  3.41879830e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5065117931174434,\n",
       "  'predicted_label': 1},\n",
       " 465: {'fold_num': 465,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.66460334e-05, -9.70462775e-06,  0.00000000e+00, ...,\n",
       "          -3.15627864e-05,  4.70924346e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3431550017964493,\n",
       "  'predicted_label': 0},\n",
       " 466: {'fold_num': 466,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.44784346e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           3.14954573e-05, -1.90235831e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8030766157861745,\n",
       "  'predicted_label': 1},\n",
       " 467: {'fold_num': 467,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[7.51989115e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.35658545e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.591271261933801,\n",
       "  'predicted_label': 1},\n",
       " 468: {'fold_num': 468,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.20532030e-05, -1.07911408e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  2.91182435e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7817637466163011,\n",
       "  'predicted_label': 1},\n",
       " 469: {'fold_num': 469,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.43962111e-05, -8.45628466e-05,  0.00000000e+00, ...,\n",
       "          -5.47828997e-04, -4.81581769e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.41314076054664284,\n",
       "  'predicted_label': 0},\n",
       " 470: {'fold_num': 470,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.71834040e-05, -7.12205421e-06,  0.00000000e+00, ...,\n",
       "          -1.29328360e-05,  1.73821638e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.44574711603755723,\n",
       "  'predicted_label': 0},\n",
       " 471: {'fold_num': 471,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.36329110e-04, 2.80737617e-05, 0.00000000e+00, ...,\n",
       "          2.32799602e-05, 2.33405155e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.9111385281385281,\n",
       "  'predicted_label': 1},\n",
       " 472: {'fold_num': 472,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.28345798e-05, -4.77201838e-05,  0.00000000e+00, ...,\n",
       "           1.29328360e-05,  1.62211017e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7251372868617451,\n",
       "  'predicted_label': 1},\n",
       " 473: {'fold_num': 473,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.62414452e-05,  5.79807238e-06,  0.00000000e+00, ...,\n",
       "          -7.52595463e-05, -2.73546603e-06, -1.14782961e-05]]),\n",
       "  'predictive_score': 0.6062576509747563,\n",
       "  'predicted_label': 1},\n",
       " 474: {'fold_num': 474,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.51914471e-05, -2.05547895e-05,  0.00000000e+00, ...,\n",
       "          -9.52075992e-06,  3.55327562e-05,  8.70539077e-04]]),\n",
       "  'predictive_score': 0.5179018048851134,\n",
       "  'predicted_label': 1},\n",
       " 475: {'fold_num': 475,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.09226052e-04, -3.95665058e-05,  0.00000000e+00, ...,\n",
       "          -2.36287442e-05,  4.73649812e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8827423187192927,\n",
       "  'predicted_label': 1},\n",
       " 476: {'fold_num': 476,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-9.31258643e-05,  9.05357192e-06,  0.00000000e+00, ...,\n",
       "           2.36287442e-05, -4.65467913e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3818116458704693,\n",
       "  'predicted_label': 0},\n",
       " 477: {'fold_num': 477,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.17305275e-05, -1.23535446e-05,  0.00000000e+00, ...,\n",
       "           5.88941700e-06,  3.55327562e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.614620302556061,\n",
       "  'predicted_label': 1},\n",
       " 478: {'fold_num': 478,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.49771065e-05,  1.32474282e-05,  5.52370635e-06, ...,\n",
       "           0.00000000e+00, -3.60574785e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.24166789965280683,\n",
       "  'predicted_label': 0},\n",
       " 479: {'fold_num': 479,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 6.62236421e-05, -5.40177429e-06,  5.26674083e-06, ...,\n",
       "           0.00000000e+00, -2.42760077e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3030510494622337,\n",
       "  'predicted_label': 0},\n",
       " 480: {'fold_num': 480,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.47961633e-05, -8.22733732e-06, -1.25730806e-04, ...,\n",
       "           0.00000000e+00, -2.47204887e-05, -1.67737887e-04]]),\n",
       "  'predictive_score': 0.369047914933364,\n",
       "  'predicted_label': 0},\n",
       " 481: {'fold_num': 481,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.72277079e-06, -1.97443257e-03, -5.27795581e-06, ...,\n",
       "           0.00000000e+00,  2.11230023e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8337860732104153,\n",
       "  'predicted_label': 1},\n",
       " 482: {'fold_num': 482,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.01384971e-04, -2.01918225e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.60713304e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4494208310179675,\n",
       "  'predicted_label': 0},\n",
       " 483: {'fold_num': 483,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.04015535e-04,  2.33642569e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.73205080e-05, -1.12923753e-05]]),\n",
       "  'predictive_score': 0.7978258408258412,\n",
       "  'predicted_label': 1},\n",
       " 484: {'fold_num': 484,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.85200417e-05, -1.63363863e-04,  1.19378730e-05, ...,\n",
       "          -1.29801488e-04, -6.24727225e-05,  1.40204841e-04]]),\n",
       "  'predictive_score': 0.4599853137059021,\n",
       "  'predicted_label': 0},\n",
       " 485: {'fold_num': 485,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.42303931e-05,  1.41942590e-04, -5.27795581e-06, ...,\n",
       "           3.28123060e-05,  2.10121208e-04, -9.49421132e-04]]),\n",
       "  'predictive_score': 0.8642432508367106,\n",
       "  'predicted_label': 1},\n",
       " 486: {'fold_num': 486,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.73598542e-05, -3.68815888e-04,  5.38325999e-06, ...,\n",
       "          -8.91974351e-06, -1.04314090e-05,  2.19171755e-04]]),\n",
       "  'predictive_score': 0.4898859159631217,\n",
       "  'predicted_label': 0},\n",
       " 487: {'fold_num': 487,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.06082104e-05, -5.51736919e-05,  3.70652338e-05, ...,\n",
       "          -1.62302394e-05,  0.00000000e+00, -1.34144349e-05]]),\n",
       "  'predictive_score': 0.17904843032784207,\n",
       "  'predicted_label': 0},\n",
       " 488: {'fold_num': 488,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-7.11120907e-05,  1.64117919e-04, -5.05850126e-06, ...,\n",
       "           6.49579203e-06,  0.00000000e+00,  1.01673285e-05]]),\n",
       "  'predictive_score': 0.8119592539813126,\n",
       "  'predicted_label': 1},\n",
       " 489: {'fold_num': 489,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.98702319e-03, -2.57146917e-06, ...,\n",
       "           1.70100883e-05,  0.00000000e+00,  1.30555706e-06]]),\n",
       "  'predictive_score': 0.6943501796835777,\n",
       "  'predicted_label': 1},\n",
       " 490: {'fold_num': 490,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.89348485e-04, -5.05850126e-06, ...,\n",
       "          -1.19806611e-04,  0.00000000e+00,  3.40683097e-04]]),\n",
       "  'predictive_score': 0.7354933171833328,\n",
       "  'predicted_label': 1},\n",
       " 491: {'fold_num': 491,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.47983412e-05,  5.46925475e-04,  0.00000000e+00, ...,\n",
       "          -8.49847968e-06,  0.00000000e+00, -2.01726670e-05]]),\n",
       "  'predictive_score': 0.5807567224442224,\n",
       "  'predicted_label': 1},\n",
       " 492: {'fold_num': 492,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.04012620e-04,  0.00000000e+00, ...,\n",
       "          -8.49847968e-06,  0.00000000e+00, -5.10635126e-05]]),\n",
       "  'predictive_score': 0.6890493256743255,\n",
       "  'predicted_label': 1},\n",
       " 493: {'fold_num': 493,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.48910327e-04,  0.00000000e+00, ...,\n",
       "           3.63569227e-06,  0.00000000e+00, -5.41856958e-06]]),\n",
       "  'predictive_score': 0.6067591028252793,\n",
       "  'predicted_label': 1},\n",
       " 494: {'fold_num': 494,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.02198023e-04,  0.00000000e+00, ...,\n",
       "          -5.47399565e-06,  0.00000000e+00,  1.61884859e-06]]),\n",
       "  'predictive_score': 0.6754466738327038,\n",
       "  'predicted_label': 1},\n",
       " 495: {'fold_num': 495,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 8.19311025e-05, 0.00000000e+00, ...,\n",
       "          1.82013078e-06, 0.00000000e+00, 3.37630144e-05]]),\n",
       "  'predictive_score': 0.8846785493273497,\n",
       "  'predicted_label': 1},\n",
       " 496: {'fold_num': 496,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.88630613e-04,  0.00000000e+00, ...,\n",
       "          -7.67734247e-06,  0.00000000e+00, -3.52311754e-05]]),\n",
       "  'predictive_score': 0.35406299288516785,\n",
       "  'predicted_label': 0},\n",
       " 497: {'fold_num': 497,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.65812897e-04,  0.00000000e+00, ...,\n",
       "          -3.94350915e-06,  0.00000000e+00,  1.25377027e-04]]),\n",
       "  'predictive_score': 0.8103664890321238,\n",
       "  'predicted_label': 1},\n",
       " 498: {'fold_num': 498,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -4.48925617e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  7.62670628e-06,  6.24766041e-06]]),\n",
       "  'predictive_score': 0.4779868524363492,\n",
       "  'predicted_label': 0},\n",
       " 499: {'fold_num': 499,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 3.01193417e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.28270304e-05, 9.34039932e-06]]),\n",
       "  'predictive_score': 0.5911087260692524,\n",
       "  'predicted_label': 1},\n",
       " 500: {'fold_num': 500,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.10164008e-04, -7.84519696e-06, ...,\n",
       "           0.00000000e+00,  4.18015015e-05, -2.75514882e-05]]),\n",
       "  'predictive_score': 0.7946952145077149,\n",
       "  'predicted_label': 1},\n",
       " 501: {'fold_num': 501,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  5.02281591e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.01944880e-05,  1.09767488e-05]]),\n",
       "  'predictive_score': 0.5479186506433026,\n",
       "  'predicted_label': 1},\n",
       " 502: {'fold_num': 502,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 5.76091520e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.68774672e-06, 1.55880597e-05]]),\n",
       "  'predictive_score': 0.7244225309863853,\n",
       "  'predicted_label': 1},\n",
       " 503: {'fold_num': 503,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.53323730e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.28627948e-05, -1.07270861e-04]]),\n",
       "  'predictive_score': 0.9179131285381285,\n",
       "  'predicted_label': 1},\n",
       " 504: {'fold_num': 504,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.92644748e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.13178007e-06, -1.24205055e-04]]),\n",
       "  'predictive_score': 0.847655909450027,\n",
       "  'predicted_label': 1},\n",
       " 505: {'fold_num': 505,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -7.20260567e-05, ...,\n",
       "           0.00000000e+00,  7.12704336e-05, -8.28924188e-06]]),\n",
       "  'predictive_score': 0.9070037323787323,\n",
       "  'predicted_label': 1},\n",
       " 506: {'fold_num': 506,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 4.22011460e-05, ...,\n",
       "          0.00000000e+00, 5.68965448e-06, 6.32484879e-05]]),\n",
       "  'predictive_score': 0.24119829476079466,\n",
       "  'predicted_label': 0},\n",
       " 507: {'fold_num': 507,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.64113868e-04,  2.65259220e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  3.70781168e-05, -7.93436350e-06]]),\n",
       "  'predictive_score': 0.6207074269684564,\n",
       "  'predicted_label': 1},\n",
       " 508: {'fold_num': 508,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.41927621e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  6.01631511e-06, -2.23309665e-05]]),\n",
       "  'predictive_score': 0.6234595690257455,\n",
       "  'predicted_label': 1},\n",
       " 509: {'fold_num': 509,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.43880279e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.20374024e-05, -1.00990310e-04]]),\n",
       "  'predictive_score': 0.8701900705503647,\n",
       "  'predicted_label': 1},\n",
       " 510: {'fold_num': 510,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  4.90342322e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.76129268e-05, -6.31817573e-05]]),\n",
       "  'predictive_score': 0.8193899229855113,\n",
       "  'predicted_label': 1},\n",
       " 511: {'fold_num': 511,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.01152002e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.41068876e-04]]),\n",
       "  'predictive_score': 0.42665581973496053,\n",
       "  'predicted_label': 0},\n",
       " 512: {'fold_num': 512,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.95675574e-05,  7.57634892e-05, -5.51273983e-06, ...,\n",
       "           0.00000000e+00, -1.65266126e-04,  1.05066566e-04]]),\n",
       "  'predictive_score': 0.5735169691419691,\n",
       "  'predicted_label': 1},\n",
       " 513: {'fold_num': 513,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.07566273e-06,  1.31445168e-05,  0.00000000e+00, ...,\n",
       "          -1.32660131e-04,  7.08257144e-05, -2.89832511e-05]]),\n",
       "  'predictive_score': 0.4273229021795199,\n",
       "  'predicted_label': 0},\n",
       " 514: {'fold_num': 514,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.22693917e-05,  0.00000000e+00, -8.58956311e-07, ...,\n",
       "           1.71424862e-05,  2.77512785e-05,  2.23914971e-04]]),\n",
       "  'predictive_score': 0.5645853201236326,\n",
       "  'predicted_label': 1},\n",
       " 515: {'fold_num': 515,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.26921279e-06,  2.75809115e-06,  3.68261594e-05, ...,\n",
       "           1.04740235e-05, -4.71661861e-06,  3.81372100e-04]]),\n",
       "  'predictive_score': 0.7632578842725902,\n",
       "  'predicted_label': 1},\n",
       " 516: {'fold_num': 516,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.92149099e-06,  1.11617238e-05,  3.68261594e-05, ...,\n",
       "           1.04740235e-05,  0.00000000e+00,  1.33154023e-03]]),\n",
       "  'predictive_score': 0.8493802100677104,\n",
       "  'predicted_label': 1},\n",
       " 517: {'fold_num': 517,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.37157541e-06,  1.11617238e-05, -3.87643783e-06, ...,\n",
       "           3.48902770e-05, -1.72467836e-03,  4.38701921e-05]]),\n",
       "  'predictive_score': 0.8265330919080917,\n",
       "  'predicted_label': 1},\n",
       " 518: {'fold_num': 518,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.60827952e-05,  2.62747728e-05, -1.23097019e-04, ...,\n",
       "          -1.62747342e-05,  0.00000000e+00,  3.57714319e-05]]),\n",
       "  'predictive_score': 0.1066363727431839,\n",
       "  'predicted_label': 0},\n",
       " 519: {'fold_num': 519,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.41648420e-04, -7.53273326e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  2.26178964e-05]]),\n",
       "  'predictive_score': 0.499190807343671,\n",
       "  'predicted_label': 0},\n",
       " 520: {'fold_num': 520,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.59213583e-05, -9.09306995e-05, ...,\n",
       "          -9.68078828e-06,  0.00000000e+00, -8.32069349e-05]]),\n",
       "  'predictive_score': 0.14624849539865015,\n",
       "  'predicted_label': 0},\n",
       " 521: {'fold_num': 521,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -6.66847120e-06, -1.07424787e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -2.17350192e-04]]),\n",
       "  'predictive_score': 0.4076088060116699,\n",
       "  'predicted_label': 0},\n",
       " 522: {'fold_num': 522,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.96499238e-05, -6.79310820e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -4.97321838e-05]]),\n",
       "  'predictive_score': 0.49585449449787694,\n",
       "  'predicted_label': 0},\n",
       " 523: {'fold_num': 523,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[3.59001795e-05, 3.01313004e-06, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.84253810e-05]]),\n",
       "  'predictive_score': 0.3926737176007689,\n",
       "  'predicted_label': 0},\n",
       " 524: {'fold_num': 524,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.72059632e-05, -7.61092450e-06,  1.08287255e-05, ...,\n",
       "           2.33386847e-05,  0.00000000e+00, -1.84757031e-05]]),\n",
       "  'predictive_score': 0.901260551948052,\n",
       "  'predicted_label': 1},\n",
       " 525: {'fold_num': 525,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.78878605e-04, -4.15472336e-05,  2.99819699e-05, ...,\n",
       "           1.18009106e-04,  0.00000000e+00, -6.21974584e-05]]),\n",
       "  'predictive_score': 0.13281844424065786,\n",
       "  'predicted_label': 0},\n",
       " 526: {'fold_num': 526,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-5.43498920e-04,  6.79675670e-06, -1.18971998e-05, ...,\n",
       "          -6.46451381e-05,  0.00000000e+00,  9.06405905e-05]]),\n",
       "  'predictive_score': 0.5813130786482179,\n",
       "  'predicted_label': 1},\n",
       " 527: {'fold_num': 527,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.20565733e-05,  5.55079615e-05, -3.04439741e-05, ...,\n",
       "          -6.46451381e-05,  0.00000000e+00, -1.48857037e-05]]),\n",
       "  'predictive_score': 0.8638038587229763,\n",
       "  'predicted_label': 1},\n",
       " 528: {'fold_num': 528,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.55289874e-05,  3.59168988e-06,  2.39432317e-05, ...,\n",
       "           5.60257863e-05,  0.00000000e+00,  1.24354597e-04]]),\n",
       "  'predictive_score': 0.5896564044615513,\n",
       "  'predicted_label': 1},\n",
       " 529: {'fold_num': 529,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.83162618e-04,  6.84979044e-06,  1.26928784e-06, ...,\n",
       "           2.35525657e-05,  0.00000000e+00,  1.52848282e-05]]),\n",
       "  'predictive_score': 0.1950236041478301,\n",
       "  'predicted_label': 0},\n",
       " 530: {'fold_num': 530,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.67561192e-04, -9.94834452e-06, -3.91750758e-05, ...,\n",
       "           2.35525657e-05,  0.00000000e+00,  1.26019515e-05]]),\n",
       "  'predictive_score': 0.4789372395750104,\n",
       "  'predicted_label': 0},\n",
       " 531: {'fold_num': 531,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.26758438e-04, -4.65553951e-05, -3.31743762e-05, ...,\n",
       "           2.35525657e-05,  0.00000000e+00, -2.36810940e-04]]),\n",
       "  'predictive_score': 0.2331066014271695,\n",
       "  'predicted_label': 0},\n",
       " 532: {'fold_num': 532,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.82126155e-04, -5.14275613e-05, -3.91750758e-05, ...,\n",
       "           1.57721144e-05,  0.00000000e+00, -2.81641346e-04]]),\n",
       "  'predictive_score': 0.2887281383010283,\n",
       "  'predicted_label': 0},\n",
       " 533: {'fold_num': 533,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.65249279e-04,  6.12073388e-05, -6.43761404e-06, ...,\n",
       "           1.52716531e-05, -1.06815437e-04, -6.10486163e-05]]),\n",
       "  'predictive_score': 0.6411009158325336,\n",
       "  'predicted_label': 1},\n",
       " 534: {'fold_num': 534,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.10456540e-05, -2.76660259e-05, -1.98386856e-05, ...,\n",
       "          -2.04122236e-05,  0.00000000e+00,  3.15726601e-05]]),\n",
       "  'predictive_score': 0.29032079764490765,\n",
       "  'predicted_label': 0},\n",
       " 535: {'fold_num': 535,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.55798040e-04, -5.46380055e-05,  1.67549778e-05, ...,\n",
       "           6.88600229e-04, -2.20321323e-04,  4.67761951e-04]]),\n",
       "  'predictive_score': 0.5963513188093296,\n",
       "  'predicted_label': 1},\n",
       " 536: {'fold_num': 536,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.86172782e-05,  1.77745040e-05,  1.98472994e-05, ...,\n",
       "           0.00000000e+00, -2.99731293e-05,  2.15091886e-05]]),\n",
       "  'predictive_score': 0.686608791234565,\n",
       "  'predicted_label': 1},\n",
       " 537: {'fold_num': 537,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.86904699e-05, -6.45710930e-05,  1.07374398e-05, ...,\n",
       "           0.00000000e+00, -1.25772632e-05,  2.11719893e-04]]),\n",
       "  'predictive_score': 0.6419323902361824,\n",
       "  'predicted_label': 1},\n",
       " 538: {'fold_num': 538,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.84945812e-05, -2.15580451e-06, -1.19293608e-06, ...,\n",
       "          -2.66443438e-05, -7.64059638e-06, -3.06319348e-05]]),\n",
       "  'predictive_score': 0.832757665945166,\n",
       "  'predicted_label': 1},\n",
       " 539: {'fold_num': 539,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.46382310e-05,  9.17887597e-05,  1.67460629e-05, ...,\n",
       "          -1.56766058e-05, -1.08341229e-05,  2.89820199e-05]]),\n",
       "  'predictive_score': 0.658277024446142,\n",
       "  'predicted_label': 1},\n",
       " 540: {'fold_num': 540,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.23623250e-05,  9.95485102e-06,  3.67859180e-05, ...,\n",
       "          -1.34612815e-05, -1.08341229e-05, -1.31579033e-04]]),\n",
       "  'predictive_score': 0.7689753649128651,\n",
       "  'predicted_label': 1},\n",
       " 541: {'fold_num': 541,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.82488351e-05, -5.61140707e-06,  1.16923731e-05, ...,\n",
       "           5.35836235e-04,  0.00000000e+00,  1.90293348e-05]]),\n",
       "  'predictive_score': 0.9260194805194802,\n",
       "  'predicted_label': 1},\n",
       " 542: {'fold_num': 542,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.40783452e-04,  9.69172164e-06,  0.00000000e+00, ...,\n",
       "          -6.53490458e-05,  0.00000000e+00,  9.16925001e-05]]),\n",
       "  'predictive_score': 0.8019831305390513,\n",
       "  'predicted_label': 1},\n",
       " 543: {'fold_num': 543,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.28917255e-06,  6.65989856e-06,  0.00000000e+00, ...,\n",
       "          -2.69427222e-05,  4.37338749e-06,  4.34109900e-05]]),\n",
       "  'predictive_score': 0.6721063483085544,\n",
       "  'predicted_label': 1},\n",
       " 544: {'fold_num': 544,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.47278848e-06, -9.96135751e-06,  0.00000000e+00, ...,\n",
       "          -1.33405902e-04,  1.20165052e-04, -8.80812758e-06]]),\n",
       "  'predictive_score': 0.43344041315152,\n",
       "  'predicted_label': 0},\n",
       " 545: {'fold_num': 545,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.54674801e-05, -5.58219360e-05,  0.00000000e+00, ...,\n",
       "           6.58166460e-05, -3.43148882e-05,  4.34530395e-06]]),\n",
       "  'predictive_score': 0.30506749232020136,\n",
       "  'predicted_label': 0},\n",
       " 546: {'fold_num': 546,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.89864646e-05, -5.57270202e-06,  0.00000000e+00, ...,\n",
       "          -1.25393063e-05,  0.00000000e+00,  1.88319677e-05]]),\n",
       "  'predictive_score': 0.6849715854106335,\n",
       "  'predicted_label': 1},\n",
       " 547: {'fold_num': 547,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.98742943e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.38355959e-06,  3.73055978e-05]]),\n",
       "  'predictive_score': 0.6783536240805979,\n",
       "  'predicted_label': 1},\n",
       " 548: {'fold_num': 548,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.05955962e-05,  1.00647565e-05,  0.00000000e+00, ...,\n",
       "          -3.24553708e-05,  5.41388801e-05,  1.88319677e-05]]),\n",
       "  'predictive_score': 0.7600472787016906,\n",
       "  'predicted_label': 1},\n",
       " 549: {'fold_num': 549,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.93180645e-05, -9.69496133e-06,  0.00000000e+00, ...,\n",
       "           1.36716700e-05,  1.08067979e-05,  2.47514968e-05]]),\n",
       "  'predictive_score': 0.4819139110158846,\n",
       "  'predicted_label': 0},\n",
       " 550: {'fold_num': 550,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-7.68201563e-05,  9.16387183e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.08067979e-05,  8.80569486e-06]]),\n",
       "  'predictive_score': 0.7372996970349912,\n",
       "  'predicted_label': 1},\n",
       " 551: {'fold_num': 551,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[2.79324619e-05, 3.41748149e-06, 0.00000000e+00, ...,\n",
       "          2.29431254e-05, 1.08067979e-05, 4.03683901e-05]]),\n",
       "  'predictive_score': 0.4963623210509823,\n",
       "  'predicted_label': 0},\n",
       " 552: {'fold_num': 552,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.76666633e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -6.33026047e-05, -2.05692476e-05,  8.26089602e-05]]),\n",
       "  'predictive_score': 0.283450840825841,\n",
       "  'predicted_label': 0},\n",
       " 553: {'fold_num': 553,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 7.50218365e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -6.38509706e-05,  1.08067979e-05,  1.75254879e-05]]),\n",
       "  'predictive_score': 0.18999551592198646,\n",
       "  'predicted_label': 0},\n",
       " 554: {'fold_num': 554,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.12081854e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.25368772e-05, -3.00995666e-04, -1.56700377e-04]]),\n",
       "  'predictive_score': 0.6972973137973139,\n",
       "  'predicted_label': 1},\n",
       " 555: {'fold_num': 555,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           4.35653804e-05, -1.93979453e-04,  1.48496217e-05]]),\n",
       "  'predictive_score': 0.8296668980529275,\n",
       "  'predicted_label': 1},\n",
       " 556: {'fold_num': 556,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  8.47795179e-06,  0.00000000e+00, ...,\n",
       "          -1.56983756e-05,  0.00000000e+00, -1.54192975e-05]]),\n",
       "  'predictive_score': 0.32662323207837923,\n",
       "  'predicted_label': 0},\n",
       " 557: {'fold_num': 557,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 6.29134367e-06, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.40376417e-05]]),\n",
       "  'predictive_score': 0.5336745954209189,\n",
       "  'predicted_label': 1},\n",
       " 558: {'fold_num': 558,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.30647811e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.04504705e-05]]),\n",
       "  'predictive_score': 0.1393754144032782,\n",
       "  'predicted_label': 0},\n",
       " 559: {'fold_num': 559,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.12266943e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.13653618e-05, -3.80531972e-05]]),\n",
       "  'predictive_score': 0.4647484659303543,\n",
       "  'predicted_label': 0},\n",
       " 560: {'fold_num': 560,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.37221977e-06,  1.37883652e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.47910005e-05, -3.82818064e-05]]),\n",
       "  'predictive_score': 0.4448963406584891,\n",
       "  'predicted_label': 0},\n",
       " 561: {'fold_num': 561,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.77271187e-05,  4.17423338e-04,  0.00000000e+00, ...,\n",
       "          -1.52563059e-06, -4.96403613e-06,  7.99129647e-05]]),\n",
       "  'predictive_score': 0.6560088904688364,\n",
       "  'predicted_label': 1},\n",
       " 562: {'fold_num': 562,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.62851162e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           1.66684589e-05,  0.00000000e+00,  7.65472907e-05]]),\n",
       "  'predictive_score': 0.7853065921007097,\n",
       "  'predicted_label': 1},\n",
       " 563: {'fold_num': 563,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.97555231e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -3.91819508e-06,  0.00000000e+00, -3.21181280e-06]]),\n",
       "  'predictive_score': 0.8388067322254629,\n",
       "  'predicted_label': 1},\n",
       " 564: {'fold_num': 564,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.26997907e-05,  7.54053566e-05,  0.00000000e+00, ...,\n",
       "          -1.81556843e-06,  0.00000000e+00, -5.99809192e-05]]),\n",
       "  'predictive_score': 0.8076105334723753,\n",
       "  'predicted_label': 1},\n",
       " 565: {'fold_num': 565,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[5.92278527e-06, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.25338491e-05, 0.00000000e+00, 9.40895666e-05]]),\n",
       "  'predictive_score': 0.8922532013050589,\n",
       "  'predicted_label': 1},\n",
       " 566: {'fold_num': 566,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.79810162e-05, -1.60752681e-05,  0.00000000e+00, ...,\n",
       "           8.13669650e-06,  0.00000000e+00, -3.05029113e-05]]),\n",
       "  'predictive_score': 0.7070217078093977,\n",
       "  'predicted_label': 1},\n",
       " 567: {'fold_num': 567,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.13072852e-04,  9.35646415e-07,  0.00000000e+00, ...,\n",
       "          -1.48544524e-06,  5.32491508e-05,  2.12580420e-04]]),\n",
       "  'predictive_score': 0.5108093679196619,\n",
       "  'predicted_label': 1},\n",
       " 568: {'fold_num': 568,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.09809768e-05,  2.48894577e-05,  0.00000000e+00, ...,\n",
       "           9.66232710e-06,  8.44679516e-06, -3.05029113e-05]]),\n",
       "  'predictive_score': 0.8205311959282546,\n",
       "  'predicted_label': 1},\n",
       " 569: {'fold_num': 569,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.88584689e-06, -1.82604937e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -2.89795753e-05]]),\n",
       "  'predictive_score': 0.2248286921411922,\n",
       "  'predicted_label': 0},\n",
       " 570: {'fold_num': 570,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.45204249e-06, -9.34904259e-07,  0.00000000e+00, ...,\n",
       "           1.87444831e-06,  0.00000000e+00,  3.79092903e-05]]),\n",
       "  'predictive_score': 0.3785287802367911,\n",
       "  'predicted_label': 0},\n",
       " 571: {'fold_num': 571,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.53608708e-05,  4.81874293e-06,  0.00000000e+00, ...,\n",
       "           9.33243179e-05,  0.00000000e+00,  1.89414054e-04]]),\n",
       "  'predictive_score': 0.5561034965851143,\n",
       "  'predicted_label': 1},\n",
       " 572: {'fold_num': 572,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 2.46438238e-05, 0.00000000e+00, ...,\n",
       "          2.02810613e-05, 0.00000000e+00, 1.49324766e-05]]),\n",
       "  'predictive_score': 0.5383537251147547,\n",
       "  'predicted_label': 1},\n",
       " 573: {'fold_num': 573,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.84748564e-05,  1.82692833e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.21746955e-05]]),\n",
       "  'predictive_score': 0.5514571160049102,\n",
       "  'predicted_label': 1},\n",
       " 574: {'fold_num': 574,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.61987190e-05, -7.26409877e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  9.01444087e-05]]),\n",
       "  'predictive_score': 0.6675266806421992,\n",
       "  'predicted_label': 1},\n",
       " 575: {'fold_num': 575,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.06258558e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  6.06095594e-05]]),\n",
       "  'predictive_score': 0.7183294213955979,\n",
       "  'predicted_label': 1},\n",
       " 576: {'fold_num': 576,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-5.34533328e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  9.95210748e-05]]),\n",
       "  'predictive_score': 0.8460029970029973,\n",
       "  'predicted_label': 1},\n",
       " 577: {'fold_num': 577,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[5.11395277e-06, 0.00000000e+00, 3.96502512e-06, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.96178763e-05]]),\n",
       "  'predictive_score': 0.859558060833216,\n",
       "  'predicted_label': 1},\n",
       " 578: {'fold_num': 578,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-7.17726191e-06,  0.00000000e+00,  2.90886900e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.88950695e-04]]),\n",
       "  'predictive_score': 0.41689234172690026,\n",
       "  'predicted_label': 0},\n",
       " 579: {'fold_num': 579,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.27056813e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  9.49374756e-05, -3.06443128e-05]]),\n",
       "  'predictive_score': 0.6353822003160235,\n",
       "  'predicted_label': 1},\n",
       " 580: {'fold_num': 580,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.68473298e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.61606980e-05,  1.45518846e-04]]),\n",
       "  'predictive_score': 0.46639474466022457,\n",
       "  'predicted_label': 0},\n",
       " 581: {'fold_num': 581,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.29778292e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.02486866e-05]]),\n",
       "  'predictive_score': 0.7546094110138228,\n",
       "  'predicted_label': 1},\n",
       " 582: {'fold_num': 582,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.30934396e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  3.24515256e-04]]),\n",
       "  'predictive_score': 0.28365026640026636,\n",
       "  'predicted_label': 0},\n",
       " 583: {'fold_num': 583,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.51451543e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.69507174e-04]]),\n",
       "  'predictive_score': 0.5139271163133392,\n",
       "  'predicted_label': 1},\n",
       " 584: {'fold_num': 584,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.92123653e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           4.02793162e-06,  0.00000000e+00,  1.36593918e-04]]),\n",
       "  'predictive_score': 0.22039750183596932,\n",
       "  'predicted_label': 0},\n",
       " 585: {'fold_num': 585,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.36245815e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -4.12781287e-06,  0.00000000e+00, -1.54120361e-04]]),\n",
       "  'predictive_score': 0.5493454600954601,\n",
       "  'predicted_label': 1},\n",
       " 586: {'fold_num': 586,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.98797466e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.41129311e-05, -5.99379823e-07]]),\n",
       "  'predictive_score': 0.9442498090145149,\n",
       "  'predicted_label': 1},\n",
       " 587: {'fold_num': 587,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.71412230e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.23944973e-04, -2.40370622e-04]]),\n",
       "  'predictive_score': 0.31493446545284787,\n",
       "  'predicted_label': 0},\n",
       " 588: {'fold_num': 588,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.88944258e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  9.57312352e-06, -1.06233021e-05]]),\n",
       "  'predictive_score': 0.8871349830724831,\n",
       "  'predicted_label': 1},\n",
       " 589: {'fold_num': 589,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.86778317e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.12721518e-05, 1.55670023e-04]]),\n",
       "  'predictive_score': 0.7465326909932176,\n",
       "  'predicted_label': 1},\n",
       " 590: {'fold_num': 590,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.08423051e-05,  0.00000000e+00, -6.47861676e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  7.03833889e-04]]),\n",
       "  'predictive_score': 0.28855338222578936,\n",
       "  'predicted_label': 0},\n",
       " 591: {'fold_num': 591,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.45158507e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  4.47046334e-04]]),\n",
       "  'predictive_score': 0.3531606358972088,\n",
       "  'predicted_label': 0},\n",
       " 592: {'fold_num': 592,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.82438694e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.51751133e-05, -6.85827362e-05]]),\n",
       "  'predictive_score': 0.629960521311334,\n",
       "  'predicted_label': 1},\n",
       " 593: {'fold_num': 593,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.00978474e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -3.12418377e-05,  6.99855478e-05]]),\n",
       "  'predictive_score': 0.3880678329023916,\n",
       "  'predicted_label': 0},\n",
       " 594: {'fold_num': 594,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.57772348e-05,  6.73605844e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -9.78472825e-05]]),\n",
       "  'predictive_score': 0.3546893470951133,\n",
       "  'predicted_label': 0},\n",
       " 595: {'fold_num': 595,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 8.55576860e-05, -1.70768561e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -6.50558430e-05, -9.78472825e-05]]),\n",
       "  'predictive_score': 0.3735176722787017,\n",
       "  'predicted_label': 0},\n",
       " 596: {'fold_num': 596,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.64621793e-05,  9.88424266e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.15165112e-04]]),\n",
       "  'predictive_score': 0.9704296218487396,\n",
       "  'predicted_label': 1},\n",
       " 597: {'fold_num': 597,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.89766714e-05, -1.38970734e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  7.23847591e-04]]),\n",
       "  'predictive_score': 0.49282205754341973,\n",
       "  'predicted_label': 0},\n",
       " 598: {'fold_num': 598,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.45012138e-05,  2.31653201e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -5.76055830e-05]]),\n",
       "  'predictive_score': 0.8882705488955489,\n",
       "  'predicted_label': 1},\n",
       " 599: {'fold_num': 599,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.23165845e-05,  1.68656308e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  2.18209993e-04]]),\n",
       "  'predictive_score': 0.5712727229770574,\n",
       "  'predicted_label': 1},\n",
       " 600: {'fold_num': 600,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.29396583e-04,  5.76527592e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.37624334e-04]]),\n",
       "  'predictive_score': 0.723740828367427,\n",
       "  'predicted_label': 1},\n",
       " 601: {'fold_num': 601,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.53070949e-05,  1.13203342e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.51073291e-04, -9.50621318e-06]]),\n",
       "  'predictive_score': 0.8531813394938395,\n",
       "  'predicted_label': 1},\n",
       " 602: {'fold_num': 602,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.14513934e-04,  7.42535558e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.43351715e-05, -6.74872623e-05]]),\n",
       "  'predictive_score': 0.6574364414180589,\n",
       "  'predicted_label': 1},\n",
       " 603: {'fold_num': 603,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.99928119e-05,  7.22479747e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  5.06683004e-05, -3.77195793e-05]]),\n",
       "  'predictive_score': 0.8551452260974322,\n",
       "  'predicted_label': 1},\n",
       " 604: {'fold_num': 604,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.02876441e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -8.26366354e-06,  0.00000000e+00, -1.20012895e-04]]),\n",
       "  'predictive_score': 0.22270045436589558,\n",
       "  'predicted_label': 0},\n",
       " 605: {'fold_num': 605,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.72703409e-06,  2.83470856e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.46073460e-05, -6.35048336e-05]]),\n",
       "  'predictive_score': 0.7139778762903766,\n",
       "  'predicted_label': 1},\n",
       " 606: {'fold_num': 606,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.92259252e-05,  3.81295260e-04, -1.49672632e-05, ...,\n",
       "           0.00000000e+00,  7.34184268e-06, -6.84226293e-05]]),\n",
       "  'predictive_score': 0.717481378635984,\n",
       "  'predicted_label': 1},\n",
       " 607: {'fold_num': 607,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.21085051e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -8.53269258e-05,  1.25463535e-04]]),\n",
       "  'predictive_score': 0.3494309953462431,\n",
       "  'predicted_label': 0},\n",
       " 608: {'fold_num': 608,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.40108948e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.39256477e-05,  4.30140678e-05]]),\n",
       "  'predictive_score': 0.3966071093938743,\n",
       "  'predicted_label': 0},\n",
       " 609: {'fold_num': 609,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.33851772e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           4.11183776e-06,  2.21703741e-03, -2.32667534e-04]]),\n",
       "  'predictive_score': 0.2757952095204418,\n",
       "  'predicted_label': 0},\n",
       " 610: {'fold_num': 610,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.78132790e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.83215732e-04, 2.31244559e-06]]),\n",
       "  'predictive_score': 0.8738200231141411,\n",
       "  'predicted_label': 1},\n",
       " 611: {'fold_num': 611,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.86991794e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.64141584e-05, -6.44889680e-05]]),\n",
       "  'predictive_score': 0.26346622209489845,\n",
       "  'predicted_label': 0},\n",
       " 612: {'fold_num': 612,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.71753043e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.52288406e-06, 3.32220040e-05]]),\n",
       "  'predictive_score': 0.5202242634816165,\n",
       "  'predicted_label': 1},\n",
       " 613: {'fold_num': 613,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.87027691e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  6.04995677e-05, -1.01381879e-04]]),\n",
       "  'predictive_score': 0.6610837195784951,\n",
       "  'predicted_label': 1},\n",
       " 614: {'fold_num': 614,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.95892129e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.71618664e-05, -2.18204717e-05]]),\n",
       "  'predictive_score': 0.6738708252531782,\n",
       "  'predicted_label': 1},\n",
       " 615: {'fold_num': 615,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.32120960e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.69936686e-06, -2.01726670e-05]]),\n",
       "  'predictive_score': 0.5234741888228732,\n",
       "  'predicted_label': 1},\n",
       " 616: {'fold_num': 616,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.62614938e-06, -1.59013295e-05]]),\n",
       "  'predictive_score': 0.5562216207854752,\n",
       "  'predicted_label': 1},\n",
       " 617: {'fold_num': 617,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.30114937e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  5.58520964e-04, -5.15518486e-05]]),\n",
       "  'predictive_score': 0.8825321737086442,\n",
       "  'predicted_label': 1},\n",
       " 618: {'fold_num': 618,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.01520467e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  8.73557644e-06,  1.01540017e-04]]),\n",
       "  'predictive_score': 0.1537873870238809,\n",
       "  'predicted_label': 0},\n",
       " 619: {'fold_num': 619,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.55856117e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.29639370e-05, -7.51827577e-06, -3.29733420e-05]]),\n",
       "  'predictive_score': 0.6822143100062991,\n",
       "  'predicted_label': 1},\n",
       " 620: {'fold_num': 620,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.78502046e-06,  1.16652637e-04,  0.00000000e+00, ...,\n",
       "           1.57102805e-05,  4.66302796e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3173871399068767,\n",
       "  'predicted_label': 0},\n",
       " 621: {'fold_num': 621,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.33156279e-06, -2.11091644e-04,  1.40174079e-06, ...,\n",
       "           1.54013676e-05,  3.28974846e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3128345612720613,\n",
       "  'predicted_label': 0},\n",
       " 622: {'fold_num': 622,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.76838027e-05,  0.00000000e+00, -3.06962935e-06, ...,\n",
       "          -1.29879717e-05,  5.19162071e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6557971099033405,\n",
       "  'predicted_label': 1},\n",
       " 623: {'fold_num': 623,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.06016900e-06,  0.00000000e+00,  7.90145605e-06, ...,\n",
       "          -2.49889573e-04,  1.82924348e-05,  7.28586405e-06]]),\n",
       "  'predictive_score': 0.5443545176228999,\n",
       "  'predicted_label': 1},\n",
       " 624: {'fold_num': 624,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.53650199e-06,  0.00000000e+00,  4.95266364e-06, ...,\n",
       "           1.05626914e-05, -4.22837010e-05, -1.57145473e-05]]),\n",
       "  'predictive_score': 0.457529776595953,\n",
       "  'predicted_label': 0},\n",
       " 625: {'fold_num': 625,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.83401322e-05,  0.00000000e+00,  9.97166588e-07, ...,\n",
       "           5.13513881e-06,  7.28219295e-05, -4.35498437e-06]]),\n",
       "  'predictive_score': 0.2699328235404088,\n",
       "  'predicted_label': 0},\n",
       " 626: {'fold_num': 626,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.92822097e-04,  0.00000000e+00, -2.06713998e-06, ...,\n",
       "          -7.54043523e-06, -3.40159118e-05,  1.23688518e-05]]),\n",
       "  'predictive_score': 0.8960134865134864,\n",
       "  'predicted_label': 1},\n",
       " 627: {'fold_num': 627,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.97370245e-06,  0.00000000e+00,  2.86302885e-06, ...,\n",
       "           1.21509956e-05, -1.48110374e-05,  4.10911617e-06]]),\n",
       "  'predictive_score': 0.35680343961593947,\n",
       "  'predicted_label': 0},\n",
       " 628: {'fold_num': 628,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.89012609e-06,  0.00000000e+00,  1.40174079e-06, ...,\n",
       "           4.67078063e-06,  4.62810027e-05,  5.96691077e-06]]),\n",
       "  'predictive_score': 0.3529150379848908,\n",
       "  'predicted_label': 0},\n",
       " 629: {'fold_num': 629,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.32890058e-05,  0.00000000e+00,  9.97166588e-07, ...,\n",
       "           1.21509956e-05,  7.27552525e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.11343295021971489,\n",
       "  'predicted_label': 0},\n",
       " 630: {'fold_num': 630,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.49915397e-05,  2.33857259e-05,  9.97166588e-07, ...,\n",
       "           3.38490079e-05, -2.95855718e-05, -7.04732382e-05]]),\n",
       "  'predictive_score': 0.4410066787787376,\n",
       "  'predicted_label': 0},\n",
       " 631: {'fold_num': 631,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.60091006e-05,  0.00000000e+00, -9.97166588e-07, ...,\n",
       "          -6.62716699e-06,  1.46271716e-04, -4.48351985e-06]]),\n",
       "  'predictive_score': 0.6301124524984819,\n",
       "  'predicted_label': 1},\n",
       " 632: {'fold_num': 632,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.45024319e-06,  0.00000000e+00,  9.97166588e-07, ...,\n",
       "           0.00000000e+00, -2.95855718e-05, -4.88201790e-06]]),\n",
       "  'predictive_score': 0.23501353507603515,\n",
       "  'predicted_label': 0},\n",
       " 633: {'fold_num': 633,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.01041901e-05,  0.00000000e+00,  6.03081301e-06, ...,\n",
       "           0.00000000e+00,  1.44905347e-06, -1.91837583e-05]]),\n",
       "  'predictive_score': 0.7313183083900963,\n",
       "  'predicted_label': 1},\n",
       " 634: {'fold_num': 634,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.90080262e-05, -6.14172897e-05,  3.48435574e-06, ...,\n",
       "           0.00000000e+00,  4.11612866e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1074089639935228,\n",
       "  'predicted_label': 0},\n",
       " 635: {'fold_num': 635,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.73339721e-05,  0.00000000e+00,  8.03128604e-06, ...,\n",
       "           0.00000000e+00,  2.80645191e-05, -2.47170939e-05]]),\n",
       "  'predictive_score': 0.5166441238500064,\n",
       "  'predicted_label': 1},\n",
       " 636: {'fold_num': 636,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.32547514e-05,  0.00000000e+00,  1.40174079e-06, ...,\n",
       "           0.00000000e+00, -1.61434090e-05,  7.47104256e-06]]),\n",
       "  'predictive_score': 0.3794789067142006,\n",
       "  'predicted_label': 0},\n",
       " 637: {'fold_num': 637,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 8.38314895e-07,  0.00000000e+00,  9.97166588e-07, ...,\n",
       "           0.00000000e+00, -2.03028171e-05, -9.44165048e-05]]),\n",
       "  'predictive_score': 0.30573138013946843,\n",
       "  'predicted_label': 0},\n",
       " 638: {'fold_num': 638,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 6.36981024e-05, 3.88952199e-06, ...,\n",
       "          0.00000000e+00, 2.03028171e-05, 1.16316200e-04]]),\n",
       "  'predictive_score': 0.572255890566262,\n",
       "  'predicted_label': 1},\n",
       " 639: {'fold_num': 639,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -3.11985242e-05,  9.97166588e-07, ...,\n",
       "           0.00000000e+00, -8.64600707e-06,  2.75281673e-05]]),\n",
       "  'predictive_score': 0.4100252302522037,\n",
       "  'predicted_label': 0},\n",
       " 640: {'fold_num': 640,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -3.32380438e-05, -1.63209022e-04, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.90045020e-05]]),\n",
       "  'predictive_score': 0.3615906936201055,\n",
       "  'predicted_label': 0},\n",
       " 641: {'fold_num': 641,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.22948241e-05, -7.08284726e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -3.53791305e-05]]),\n",
       "  'predictive_score': 0.8610039432789433,\n",
       "  'predicted_label': 1},\n",
       " 642: {'fold_num': 642,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.06121335e-05, -1.21315759e-04, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -3.88100813e-06]]),\n",
       "  'predictive_score': 0.19418062271835493,\n",
       "  'predicted_label': 0},\n",
       " 643: {'fold_num': 643,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -3.92667951e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -3.05566179e-05]]),\n",
       "  'predictive_score': 0.7482785321403742,\n",
       "  'predicted_label': 1},\n",
       " 644: {'fold_num': 644,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.06102244e-05,  5.05799597e-05, ...,\n",
       "           0.00000000e+00,  6.23881348e-05, -1.44990620e-04]]),\n",
       "  'predictive_score': 0.06109125837930186,\n",
       "  'predicted_label': 0},\n",
       " 645: {'fold_num': 645,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -6.15631516e-05,  6.51495492e-05, ...,\n",
       "           0.00000000e+00,  1.66649296e-05, -2.17182481e-04]]),\n",
       "  'predictive_score': 0.3304409430438843,\n",
       "  'predicted_label': 0},\n",
       " 646: {'fold_num': 646,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.94668790e-06, -6.15631516e-05, -1.55934367e-04, ...,\n",
       "           0.00000000e+00, -4.78750315e-05, -2.96083996e-05]]),\n",
       "  'predictive_score': 0.09467520428917486,\n",
       "  'predicted_label': 0},\n",
       " 647: {'fold_num': 647,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.91415102e-06,  0.00000000e+00,  2.47397460e-05, ...,\n",
       "           0.00000000e+00, -5.15265882e-05, -7.92849527e-05]]),\n",
       "  'predictive_score': 0.5430742531677126,\n",
       "  'predicted_label': 1},\n",
       " 648: {'fold_num': 648,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.84947546e-05,  0.00000000e+00, -2.27442138e-05, ...,\n",
       "           0.00000000e+00,  2.35051930e-05,  6.39535399e-05]]),\n",
       "  'predictive_score': 0.2375548969004852,\n",
       "  'predicted_label': 0},\n",
       " 649: {'fold_num': 649,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.91560107e-06,  1.67979299e-05, -4.57694106e-05, ...,\n",
       "           0.00000000e+00,  1.32115398e-04,  1.27840588e-04]]),\n",
       "  'predictive_score': 0.6706687969967767,\n",
       "  'predicted_label': 1},\n",
       " 650: {'fold_num': 650,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.16834269e-06,  3.69168074e-05, -9.58181388e-05, ...,\n",
       "           0.00000000e+00, -1.19186662e-05,  1.00179875e-05]]),\n",
       "  'predictive_score': 0.2049065034337867,\n",
       "  'predicted_label': 0},\n",
       " 651: {'fold_num': 651,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.18736912e-04,  0.00000000e+00,  6.77418572e-05, ...,\n",
       "           0.00000000e+00, -1.63211853e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.15519648529575,\n",
       "  'predicted_label': 0},\n",
       " 652: {'fold_num': 652,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 1.25222693e-05, 2.43560959e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6722895609464495,\n",
       "  'predicted_label': 1},\n",
       " 653: {'fold_num': 653,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 1.67979299e-05, 3.39079526e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.882484677001705,\n",
       "  'predicted_label': 1},\n",
       " 654: {'fold_num': 654,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  6.13668255e-05, -6.92210727e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6485971842484999,\n",
       "  'predicted_label': 1},\n",
       " 655: {'fold_num': 655,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.68306789e-05, -2.94322618e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6410509242864119,\n",
       "  'predicted_label': 1},\n",
       " 656: {'fold_num': 656,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -2.00324543e-04, -3.12857439e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4328943765857465,\n",
       "  'predicted_label': 0},\n",
       " 657: {'fold_num': 657,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 1.23367573e-05, 3.14890293e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8491981925238506,\n",
       "  'predicted_label': 1},\n",
       " 658: {'fold_num': 658,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 1.67267232e-05, 2.12554653e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6142932890982427,\n",
       "  'predicted_label': 1},\n",
       " 659: {'fold_num': 659,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.46529277e-04, -1.19790744e-05, -1.61139335e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3950755063864582,\n",
       "  'predicted_label': 0},\n",
       " 660: {'fold_num': 660,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.02749019e-04, ...,\n",
       "           0.00000000e+00,  2.75572264e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4251833105619868,\n",
       "  'predicted_label': 0},\n",
       " 661: {'fold_num': 661,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -3.84888873e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6551307234432232,\n",
       "  'predicted_label': 1},\n",
       " 662: {'fold_num': 662,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.03291372e-06, -2.93395902e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6936206802313614,\n",
       "  'predicted_label': 1},\n",
       " 663: {'fold_num': 663,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -6.66747352e-07, -4.25965974e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.759088359725668,\n",
       "  'predicted_label': 1},\n",
       " 664: {'fold_num': 664,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.0000000e+00,  1.6311987e-06, -2.2088056e-05, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]),\n",
       "  'predictive_score': 0.753332442067736,\n",
       "  'predicted_label': 1},\n",
       " 665: {'fold_num': 665,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  9.18911390e-06, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -6.48910478e-05]]),\n",
       "  'predictive_score': 0.32316403155238305,\n",
       "  'predicted_label': 0},\n",
       " 666: {'fold_num': 666,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -3.55098251e-06,  7.87928332e-06, ...,\n",
       "           0.00000000e+00, -2.08785720e-05,  3.53589705e-05]]),\n",
       "  'predictive_score': 0.4120460332151507,\n",
       "  'predicted_label': 0},\n",
       " 667: {'fold_num': 667,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.81925143e-06, -7.77779727e-06, ...,\n",
       "           0.00000000e+00, -4.61878129e-06, -3.72742196e-05]]),\n",
       "  'predictive_score': 0.5513903257690022,\n",
       "  'predicted_label': 1},\n",
       " 668: {'fold_num': 668,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 6.66510649e-04, -3.77860128e-06,  8.41301726e-06, ...,\n",
       "           1.27526403e-05, -4.66299193e-04, -1.10089825e-05]]),\n",
       "  'predictive_score': 0.243521588383237,\n",
       "  'predicted_label': 0},\n",
       " 669: {'fold_num': 669,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.01960298e-05,  3.55176290e-06, -5.85207754e-05, ...,\n",
       "          -8.00336102e-06, -1.45774090e-04,  1.42751240e-05]]),\n",
       "  'predictive_score': 0.8059261179137338,\n",
       "  'predicted_label': 1},\n",
       " 670: {'fold_num': 670,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.01960298e-05,  1.92731775e-06,  0.00000000e+00, ...,\n",
       "          -1.61118129e-05,  7.32162116e-05,  5.99226515e-05]]),\n",
       "  'predictive_score': 0.9177100052725053,\n",
       "  'predicted_label': 1},\n",
       " 671: {'fold_num': 671,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.08509256e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 8.07936395e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5261681076276664,\n",
       "  'predicted_label': 1},\n",
       " 672: {'fold_num': 672,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.21656893e-06,  0.00000000e+00, ...,\n",
       "          -2.14462537e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.569846716278218,\n",
       "  'predicted_label': 1},\n",
       " 673: {'fold_num': 673,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -3.16703317e-05,  0.00000000e+00, -6.67437787e-06]]),\n",
       "  'predictive_score': 0.8435375534553167,\n",
       "  'predicted_label': 1},\n",
       " 674: {'fold_num': 674,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.70632604e-05,  0.00000000e+00, -4.01447824e-05]]),\n",
       "  'predictive_score': 0.6943809662559662,\n",
       "  'predicted_label': 1},\n",
       " 675: {'fold_num': 675,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          5.20415923e-05, 0.00000000e+00, 1.89027293e-05]]),\n",
       "  'predictive_score': 0.22049210608363082,\n",
       "  'predicted_label': 0},\n",
       " 676: {'fold_num': 676,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -6.46025302e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7967601716094365,\n",
       "  'predicted_label': 1},\n",
       " 677: {'fold_num': 677,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.92372778e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.92837232e-05, -5.89765854e-06, -9.35849267e-06]]),\n",
       "  'predictive_score': 0.5729183962752074,\n",
       "  'predicted_label': 1},\n",
       " 678: {'fold_num': 678,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.01773723e-04,  0.00000000e+00,  2.87055594e-05, ...,\n",
       "          -1.41149223e-05,  1.87154362e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.641930740419711,\n",
       "  'predicted_label': 1},\n",
       " 679: {'fold_num': 679,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.38508234e-05,  0.00000000e+00, -2.33398183e-06, ...,\n",
       "          -1.14168308e-05,  9.86333129e-05, -4.11713107e-06]]),\n",
       "  'predictive_score': 0.9078577680489442,\n",
       "  'predicted_label': 1},\n",
       " 680: {'fold_num': 680,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.01646269e-04,  0.00000000e+00, -1.03152231e-05, ...,\n",
       "           8.00385487e-06, -5.96932996e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.26839050148338084,\n",
       "  'predicted_label': 0},\n",
       " 681: {'fold_num': 681,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.05028763e-04, ...,\n",
       "           3.10291340e-05,  1.90865026e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.38566146255705064,\n",
       "  'predicted_label': 0},\n",
       " 682: {'fold_num': 682,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.34271407e-05,  6.91269967e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7400499637101805,\n",
       "  'predicted_label': 1},\n",
       " 683: {'fold_num': 683,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -5.68686574e-06, ...,\n",
       "          -1.14820848e-05,  1.57382376e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8050606746194984,\n",
       "  'predicted_label': 1},\n",
       " 684: {'fold_num': 684,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  3.22153420e-05, ...,\n",
       "           4.73397227e-05, -2.05510173e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1931124712276029,\n",
       "  'predicted_label': 0},\n",
       " 685: {'fold_num': 685,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.60548337e-05, -9.39035685e-06, -3.74307185e-05, ...,\n",
       "          -2.77305735e-04,  3.40642455e-05,  3.32770796e-07]]),\n",
       "  'predictive_score': 0.5481712397080046,\n",
       "  'predicted_label': 1},\n",
       " 686: {'fold_num': 686,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.32613416e-05, -9.24718329e-07,  5.82178359e-06, ...,\n",
       "           2.11320589e-05,  7.17690063e-05,  3.00282488e-05]]),\n",
       "  'predictive_score': 0.33249660751615095,\n",
       "  'predicted_label': 0},\n",
       " 687: {'fold_num': 687,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.45957564e-05, -4.24991258e-06,  8.47165986e-06, ...,\n",
       "           7.42632084e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4717395080409785,\n",
       "  'predicted_label': 0},\n",
       " 688: {'fold_num': 688,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.68780711e-05, -4.24991258e-06,  8.47165986e-06, ...,\n",
       "           5.41508199e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.47948554223554224,\n",
       "  'predicted_label': 0},\n",
       " 689: {'fold_num': 689,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -9.39035685e-06, -1.49635081e-05, ...,\n",
       "          -3.89903514e-05,  9.23750258e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6568366766961969,\n",
       "  'predicted_label': 1},\n",
       " 690: {'fold_num': 690,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.15537741e-05, -1.07256748e-06, -5.71504328e-05, ...,\n",
       "          -7.06379890e-04,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3922577302298665,\n",
       "  'predicted_label': 0},\n",
       " 691: {'fold_num': 691,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.32613416e-05, -4.25805181e-06,  2.05242546e-05, ...,\n",
       "           1.25652112e-04,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4598741356682534,\n",
       "  'predicted_label': 0},\n",
       " 692: {'fold_num': 692,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.32613416e-05, -2.08877204e-06,  2.62174494e-05, ...,\n",
       "           0.00000000e+00, -1.72774082e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4636622178990599,\n",
       "  'predicted_label': 0},\n",
       " 693: {'fold_num': 693,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.28424075e-05,  5.70171071e-06,  8.87408232e-06, ...,\n",
       "           2.86657890e-05, -1.83159756e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3269579861572895,\n",
       "  'predicted_label': 0},\n",
       " 694: {'fold_num': 694,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.06703437e-04,  0.00000000e+00,  1.98569038e-05, ...,\n",
       "          -2.94215052e-05,  4.70421738e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5584036989412375,\n",
       "  'predicted_label': 1},\n",
       " 695: {'fold_num': 695,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.33095991e-05,  0.00000000e+00,  1.32373691e-06, ...,\n",
       "          -1.98276704e-05,  1.86510548e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7818722621332915,\n",
       "  'predicted_label': 1},\n",
       " 696: {'fold_num': 696,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.51977573e-05,  0.00000000e+00, -1.00184980e-07, ...,\n",
       "          -1.63114599e-05,  5.66603341e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6182797068127951,\n",
       "  'predicted_label': 1},\n",
       " 697: {'fold_num': 697,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.15094316e-04,  3.06436329e-05,  2.03417413e-06, ...,\n",
       "          -1.27403052e-05,  3.97329986e-04,  1.31477678e-05]]),\n",
       "  'predictive_score': 0.7941434524732159,\n",
       "  'predicted_label': 1},\n",
       " 698: {'fold_num': 698,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.31503809e-05,  0.00000000e+00, -5.81565167e-06, ...,\n",
       "           2.48645662e-05,  0.00000000e+00, -7.22261651e-06]]),\n",
       "  'predictive_score': 0.41202069604372227,\n",
       "  'predicted_label': 0},\n",
       " 699: {'fold_num': 699,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.08217810e-04,  0.00000000e+00, -2.03417413e-06, ...,\n",
       "           6.02218287e-05,  0.00000000e+00, -7.22261651e-06]]),\n",
       "  'predictive_score': 0.4289532774876445,\n",
       "  'predicted_label': 0},\n",
       " 700: {'fold_num': 700,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.38481442e-05,  4.91421465e-06,  3.79405676e-05, ...,\n",
       "          -2.06272751e-05,  9.89688834e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6556364090158208,\n",
       "  'predicted_label': 1},\n",
       " 701: {'fold_num': 701,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.29709872e-05,  1.63723747e-05,  9.76535007e-05, ...,\n",
       "          -1.70120039e-05, -1.60591386e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6372243601986247,\n",
       "  'predicted_label': 1},\n",
       " 702: {'fold_num': 702,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.90761289e-05, -2.49637280e-05, -4.45705253e-05, ...,\n",
       "           2.30885885e-05,  1.46644679e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.36526956918210796,\n",
       "  'predicted_label': 0},\n",
       " 703: {'fold_num': 703,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.10980001e-05,  1.25198577e-05,  2.03417413e-06, ...,\n",
       "          -1.09673959e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5533787066691479,\n",
       "  'predicted_label': 1},\n",
       " 704: {'fold_num': 704,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.51447843e-05,  4.71255971e-05, -7.94981538e-05, ...,\n",
       "           1.92696288e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4816588542176777,\n",
       "  'predicted_label': 0},\n",
       " 705: {'fold_num': 705,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.09036307e-05,  8.85230854e-06,  7.11779112e-06, ...,\n",
       "          -1.24830396e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7582282684635628,\n",
       "  'predicted_label': 1},\n",
       " 706: {'fold_num': 706,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.77994775e-06, -2.23692602e-05,  8.01056139e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.13235527e-05]]),\n",
       "  'predictive_score': 0.0845651839990075,\n",
       "  'predicted_label': 0},\n",
       " 707: {'fold_num': 707,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.46533114e-07,  2.34612886e-05,  1.66627800e-04, ...,\n",
       "          -1.29879760e-05,  0.00000000e+00,  3.42080602e-06]]),\n",
       "  'predictive_score': 0.815689197240668,\n",
       "  'predicted_label': 1},\n",
       " 708: {'fold_num': 708,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.10951468e-05, -1.80601549e-05,  9.15333475e-05, ...,\n",
       "           3.90424219e-06,  0.00000000e+00, -3.42080602e-06]]),\n",
       "  'predictive_score': 0.3669543839373561,\n",
       "  'predicted_label': 0},\n",
       " 709: {'fold_num': 709,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.04148069e-05, -1.73907325e-05,  2.25438069e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.12550698606948607,\n",
       "  'predicted_label': 0},\n",
       " 710: {'fold_num': 710,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.30000626e-05, 5.54147215e-05, 3.21362832e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.9363311965811963,\n",
       "  'predicted_label': 1},\n",
       " 711: {'fold_num': 711,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.68864983e-05, -1.81427999e-05,  1.75840227e-06, ...,\n",
       "           5.77540915e-06,  0.00000000e+00,  6.04853100e-06]]),\n",
       "  'predictive_score': 0.16001715071993708,\n",
       "  'predicted_label': 0},\n",
       " 712: {'fold_num': 712,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.90966303e-05,  3.16310992e-06, -1.57769652e-05, ...,\n",
       "           0.00000000e+00, -2.52366524e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7250144316467845,\n",
       "  'predicted_label': 1},\n",
       " 713: {'fold_num': 713,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[3.19868423e-05, 5.49892317e-05, 1.58640173e-05, ...,\n",
       "          0.00000000e+00, 3.57720591e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5114844787565377,\n",
       "  'predicted_label': 1},\n",
       " 714: {'fold_num': 714,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.85436266e-05,  1.84222212e-05, -1.29436505e-04, ...,\n",
       "           0.00000000e+00, -1.04327339e-03,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8391980700543007,\n",
       "  'predicted_label': 1},\n",
       " 715: {'fold_num': 715,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-8.60056981e-06,  8.24852652e-04,  1.40309117e-04, ...,\n",
       "           0.00000000e+00, -2.82312659e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.281081073746515,\n",
       "  'predicted_label': 0},\n",
       " 716: {'fold_num': 716,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.08700960e-05, -4.74187061e-05,  1.94130336e-05, ...,\n",
       "          -2.94317201e-05, -1.05932152e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4754965119795178,\n",
       "  'predicted_label': 0},\n",
       " 717: {'fold_num': 717,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.64409487e-05, -1.69286980e-05, -3.89042196e-04, ...,\n",
       "           0.00000000e+00, -7.03534223e-07,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.33409533154753746,\n",
       "  'predicted_label': 0},\n",
       " 718: {'fold_num': 718,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.28591750e-05, -2.69194076e-05,  2.01295642e-05, ...,\n",
       "           0.00000000e+00,  7.33482202e-05,  7.69739269e-06]]),\n",
       "  'predictive_score': 0.20189701760657644,\n",
       "  'predicted_label': 0},\n",
       " 719: {'fold_num': 719,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.30954479e-05,  6.86292308e-04, -3.23092707e-05, ...,\n",
       "           0.00000000e+00,  5.81263458e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.14810712024044068,\n",
       "  'predicted_label': 0},\n",
       " 720: {'fold_num': 720,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -4.92729891e-05,  2.01295642e-05, ...,\n",
       "           0.00000000e+00, -3.10472444e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4962396059392965,\n",
       "  'predicted_label': 0},\n",
       " 721: {'fold_num': 721,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.06361251e-05,  2.41992749e-04, -1.48443662e-05, ...,\n",
       "           0.00000000e+00, -4.69410391e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.19830449085228502,\n",
       "  'predicted_label': 0},\n",
       " 722: {'fold_num': 722,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.89144528e-05,  1.13802270e-04, -4.76215666e-05, ...,\n",
       "           0.00000000e+00,  3.16824416e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7694292859917858,\n",
       "  'predicted_label': 1},\n",
       " 723: {'fold_num': 723,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.06361251e-05,  1.22187555e-04, -1.60128220e-05, ...,\n",
       "           0.00000000e+00, -1.34640440e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.27517790257128494,\n",
       "  'predicted_label': 0},\n",
       " 724: {'fold_num': 724,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.54394977e-04,  9.54409013e-05, -4.63208538e-05, ...,\n",
       "           0.00000000e+00,  2.02127284e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8936791749916749,\n",
       "  'predicted_label': 1},\n",
       " 725: {'fold_num': 725,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  8.17013315e-05, -4.76749058e-05, ...,\n",
       "           0.00000000e+00,  5.37341963e-06, -1.68318936e-05]]),\n",
       "  'predictive_score': 0.5460308323212736,\n",
       "  'predicted_label': 1},\n",
       " 726: {'fold_num': 726,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.20208479e-04, -1.83414140e-05, ...,\n",
       "           9.49603358e-06,  8.70787737e-05,  3.68462623e-05]]),\n",
       "  'predictive_score': 0.3617445614026496,\n",
       "  'predicted_label': 0},\n",
       " 727: {'fold_num': 727,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  1.05432875e-04, -1.12505061e-04, ...,\n",
       "           0.00000000e+00,  1.77382328e-05,  5.64074095e-04]]),\n",
       "  'predictive_score': 0.7999085362736679,\n",
       "  'predicted_label': 1},\n",
       " 728: {'fold_num': 728,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  2.05264427e-04, -3.22335217e-05, ...,\n",
       "           0.00000000e+00,  1.09281199e-04,  6.79644687e-05]]),\n",
       "  'predictive_score': 0.20725185925185927,\n",
       "  'predicted_label': 0},\n",
       " 729: {'fold_num': 729,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  9.05382115e-05, -1.04866160e-04, ...,\n",
       "           0.00000000e+00,  5.85747423e-05, -9.50922481e-06]]),\n",
       "  'predictive_score': 0.8562587431488363,\n",
       "  'predicted_label': 1},\n",
       " 730: {'fold_num': 730,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.34546077e-05, -8.10907654e-05, -9.60369316e-06, ...,\n",
       "           0.00000000e+00, -1.25783266e-05,  1.96526394e-05]]),\n",
       "  'predictive_score': 0.443827885629163,\n",
       "  'predicted_label': 0},\n",
       " 731: {'fold_num': 731,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.17919180e-05,  7.22967927e-04, -1.60215371e-05, ...,\n",
       "          -1.04557588e-04, -2.06689509e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1384906204906205,\n",
       "  'predicted_label': 0},\n",
       " 732: {'fold_num': 732,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  6.77951406e-05, -4.72855978e-05, ...,\n",
       "           0.00000000e+00,  3.15653510e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6411901021235386,\n",
       "  'predicted_label': 1},\n",
       " 733: {'fold_num': 733,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.84460476e-05, -2.01295642e-05, ...,\n",
       "           0.00000000e+00,  2.02171520e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8109651358058869,\n",
       "  'predicted_label': 1},\n",
       " 734: {'fold_num': 734,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.87494359e-05, -1.03487509e-04, -3.48877372e-05, ...,\n",
       "           0.00000000e+00, -1.25899352e-05,  1.73471117e-04]]),\n",
       "  'predictive_score': 0.3378406466899115,\n",
       "  'predicted_label': 0},\n",
       " 735: {'fold_num': 735,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.18147710e-05, -7.37760085e-05,  1.60041306e-05, ...,\n",
       "           0.00000000e+00,  2.60875404e-05, -4.29630017e-05]]),\n",
       "  'predictive_score': 0.517472660380555,\n",
       "  'predicted_label': 1},\n",
       " 736: {'fold_num': 736,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.04812477e-05, -1.95361855e-05,  4.74315821e-05, ...,\n",
       "          -2.62248609e-04,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3187337444117631,\n",
       "  'predicted_label': 0},\n",
       " 737: {'fold_num': 737,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.        ,  0.        , -0.00010487, ...,  0.        ,\n",
       "           0.        ,  0.        ]]),\n",
       "  'predictive_score': 0.5187118964626706,\n",
       "  'predicted_label': 1},\n",
       " 738: {'fold_num': 738,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.18487353e-05,  0.00000000e+00,  4.88547143e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2008164711965022,\n",
       "  'predicted_label': 0},\n",
       " 739: {'fold_num': 739,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.04812477e-05,  0.00000000e+00, -7.81771882e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -5.64269895e-06]]),\n",
       "  'predictive_score': 0.5217065928567478,\n",
       "  'predicted_label': 1},\n",
       " 740: {'fold_num': 740,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.19003443e-05,  0.00000000e+00, -3.41974606e-04, ...,\n",
       "           1.76277068e-05, -5.41709867e-06, -5.64269895e-06]]),\n",
       "  'predictive_score': 0.6569798725741065,\n",
       "  'predicted_label': 1},\n",
       " 741: {'fold_num': 741,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.19845957e-05,  0.00000000e+00, -3.41974606e-04, ...,\n",
       "          -1.01821844e-05,  4.97445995e-05, -6.50324763e-06]]),\n",
       "  'predictive_score': 0.771656961094461,\n",
       "  'predicted_label': 1},\n",
       " 742: {'fold_num': 742,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.32767539e-05,  0.00000000e+00, -3.21405380e-05, ...,\n",
       "           2.58319782e-05, -4.29996572e-05,  2.56439682e-06]]),\n",
       "  'predictive_score': 0.3215922677683513,\n",
       "  'predicted_label': 0},\n",
       " 743: {'fold_num': 743,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.99772244e-05,  0.00000000e+00,  1.55029641e-05, ...,\n",
       "           5.69038521e-06,  2.41046602e-05,  1.90641155e-05]]),\n",
       "  'predictive_score': 0.5391347736156173,\n",
       "  'predicted_label': 1},\n",
       " 744: {'fold_num': 744,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.09293293e-05, -3.09957332e-04,  3.01178372e-05, ...,\n",
       "          -1.28135291e-04,  2.37925954e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5484634874928993,\n",
       "  'predicted_label': 1},\n",
       " 745: {'fold_num': 745,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.05013830e-05,  0.00000000e+00,  4.30055366e-05, ...,\n",
       "           7.01651224e-06, -5.12059388e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7746309941133857,\n",
       "  'predicted_label': 1},\n",
       " 746: {'fold_num': 746,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.05013830e-05, 0.00000000e+00, 2.34226452e-05, ...,\n",
       "          7.84666077e-05, 2.16537760e-06, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.7668858716532866,\n",
       "  'predicted_label': 1},\n",
       " 747: {'fold_num': 747,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.07413153e-05,  0.00000000e+00, -6.55553329e-06, ...,\n",
       "           1.77070602e-05, -2.03417413e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5322414312768415,\n",
       "  'predicted_label': 1},\n",
       " 748: {'fold_num': 748,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.64442239e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           4.06185514e-06, -3.06679914e-06, -2.57177729e-06]]),\n",
       "  'predictive_score': 0.6372710928777106,\n",
       "  'predicted_label': 1},\n",
       " 749: {'fold_num': 749,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 9.37675774e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.83632159e-05, -1.07816980e-04,  2.56383514e-06]]),\n",
       "  'predictive_score': 0.26697374226650544,\n",
       "  'predicted_label': 0},\n",
       " 750: {'fold_num': 750,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.29489571e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           2.82942449e-06, -2.26048994e-06, -1.26497046e-05]]),\n",
       "  'predictive_score': 0.8003663464588384,\n",
       "  'predicted_label': 1},\n",
       " 751: {'fold_num': 751,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.08341666e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.14367489e-06, -1.50689152e-06, -2.72087854e-06]]),\n",
       "  'predictive_score': 0.800252248439555,\n",
       "  'predicted_label': 1},\n",
       " 752: {'fold_num': 752,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -4.73385613e-05,  1.44553716e-05,  3.44762429e-06]]),\n",
       "  'predictive_score': 0.4188946143725555,\n",
       "  'predicted_label': 0},\n",
       " 753: {'fold_num': 753,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.48687422e-05,  0.00000000e+00, -6.47687578e-06]]),\n",
       "  'predictive_score': 0.905278281359164,\n",
       "  'predicted_label': 1},\n",
       " 754: {'fold_num': 754,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           1.17891228e-05,  0.00000000e+00, -3.84491198e-06]]),\n",
       "  'predictive_score': 0.10757131830158148,\n",
       "  'predicted_label': 0},\n",
       " 755: {'fold_num': 755,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -7.23128959e-06,  0.00000000e+00, -5.62333498e-06]]),\n",
       "  'predictive_score': 0.6683212404425639,\n",
       "  'predicted_label': 1},\n",
       " 756: {'fold_num': 756,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.52494749e-05, -2.03417413e-06, -3.69651861e-06]]),\n",
       "  'predictive_score': 0.6248142649833828,\n",
       "  'predicted_label': 1},\n",
       " 757: {'fold_num': 757,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -4.34795531e-05, ...,\n",
       "          -2.29993509e-05,  0.00000000e+00, -1.25909161e-05]]),\n",
       "  'predictive_score': 0.6566232558291383,\n",
       "  'predicted_label': 1},\n",
       " 758: {'fold_num': 758,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.21167855e-04, ...,\n",
       "          -2.29993509e-05,  0.00000000e+00, -2.71901275e-06]]),\n",
       "  'predictive_score': 0.703443920630453,\n",
       "  'predicted_label': 1},\n",
       " 759: {'fold_num': 759,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -3.73924267e-05, -3.69138163e-06]]),\n",
       "  'predictive_score': 0.5453033922776569,\n",
       "  'predicted_label': 1},\n",
       " 760: {'fold_num': 760,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.39155511e-05, ...,\n",
       "          -1.55727764e-05,  1.06766352e-05, -7.77972397e-04]]),\n",
       "  'predictive_score': 0.5200594571491309,\n",
       "  'predicted_label': 1},\n",
       " 761: {'fold_num': 761,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  4.46407888e-05, ...,\n",
       "          -1.89382235e-05,  1.09056436e-05,  4.07851912e-06]]),\n",
       "  'predictive_score': 0.8786248130954012,\n",
       "  'predicted_label': 1},\n",
       " 762: {'fold_num': 762,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.56741205e-04,  0.00000000e+00, -7.98393185e-06, ...,\n",
       "           0.00000000e+00, -2.96961633e-05,  5.86087262e-06]]),\n",
       "  'predictive_score': 0.2086152874902875,\n",
       "  'predicted_label': 0},\n",
       " 763: {'fold_num': 763,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -5.22563743e-05, ...,\n",
       "           0.00000000e+00,  5.52285894e-05,  2.56215723e-06]]),\n",
       "  'predictive_score': 0.3157685533420828,\n",
       "  'predicted_label': 0},\n",
       " 764: {'fold_num': 764,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  1.88702186e-05, ...,\n",
       "           4.39496982e-06, -5.15527275e-06, -2.71901275e-06]]),\n",
       "  'predictive_score': 0.7574282494681103,\n",
       "  'predicted_label': 1},\n",
       " 765: {'fold_num': 765,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  4.46075524e-05, ...,\n",
       "           4.39496982e-06,  1.09549546e-05, -3.70487345e-06]]),\n",
       "  'predictive_score': 0.817263937043349,\n",
       "  'predicted_label': 1},\n",
       " 766: {'fold_num': 766,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  1.25063874e-05, ...,\n",
       "           0.00000000e+00, -2.03417413e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5133046116680018,\n",
       "  'predicted_label': 1},\n",
       " 767: {'fold_num': 767,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.32262002e-06, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8089872901324309,\n",
       "  'predicted_label': 1},\n",
       " 768: {'fold_num': 768,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.08069977e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.7062424968822028,\n",
       "  'predicted_label': 1},\n",
       " 769: {'fold_num': 769,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.24347203e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5714535845131821,\n",
       "  'predicted_label': 1},\n",
       " 770: {'fold_num': 770,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           3.95434735e-05,  0.00000000e+00, -4.76158908e-05]]),\n",
       "  'predictive_score': 0.5813870157620158,\n",
       "  'predicted_label': 1},\n",
       " 771: {'fold_num': 771,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-0.00010043,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]),\n",
       "  'predictive_score': 0.1612224703401174,\n",
       "  'predicted_label': 0},\n",
       " 772: {'fold_num': 772,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[3.81846603e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.89382235e-05, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.4402562980320333,\n",
       "  'predicted_label': 0},\n",
       " 773: {'fold_num': 773,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.89382235e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8418317179896126,\n",
       "  'predicted_label': 1},\n",
       " 774: {'fold_num': 774,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.22873545e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8104413873450252,\n",
       "  'predicted_label': 1},\n",
       " 775: {'fold_num': 775,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[4.16173410e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.22873545e-05, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.2699418983793984,\n",
       "  'predicted_label': 0},\n",
       " 776: {'fold_num': 776,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          5.31598676e-05, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.10279976308091632,\n",
       "  'predicted_label': 0},\n",
       " 777: {'fold_num': 777,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  2.89408575e-05, ...,\n",
       "          -2.36589284e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5194133138533293,\n",
       "  'predicted_label': 1},\n",
       " 778: {'fold_num': 778,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  4.73769493e-05,  0.00000000e+00, ...,\n",
       "          -3.79219712e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7824441921382711,\n",
       "  'predicted_label': 1},\n",
       " 779: {'fold_num': 779,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[0.00000000e+00, 1.73870850e-04, 0.00000000e+00, ...,\n",
       "          2.93875831e-05, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.2773187338976812,\n",
       "  'predicted_label': 0},\n",
       " 780: {'fold_num': 780,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.32755924e-04, -2.19963438e-05,  0.00000000e+00, ...,\n",
       "           5.12467968e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.19571534837711305,\n",
       "  'predicted_label': 0},\n",
       " 781: {'fold_num': 781,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.20902183e-04, -1.97489896e-05,  0.00000000e+00, ...,\n",
       "           3.75198571e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.25074534566310885,\n",
       "  'predicted_label': 0},\n",
       " 782: {'fold_num': 782,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.18928656e-05, -3.77910032e-05,  0.00000000e+00, ...,\n",
       "          -2.06961048e-04,  0.00000000e+00, -5.53098216e-06]]),\n",
       "  'predictive_score': 0.4815341289257697,\n",
       "  'predicted_label': 0},\n",
       " 783: {'fold_num': 783,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.75379138e-05,  2.22020685e-05,  0.00000000e+00, ...,\n",
       "          -2.88786339e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5641465540178775,\n",
       "  'predicted_label': 1},\n",
       " 784: {'fold_num': 784,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.87528890e-06,  2.66781140e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.17882821e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8837094155844154,\n",
       "  'predicted_label': 1},\n",
       " 785: {'fold_num': 785,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.07536532e-04,  8.02348963e-05,  0.00000000e+00, ...,\n",
       "          -5.66975944e-06, -5.17882821e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8465510698451874,\n",
       "  'predicted_label': 1},\n",
       " 786: {'fold_num': 786,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.91379381e-04,  5.65641586e-04,  0.00000000e+00, ...,\n",
       "          -8.32626732e-05, -1.06057726e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1541937955835015,\n",
       "  'predicted_label': 0},\n",
       " 787: {'fold_num': 787,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.31977549e-04,  3.12932921e-05,  0.00000000e+00, ...,\n",
       "          -1.94420042e-05, -4.75331587e-04, -5.58243954e-06]]),\n",
       "  'predictive_score': 0.5174877121502507,\n",
       "  'predicted_label': 1},\n",
       " 788: {'fold_num': 788,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 7.38812415e-05,  5.86959161e-05,  0.00000000e+00, ...,\n",
       "          -1.32479739e-06,  6.45074034e-06, -2.56551444e-06]]),\n",
       "  'predictive_score': 0.5492477847357172,\n",
       "  'predicted_label': 1},\n",
       " 789: {'fold_num': 789,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.64832737e-04,  3.39562103e-05,  0.00000000e+00, ...,\n",
       "           6.65313579e-06,  6.52434086e-06, -1.24783746e-05]]),\n",
       "  'predictive_score': 0.7647062370678855,\n",
       "  'predicted_label': 1},\n",
       " 790: {'fold_num': 790,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.63331749e-05,  4.00939767e-05,  0.00000000e+00, ...,\n",
       "           1.79430581e-05,  6.52434086e-06, -1.24783746e-05]]),\n",
       "  'predictive_score': 0.8885580612627826,\n",
       "  'predicted_label': 1},\n",
       " 791: {'fold_num': 791,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-9.48019994e-05, -3.45477364e-05,  0.00000000e+00, ...,\n",
       "          -1.82597515e-05,  1.18969465e-04,  3.50881321e-05]]),\n",
       "  'predictive_score': 0.27611418457703285,\n",
       "  'predicted_label': 0},\n",
       " 792: {'fold_num': 792,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.19410906e-04,  2.36881231e-05,  0.00000000e+00, ...,\n",
       "           1.51911819e-05, -1.20214831e-05, -1.14956961e-05]]),\n",
       "  'predictive_score': 0.8246411513323278,\n",
       "  'predicted_label': 1},\n",
       " 793: {'fold_num': 793,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.78147401e-05, -3.33247314e-05,  0.00000000e+00, ...,\n",
       "           2.69107695e-05,  3.68863575e-06,  1.21779757e-04]]),\n",
       "  'predictive_score': 0.166702047952048,\n",
       "  'predicted_label': 0},\n",
       " 794: {'fold_num': 794,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.38005263e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.28324505e-05,  0.00000000e+00, -1.78876952e-05]]),\n",
       "  'predictive_score': 0.8454949964251435,\n",
       "  'predicted_label': 1},\n",
       " 795: {'fold_num': 795,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.22644194e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.55727764e-05,  2.85301268e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6150562697965949,\n",
       "  'predicted_label': 1},\n",
       " 796: {'fold_num': 796,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -3.82056990e-06, -1.48854994e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4388551750537043,\n",
       "  'predicted_label': 0},\n",
       " 797: {'fold_num': 797,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.60940753e-05, ...,\n",
       "          -1.98442749e-06, -4.06448102e-06,  1.28887809e-04]]),\n",
       "  'predictive_score': 0.44266363211951465,\n",
       "  'predicted_label': 0},\n",
       " 798: {'fold_num': 798,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.60940753e-05, ...,\n",
       "          -1.98442749e-06, -3.07164186e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3189804457238669,\n",
       "  'predicted_label': 0},\n",
       " 799: {'fold_num': 799,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.55055599e-05, -2.69105488e-05, ...,\n",
       "           4.38186896e-06,  1.30632330e-04, -1.81512617e-05]]),\n",
       "  'predictive_score': 0.8665297100775041,\n",
       "  'predicted_label': 1},\n",
       " 800: {'fold_num': 800,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.08413443e-05,  0.00000000e+00, -3.14985347e-06, ...,\n",
       "           1.56462253e-06, -1.32501313e-03, -1.95791088e-05]]),\n",
       "  'predictive_score': 0.6614270101000986,\n",
       "  'predicted_label': 1},\n",
       " 801: {'fold_num': 801,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.30323680e-05,  0.00000000e+00,  1.55724208e-04, ...,\n",
       "          -3.81778539e-06, -8.58884644e-05,  2.65086826e-05]]),\n",
       "  'predictive_score': 0.18098648225699304,\n",
       "  'predicted_label': 0},\n",
       " 802: {'fold_num': 802,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.69234703e-05, ...,\n",
       "          -1.41382288e-06,  2.35654668e-04,  4.06980132e-05]]),\n",
       "  'predictive_score': 0.47346845801257537,\n",
       "  'predicted_label': 0},\n",
       " 803: {'fold_num': 803,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.69234703e-05, ...,\n",
       "          -1.87791645e-06, -1.20305998e-05,  2.85247767e-05]]),\n",
       "  'predictive_score': 0.13632051975801976,\n",
       "  'predicted_label': 0},\n",
       " 804: {'fold_num': 804,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.83934826e-05, ...,\n",
       "          -5.45055071e-06, -3.04828854e-06, -2.44516996e-05]]),\n",
       "  'predictive_score': 0.2649665154891549,\n",
       "  'predicted_label': 0},\n",
       " 805: {'fold_num': 805,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  3.06900307e-05, ...,\n",
       "          -3.44751301e-05,  1.03654795e-05, -2.05443677e-05]]),\n",
       "  'predictive_score': 0.8501598413841062,\n",
       "  'predicted_label': 1},\n",
       " 806: {'fold_num': 806,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -2.64971739e-05, ...,\n",
       "           2.34816359e-06, -1.30590417e-05,  1.69020919e-06]]),\n",
       "  'predictive_score': 0.784599269001552,\n",
       "  'predicted_label': 1},\n",
       " 807: {'fold_num': 807,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.95188453e-05, -1.83751624e-05, ...,\n",
       "          -2.08039578e-06, -5.34709582e-06, -2.41808039e-05]]),\n",
       "  'predictive_score': 0.39265891583906287,\n",
       "  'predicted_label': 0},\n",
       " 808: {'fold_num': 808,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 9.42491212e-05, ...,\n",
       "          4.37245422e-06, 6.04675323e-05, 2.67435193e-05]]),\n",
       "  'predictive_score': 0.6620384794299268,\n",
       "  'predicted_label': 1},\n",
       " 809: {'fold_num': 809,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.26858342e-05, ...,\n",
       "          -1.39823577e-06, -1.87833695e-04, -1.61900467e-05]]),\n",
       "  'predictive_score': 0.41495076524352825,\n",
       "  'predicted_label': 0},\n",
       " 810: {'fold_num': 810,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           9.17948981e-06,  3.70958974e-06, -3.58716355e-06]]),\n",
       "  'predictive_score': 0.655864016702252,\n",
       "  'predicted_label': 1},\n",
       " 811: {'fold_num': 811,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.90164423e-05, -4.65649570e-06, -1.72127773e-05]]),\n",
       "  'predictive_score': 0.30490073606733825,\n",
       "  'predicted_label': 0},\n",
       " 812: {'fold_num': 812,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.08039578e-06, 3.16128143e-06, 9.30822601e-06]]),\n",
       "  'predictive_score': 0.8593260860871155,\n",
       "  'predicted_label': 1},\n",
       " 813: {'fold_num': 813,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.33257902e-06, 4.97724668e-06, 1.06923273e-05]]),\n",
       "  'predictive_score': 0.6801881521256522,\n",
       "  'predicted_label': 1},\n",
       " 814: {'fold_num': 814,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           2.08039578e-06,  6.65207891e-06, -6.20548400e-06]]),\n",
       "  'predictive_score': 0.7834627039627038,\n",
       "  'predicted_label': 1},\n",
       " 815: {'fold_num': 815,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00, -1.46532040e-05, ...,\n",
       "           4.37245422e-06,  1.25989577e-05, -6.20548400e-06]]),\n",
       "  'predictive_score': 0.7735867882117883,\n",
       "  'predicted_label': 1},\n",
       " 816: {'fold_num': 816,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.87960447e-06, 1.97769359e-04, 1.72127773e-05]]),\n",
       "  'predictive_score': 0.5815376163868811,\n",
       "  'predicted_label': 1},\n",
       " 817: {'fold_num': 817,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.00773830e-06,  9.31587552e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6302863888562418,\n",
       "  'predicted_label': 1},\n",
       " 818: {'fold_num': 818,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.58930440e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.04630451e-06,  7.12775095e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6502775531185363,\n",
       "  'predicted_label': 1},\n",
       " 819: {'fold_num': 819,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.27696375e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.21093074e-06,  9.62224943e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7168583461602036,\n",
       "  'predicted_label': 1},\n",
       " 820: {'fold_num': 820,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.85516045e-04, -3.85224908e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.67454277e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4020339754200048,\n",
       "  'predicted_label': 0},\n",
       " 821: {'fold_num': 821,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.25182868e-04, -2.50762192e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.26486294e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3865254552379164,\n",
       "  'predicted_label': 0},\n",
       " 822: {'fold_num': 822,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00025729, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "          0.        ]]),\n",
       "  'predictive_score': 0.47366711964506075,\n",
       "  'predicted_label': 0},\n",
       " 823: {'fold_num': 823,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.17804725e-04, -9.14853816e-06,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  3.91432634e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8243500972067149,\n",
       "  'predicted_label': 1},\n",
       " 824: {'fold_num': 824,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.42030416e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.52213757e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6289345780853133,\n",
       "  'predicted_label': 1},\n",
       " 825: {'fold_num': 825,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.36289025e-05,  2.98786638e-05, -1.34203541e-05, ...,\n",
       "           0.00000000e+00, -1.43631650e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8284240097278024,\n",
       "  'predicted_label': 1},\n",
       " 826: {'fold_num': 826,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.49283121e-05,  8.00553284e-06,  1.50186439e-05, ...,\n",
       "           0.00000000e+00,  7.63060782e-06, -2.64120484e-06]]),\n",
       "  'predictive_score': 0.253462430113746,\n",
       "  'predicted_label': 0},\n",
       " 827: {'fold_num': 827,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.56170912e-04,  1.37453866e-04,  2.89868343e-04, ...,\n",
       "           0.00000000e+00,  1.25874250e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4391859970954398,\n",
       "  'predicted_label': 0},\n",
       " 828: {'fold_num': 828,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.29849836e-03, -6.87559897e-05,  1.52175024e-05, ...,\n",
       "           0.00000000e+00,  2.01985792e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.42070730342498897,\n",
       "  'predicted_label': 0},\n",
       " 829: {'fold_num': 829,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.84236088e-04, -6.18611272e-05,  4.72010772e-05, ...,\n",
       "           0.00000000e+00,  1.84492836e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.07629552539225778,\n",
       "  'predicted_label': 0},\n",
       " 830: {'fold_num': 830,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 6.27232822e-04,  1.17597788e-04,  3.82984671e-05, ...,\n",
       "           0.00000000e+00, -1.21962766e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6370104695141459,\n",
       "  'predicted_label': 1},\n",
       " 831: {'fold_num': 831,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.10080791e-04, -7.84482156e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  9.49611696e-05, -3.39730163e-05]]),\n",
       "  'predictive_score': 0.6441011896600127,\n",
       "  'predicted_label': 1},\n",
       " 832: {'fold_num': 832,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[2.39547491e-04, 1.14213250e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.73482869e-06, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.5931705420052943,\n",
       "  'predicted_label': 1},\n",
       " 833: {'fold_num': 833,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.37809090e-04,  2.75495216e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.68195571e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7026261781519136,\n",
       "  'predicted_label': 1},\n",
       " 834: {'fold_num': 834,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.07999821e-05,  6.30102829e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.43267102e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8742767995892993,\n",
       "  'predicted_label': 1},\n",
       " 835: {'fold_num': 835,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.56360471e-04,  9.62534778e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7775028076498665,\n",
       "  'predicted_label': 1},\n",
       " 836: {'fold_num': 836,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00019255, 0.0003232 , 0.        , ..., 0.        , 0.        ,\n",
       "          0.        ]]),\n",
       "  'predictive_score': 0.7510503108003109,\n",
       "  'predicted_label': 1},\n",
       " 837: {'fold_num': 837,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.19148976e-04,  9.88585806e-05,  0.00000000e+00, ...,\n",
       "          -1.59971471e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.9265171462524405,\n",
       "  'predicted_label': 1},\n",
       " 838: {'fold_num': 838,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.24592405e-04, -4.76404206e-05,  0.00000000e+00, ...,\n",
       "          -7.42791887e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.15248061031246019,\n",
       "  'predicted_label': 0},\n",
       " 839: {'fold_num': 839,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.71930073e-05, -2.88717519e-05,  0.00000000e+00, ...,\n",
       "           1.67120671e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.45722653571918287,\n",
       "  'predicted_label': 0},\n",
       " 840: {'fold_num': 840,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.43975133e-04, -1.57691091e-04,  0.00000000e+00, ...,\n",
       "           1.85735678e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.47189158390629005,\n",
       "  'predicted_label': 0},\n",
       " 841: {'fold_num': 841,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.40163874e-04, -4.70498040e-05,  0.00000000e+00, ...,\n",
       "           1.95663454e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.47464306644937454,\n",
       "  'predicted_label': 0},\n",
       " 842: {'fold_num': 842,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.45107729e-03, -1.64420550e-04,  0.00000000e+00, ...,\n",
       "          -7.44740500e-05,  5.16684323e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4243606324231324,\n",
       "  'predicted_label': 0},\n",
       " 843: {'fold_num': 843,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 5.26576189e-05,  2.51689371e-04,  0.00000000e+00, ...,\n",
       "          -2.31997924e-05, -8.31965749e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3363909200534587,\n",
       "  'predicted_label': 0},\n",
       " 844: {'fold_num': 844,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.72238329e-04,  2.10448744e-05,  1.21635426e-05, ...,\n",
       "          -1.15998962e-05,  4.78631687e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6172575692281577,\n",
       "  'predicted_label': 1},\n",
       " 845: {'fold_num': 845,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.91438074e-04,  5.57745612e-05,  0.00000000e+00, ...,\n",
       "          -2.24161961e-05,  2.66879085e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7626061621342198,\n",
       "  'predicted_label': 1},\n",
       " 846: {'fold_num': 846,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.87721139e-05, 4.22999688e-05, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.51262072e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.679828255078255,\n",
       "  'predicted_label': 1},\n",
       " 847: {'fold_num': 847,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00032543,  0.        ,  0.        , ...,  0.        ,\n",
       "          -0.00015665,  0.        ]]),\n",
       "  'predictive_score': 0.5230740241440706,\n",
       "  'predicted_label': 1},\n",
       " 848: {'fold_num': 848,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.18324368e-04, 2.19600185e-05, 0.00000000e+00, ...,\n",
       "          6.26585103e-05, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.48701101186395307,\n",
       "  'predicted_label': 0},\n",
       " 849: {'fold_num': 849,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.42056489e-04, -1.40551948e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.79848611e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6355161325387721,\n",
       "  'predicted_label': 1},\n",
       " 850: {'fold_num': 850,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.90117061e-05,  1.03564593e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.32886011e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8282440794499615,\n",
       "  'predicted_label': 1},\n",
       " 851: {'fold_num': 851,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.36973559e-05,  4.87857820e-05, -7.70268002e-06, ...,\n",
       "           0.00000000e+00, -1.50501319e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5863752351664501,\n",
       "  'predicted_label': 1},\n",
       " 852: {'fold_num': 852,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.62433163e-05, -1.30089769e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.95423619e-03,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8581704512592673,\n",
       "  'predicted_label': 1},\n",
       " 853: {'fold_num': 853,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.57759961e-04, -1.61810663e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -3.29792597e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.19751002184090424,\n",
       "  'predicted_label': 0},\n",
       " 854: {'fold_num': 854,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.87222561e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.13881144e-06, -8.45033022e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.47059071855646956,\n",
       "  'predicted_label': 0},\n",
       " 855: {'fold_num': 855,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[5.94162525e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.68014087e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8103031352677251,\n",
       "  'predicted_label': 1},\n",
       " 856: {'fold_num': 856,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 8.57700069e-05, -7.29916702e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.55607151e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.636869830719676,\n",
       "  'predicted_label': 1},\n",
       " 857: {'fold_num': 857,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.49303756e-05, -7.83552969e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  2.94229371e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6751964990418934,\n",
       "  'predicted_label': 1},\n",
       " 858: {'fold_num': 858,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00016029, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "          0.        ]]),\n",
       "  'predictive_score': 0.5023271703786409,\n",
       "  'predicted_label': 1},\n",
       " 859: {'fold_num': 859,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-0.00067693,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]),\n",
       "  'predictive_score': 0.30182514868602345,\n",
       "  'predicted_label': 0},\n",
       " 860: {'fold_num': 860,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.34424217e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           9.32049241e-05, -7.31069062e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4194174096672161,\n",
       "  'predicted_label': 0},\n",
       " 861: {'fold_num': 861,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.05982093e-05, -2.21410575e-05,  0.00000000e+00, ...,\n",
       "          -5.81249425e-06,  3.80241821e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3026162256860786,\n",
       "  'predicted_label': 0},\n",
       " 862: {'fold_num': 862,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.13108501e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -2.23518143e-05, -1.48186506e-03,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7987953643578646,\n",
       "  'predicted_label': 1},\n",
       " 863: {'fold_num': 863,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.52523544e-06,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           3.37076396e-04,  4.82961111e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5305194999144301,\n",
       "  'predicted_label': 1},\n",
       " 864: {'fold_num': 864,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.11238362e-06,  0.00000000e+00,  3.06087191e-05, ...,\n",
       "          -5.66304600e-05, -2.05178913e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5655675692771284,\n",
       "  'predicted_label': 1},\n",
       " 865: {'fold_num': 865,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.63573859e-05,  0.00000000e+00,  5.90755868e-06, ...,\n",
       "           0.00000000e+00, -8.53784857e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.30394996261908036,\n",
       "  'predicted_label': 0},\n",
       " 866: {'fold_num': 866,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[3.70803098e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.54633949e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.511031858707168,\n",
       "  'predicted_label': 1},\n",
       " 867: {'fold_num': 867,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.47890793e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.75332011e-05, -2.47433585e-04]]),\n",
       "  'predictive_score': 0.34880901002592174,\n",
       "  'predicted_label': 0},\n",
       " 868: {'fold_num': 868,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-6.93579712e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.16412837e-04,  2.44010573e-04]]),\n",
       "  'predictive_score': 0.2566154900955598,\n",
       "  'predicted_label': 0},\n",
       " 869: {'fold_num': 869,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          -0.00011067,  0.        ]]),\n",
       "  'predictive_score': 0.44226520774547085,\n",
       "  'predicted_label': 0},\n",
       " 870: {'fold_num': 870,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.40671195e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6589642371517372,\n",
       "  'predicted_label': 1},\n",
       " 871: {'fold_num': 871,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[0.00000000e+00, 0.00000000e+00, 7.99015446e-06, ...,\n",
       "          0.00000000e+00, 9.25753293e-06, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6417493042088631,\n",
       "  'predicted_label': 1},\n",
       " 872: {'fold_num': 872,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.61940476e-04,  0.00000000e+00, -1.51340592e-05, ...,\n",
       "          -1.41391457e-06, -8.01271783e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2460918225865982,\n",
       "  'predicted_label': 0},\n",
       " 873: {'fold_num': 873,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.11715902e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.78263161e-06,  4.60631170e-05, -6.66434381e-05]]),\n",
       "  'predictive_score': 0.6938259842969208,\n",
       "  'predicted_label': 1},\n",
       " 874: {'fold_num': 874,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[5.60513120e-04, 0.00000000e+00, 6.31895808e-06, ...,\n",
       "          1.71793442e-05, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.41222687361657956,\n",
       "  'predicted_label': 0},\n",
       " 875: {'fold_num': 875,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.07090056e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.50258476e-05, 4.78341123e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.7787031605090818,\n",
       "  'predicted_label': 1},\n",
       " 876: {'fold_num': 876,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.90853897e-05,  4.78996386e-05,  0.00000000e+00, ...,\n",
       "          -9.21010053e-06,  2.85833060e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.796170825283248,\n",
       "  'predicted_label': 1},\n",
       " 877: {'fold_num': 877,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.37917978e-04, -1.49818539e-05,  0.00000000e+00, ...,\n",
       "          -7.44510771e-06,  5.92916200e-07,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7431735258205846,\n",
       "  'predicted_label': 1},\n",
       " 878: {'fold_num': 878,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[4.60518672e-05, 5.59740024e-06, 0.00000000e+00, ...,\n",
       "          3.35638731e-06, 1.69530003e-04, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.9250604508795301,\n",
       "  'predicted_label': 1},\n",
       " 879: {'fold_num': 879,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.27157045e-04,  3.53397180e-04,  0.00000000e+00, ...,\n",
       "           2.03417413e-06, -3.80244732e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7363557162608635,\n",
       "  'predicted_label': 1},\n",
       " 880: {'fold_num': 880,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.76483108e-04,  3.53397180e-04,  0.00000000e+00, ...,\n",
       "          -9.90821975e-06,  1.33717393e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8033002165318343,\n",
       "  'predicted_label': 1},\n",
       " 881: {'fold_num': 881,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.14958069e-04,  3.53397180e-04,  0.00000000e+00, ...,\n",
       "          -1.02319536e-05,  3.39596340e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.70681989701475,\n",
       "  'predicted_label': 1},\n",
       " 882: {'fold_num': 882,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.35717186e-04, -1.33045953e-05,  0.00000000e+00, ...,\n",
       "          -5.83574871e-05, -5.95126368e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.09942284214323685,\n",
       "  'predicted_label': 0},\n",
       " 883: {'fold_num': 883,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.85479744e-04, -1.33045953e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.00247665e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3741194104098515,\n",
       "  'predicted_label': 0},\n",
       " 884: {'fold_num': 884,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-9.03765263e-05,  2.27094305e-05,  0.00000000e+00, ...,\n",
       "           1.86602529e-05, -1.32488741e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2723701021201022,\n",
       "  'predicted_label': 0},\n",
       " 885: {'fold_num': 885,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.21548051e-04,  4.88015361e-05,  0.00000000e+00, ...,\n",
       "           1.86602529e-05, -1.13145943e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.35066323333099647,\n",
       "  'predicted_label': 0},\n",
       " 886: {'fold_num': 886,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.38509418e-05, -2.35558963e-05,  0.00000000e+00, ...,\n",
       "           3.35638731e-06,  1.13469970e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8242547468870999,\n",
       "  'predicted_label': 1},\n",
       " 887: {'fold_num': 887,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.44344623e-04, -1.67922007e-05,  0.00000000e+00, ...,\n",
       "           2.03843372e-05,  4.28704250e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8800152070152073,\n",
       "  'predicted_label': 1},\n",
       " 888: {'fold_num': 888,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.66640708e-05, -1.56922004e-05,  0.00000000e+00, ...,\n",
       "          -1.15269867e-05,  1.47698484e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7627523885428298,\n",
       "  'predicted_label': 1},\n",
       " 889: {'fold_num': 889,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.06537142e-04,  5.23073347e-06,  0.00000000e+00, ...,\n",
       "           2.03843372e-05,  2.52759071e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7841271190988011,\n",
       "  'predicted_label': 1},\n",
       " 890: {'fold_num': 890,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.66081587e-04,  2.27094305e-05, -2.94959125e-05, ...,\n",
       "           1.86387672e-05, -1.02842715e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.37225505785064605,\n",
       "  'predicted_label': 0},\n",
       " 891: {'fold_num': 891,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[5.67649962e-05, 2.03629154e-05, 0.00000000e+00, ...,\n",
       "          3.35638731e-06, 2.83218881e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6249333166833165,\n",
       "  'predicted_label': 1},\n",
       " 892: {'fold_num': 892,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.70352059e-04,  2.27021859e-05,  0.00000000e+00, ...,\n",
       "           1.86280728e-05, -1.33697216e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2961108017799194,\n",
       "  'predicted_label': 0},\n",
       " 893: {'fold_num': 893,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[7.13535698e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.03417413e-06, 3.90561379e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.7000496431672903,\n",
       "  'predicted_label': 1},\n",
       " 894: {'fold_num': 894,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[8.55828884e-05, 4.16346478e-05, 0.00000000e+00, ...,\n",
       "          2.03417413e-06, 4.60161935e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.8196704501638712,\n",
       "  'predicted_label': 1},\n",
       " 895: {'fold_num': 895,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.12336169e-04,  1.09833213e-05,  0.00000000e+00, ...,\n",
       "           2.04099817e-05,  2.01195359e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6764305604526196,\n",
       "  'predicted_label': 1},\n",
       " 896: {'fold_num': 896,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.86644792e-04,  1.56922004e-05,  0.00000000e+00, ...,\n",
       "           1.86280728e-05, -2.62825072e-05,  1.53628920e-05]]),\n",
       "  'predictive_score': 0.26475868681112497,\n",
       "  'predicted_label': 0},\n",
       " 897: {'fold_num': 897,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.86208189e-04,  2.26736283e-05,  0.00000000e+00, ...,\n",
       "          -2.03417413e-06, -1.20867051e-06, -1.14276252e-05]]),\n",
       "  'predictive_score': 0.2800166543123199,\n",
       "  'predicted_label': 0},\n",
       " 898: {'fold_num': 898,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.70099210e-04,  8.23041032e-06, -8.19109786e-06, ...,\n",
       "           2.05125597e-05,  1.93184377e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.707521554425966,\n",
       "  'predicted_label': 1},\n",
       " 899: {'fold_num': 899,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.56583357e-04,  5.59740024e-06, -1.09270131e-04, ...,\n",
       "           3.35638731e-06,  1.93184377e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6505979984068219,\n",
       "  'predicted_label': 1},\n",
       " 900: {'fold_num': 900,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.02494683e-04,  2.02855583e-05,  0.00000000e+00, ...,\n",
       "          -1.47355408e-05,  1.19532949e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8054002288561111,\n",
       "  'predicted_label': 1},\n",
       " 901: {'fold_num': 901,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.89789481e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.86067801e-05,  2.51742071e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5432341373366915,\n",
       "  'predicted_label': 1},\n",
       " 902: {'fold_num': 902,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.07558122e-05,  7.02953094e-05,  0.00000000e+00, ...,\n",
       "           7.04204448e-06, -7.85658135e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5534476578632925,\n",
       "  'predicted_label': 1},\n",
       " 903: {'fold_num': 903,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.33564091e-05,  9.78291909e-05,  0.00000000e+00, ...,\n",
       "           3.35638731e-06, -2.48699538e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7992358046365399,\n",
       "  'predicted_label': 1},\n",
       " 904: {'fold_num': 904,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-6.16378303e-05,  3.39464766e-05,  0.00000000e+00, ...,\n",
       "          -3.98736532e-05, -4.82019204e-07,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5649793054168054,\n",
       "  'predicted_label': 1},\n",
       " 905: {'fold_num': 905,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.37341848e-05,  2.48528235e-05,  0.00000000e+00, ...,\n",
       "          -1.38689682e-05, -1.43982967e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5224844729573831,\n",
       "  'predicted_label': 1},\n",
       " 906: {'fold_num': 906,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.08291446e-04, -9.61415989e-05,  0.00000000e+00, ...,\n",
       "          -1.93006055e-05, -2.03417413e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6200390622449444,\n",
       "  'predicted_label': 1},\n",
       " 907: {'fold_num': 907,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 8.87219344e-05,  1.09646406e-04,  0.00000000e+00, ...,\n",
       "          -1.63570688e-05,  3.81407648e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7462238777304568,\n",
       "  'predicted_label': 1},\n",
       " 908: {'fold_num': 908,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.73125332e-04,  1.16840180e-04,  0.00000000e+00, ...,\n",
       "          -3.28354944e-06,  3.71457884e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.09926981107128167,\n",
       "  'predicted_label': 0},\n",
       " 909: {'fold_num': 909,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.85075722e-04, -2.99574082e-05,  0.00000000e+00, ...,\n",
       "          -3.28354944e-06,  2.03417413e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.17579684058631423,\n",
       "  'predicted_label': 0},\n",
       " 910: {'fold_num': 910,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.25757636e-04,  6.38644790e-05, -2.30275550e-05, ...,\n",
       "          -6.52403821e-05, -1.54973054e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5104168070491598,\n",
       "  'predicted_label': 1},\n",
       " 911: {'fold_num': 911,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.66515511e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          -1.62254809e-05, -5.42170800e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.716299563181916,\n",
       "  'predicted_label': 1},\n",
       " 912: {'fold_num': 912,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.23440310e-04,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           9.58135731e-06, -3.81407648e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3472141726737314,\n",
       "  'predicted_label': 0},\n",
       " 913: {'fold_num': 913,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.50961575e-04, -6.84567557e-05,  0.00000000e+00, ...,\n",
       "          -4.90194441e-05,  1.38932076e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.35840723124914303,\n",
       "  'predicted_label': 0},\n",
       " 914: {'fold_num': 914,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 0.00000000e+00,  3.31429878e-05,  0.00000000e+00, ...,\n",
       "          -5.50385948e-06,  1.01657025e-05,  6.28848941e-06]]),\n",
       "  'predictive_score': 0.7526783641195408,\n",
       "  'predicted_label': 1},\n",
       " 915: {'fold_num': 915,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 5.75148985e-04,  6.85384359e-05,  0.00000000e+00, ...,\n",
       "          -1.25437572e-05,  2.60497642e-05, -6.88098454e-06]]),\n",
       "  'predictive_score': 0.5699356093253148,\n",
       "  'predicted_label': 1},\n",
       " 916: {'fold_num': 916,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.90236010e-05, -5.85739177e-05,  0.00000000e+00, ...,\n",
       "          -1.10918747e-05, -1.56427711e-05, -2.38621744e-05]]),\n",
       "  'predictive_score': 0.8476754820471926,\n",
       "  'predicted_label': 1},\n",
       " 917: {'fold_num': 917,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 9.16865616e-05,  1.08906613e-04,  0.00000000e+00, ...,\n",
       "          -8.51432736e-06,  3.81407648e-06,  1.53399693e-05]]),\n",
       "  'predictive_score': 0.8526195814634279,\n",
       "  'predicted_label': 1},\n",
       " 918: {'fold_num': 918,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.03609117e-04,  1.82881356e-04,  0.00000000e+00, ...,\n",
       "          -8.87737187e-06,  0.00000000e+00,  1.53399693e-05]]),\n",
       "  'predictive_score': 0.7820300546976245,\n",
       "  'predicted_label': 1},\n",
       " 919: {'fold_num': 919,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.78544014e-04, -1.08987646e-04,  0.00000000e+00, ...,\n",
       "          -1.16746430e-05,  0.00000000e+00,  1.53399693e-05]]),\n",
       "  'predictive_score': 0.8699654789654789,\n",
       "  'predicted_label': 1},\n",
       " 920: {'fold_num': 920,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.46498355e-04,  6.87028081e-05,  0.00000000e+00, ...,\n",
       "          -1.04542738e-04,  0.00000000e+00, -6.88098454e-06]]),\n",
       "  'predictive_score': 0.5425202391562685,\n",
       "  'predicted_label': 1},\n",
       " 921: {'fold_num': 921,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.62530016e-04,  1.01989838e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.28464237e-05, -1.47056655e-05]]),\n",
       "  'predictive_score': 0.7939149755473285,\n",
       "  'predicted_label': 1},\n",
       " 922: {'fold_num': 922,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.79330338e-05,  2.02350211e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -2.17793991e-05]]),\n",
       "  'predictive_score': 0.8381103778832106,\n",
       "  'predicted_label': 1},\n",
       " 923: {'fold_num': 923,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[1.26608326e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.10178572e-06]]),\n",
       "  'predictive_score': 0.8297143408062526,\n",
       "  'predicted_label': 1},\n",
       " 924: {'fold_num': 924,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-8.43838674e-05, -6.87855046e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -2.02271808e-05]]),\n",
       "  'predictive_score': 0.40441284188807414,\n",
       "  'predicted_label': 0},\n",
       " 925: {'fold_num': 925,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 7.76067852e-05,  3.32018913e-05, -2.11061897e-05, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6516604428423315,\n",
       "  'predicted_label': 1},\n",
       " 926: {'fold_num': 926,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.38517333e-04, -6.90356616e-05,  2.11061897e-05, ...,\n",
       "           0.00000000e+00, -6.51954388e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.26194295224170544,\n",
       "  'predicted_label': 0},\n",
       " 927: {'fold_num': 927,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[4.46508505e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.84983138e-05, 0.00000000e+00]]),\n",
       "  'predictive_score': 0.6520193731389385,\n",
       "  'predicted_label': 1},\n",
       " 928: {'fold_num': 928,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.74962938e-04,  5.26313235e-05, -3.57310863e-06, ...,\n",
       "           0.00000000e+00, -1.54119589e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5732026186532765,\n",
       "  'predicted_label': 1},\n",
       " 929: {'fold_num': 929,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 6.78511247e-05,  1.11614179e-04, -3.57310863e-06, ...,\n",
       "           0.00000000e+00,  3.27914019e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7511143648018647,\n",
       "  'predicted_label': 1},\n",
       " 930: {'fold_num': 930,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 4.54137126e-04,  2.86032323e-05, -1.98836336e-06, ...,\n",
       "           0.00000000e+00,  3.27914019e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5592152109586318,\n",
       "  'predicted_label': 1},\n",
       " 931: {'fold_num': 931,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.93082840e-05,  3.68259865e-05, -1.33323748e-06, ...,\n",
       "           0.00000000e+00,  1.84730953e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8495380089681559,\n",
       "  'predicted_label': 1},\n",
       " 932: {'fold_num': 932,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 1.37845501e-04,  3.23715092e-05, -1.06656114e-06, ...,\n",
       "           7.76762693e-06,  5.89437433e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8383253153365382,\n",
       "  'predicted_label': 1},\n",
       " 933: {'fold_num': 933,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 2.12785027e-04,  1.00525484e-04, -3.58384715e-06, ...,\n",
       "           3.28354944e-06, -5.41785498e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8282101038581299,\n",
       "  'predicted_label': 1},\n",
       " 934: {'fold_num': 934,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-4.70646087e-04,  3.33047522e-05, -5.78603102e-06, ...,\n",
       "           6.99738444e-06, -2.15838203e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5989012021475258,\n",
       "  'predicted_label': 1},\n",
       " 935: {'fold_num': 935,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.00215863e-05,  6.28201876e-05, -5.15979613e-06, ...,\n",
       "           2.03417413e-06,  1.02422880e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8578810768479884,\n",
       "  'predicted_label': 1},\n",
       " 936: {'fold_num': 936,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.68041571e-04, -6.90113012e-05,  9.32595472e-06, ...,\n",
       "          -6.99738444e-06,  2.15838203e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.473316357253857,\n",
       "  'predicted_label': 0},\n",
       " 937: {'fold_num': 937,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.93537644e-04, -3.01755199e-05,  7.84322280e-06, ...,\n",
       "           1.91540384e-05, -5.52144240e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.4264036301890404,\n",
       "  'predicted_label': 0},\n",
       " 938: {'fold_num': 938,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-3.02554487e-04,  9.75962239e-05, -4.58796135e-06, ...,\n",
       "           7.75904392e-06, -2.15838203e-05,  4.18182357e-05]]),\n",
       "  'predictive_score': 0.6667988229950303,\n",
       "  'predicted_label': 1},\n",
       " 939: {'fold_num': 939,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-9.78735227e-05, -3.41640976e-05,  1.77403498e-06, ...,\n",
       "           1.91540384e-05,  1.22740701e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.43410780232839036,\n",
       "  'predicted_label': 0},\n",
       " 940: {'fold_num': 940,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.16757157e-04,  1.48188168e-04,  5.24623992e-05, ...,\n",
       "           9.73306886e-05, -7.81997269e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8389505425130425,\n",
       "  'predicted_label': 1},\n",
       " 941: {'fold_num': 941,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.13392215e-04,  3.22914137e-08,  0.00000000e+00, ...,\n",
       "           3.35638731e-06, -3.00418567e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.5969977261300791,\n",
       "  'predicted_label': 1},\n",
       " 942: {'fold_num': 942,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.24605369e-04, -2.07113479e-04,  0.00000000e+00, ...,\n",
       "           3.35638731e-06, -1.22768410e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.6596133984479571,\n",
       "  'predicted_label': 1},\n",
       " 943: {'fold_num': 943,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.39033074e-04, -3.88971081e-05,  0.00000000e+00, ...,\n",
       "           9.94635562e-05, -3.64112362e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.7875141872016872,\n",
       "  'predicted_label': 1},\n",
       " 944: {'fold_num': 944,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.45219862e-04, -5.60162563e-05,  0.00000000e+00, ...,\n",
       "           7.83243969e-06, -5.20075001e-06, -1.68233695e-06]]),\n",
       "  'predictive_score': 0.725031260320347,\n",
       "  'predicted_label': 1},\n",
       " 945: {'fold_num': 945,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-2.41069788e-04,  9.01475747e-06,  0.00000000e+00, ...,\n",
       "           3.35638731e-06, -4.46662903e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.8476189823248645,\n",
       "  'predicted_label': 1},\n",
       " 946: {'fold_num': 946,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.76881027e-04,  3.47385474e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.25197100e-05,  3.71673755e-06]]),\n",
       "  'predictive_score': 0.46795542125573064,\n",
       "  'predicted_label': 0},\n",
       " 947: {'fold_num': 947,\n",
       "  'correct': False,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.44049010e-04,  1.08867488e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.74154772e-05, -2.59285126e-06]]),\n",
       "  'predictive_score': 0.5382999695952482,\n",
       "  'predicted_label': 1},\n",
       " 948: {'fold_num': 948,\n",
       "  'correct': True,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[-1.35254736e-06,  2.53424587e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.70402277e-07, -1.22323745e-05]]),\n",
       "  'predictive_score': 0.5218452383100215,\n",
       "  'predicted_label': 1},\n",
       " 949: {'fold_num': 949,\n",
       "  'correct': False,\n",
       "  'label': 1,\n",
       "  'shap_values': array([[ 3.02883273e-06, -3.01622541e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.90776443e-06,  6.92413275e-06]]),\n",
       "  'predictive_score': 0.48956094243304,\n",
       "  'predicted_label': 0},\n",
       " 950: {'fold_num': 950,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.43197490e-04, -2.39569408e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.51632692e-06,  2.47597416e-05]]),\n",
       "  'predictive_score': 0.47778354712023424,\n",
       "  'predicted_label': 0},\n",
       " 951: {'fold_num': 951,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-0.00018657,  0.00011468,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]),\n",
       "  'predictive_score': 0.1679369197838625,\n",
       "  'predicted_label': 0},\n",
       " 952: {'fold_num': 952,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.02021853e-04, -9.79499161e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -1.52250318e-05,  6.33660631e-06]]),\n",
       "  'predictive_score': 0.10802153258248456,\n",
       "  'predicted_label': 0},\n",
       " 953: {'fold_num': 953,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.23535947e-04, -2.03967560e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  4.84983888e-06,  3.17555362e-05]]),\n",
       "  'predictive_score': 0.22377223763079018,\n",
       "  'predicted_label': 0},\n",
       " 954: {'fold_num': 954,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.98011276e-04,  9.54706681e-04,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  1.19217168e-05, -1.53405592e-05]]),\n",
       "  'predictive_score': 0.3680574862229274,\n",
       "  'predicted_label': 0},\n",
       " 955: {'fold_num': 955,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.03963283e-04,  8.95201076e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  3.77354041e-06,  2.63939569e-05]]),\n",
       "  'predictive_score': 0.38570321802810204,\n",
       "  'predicted_label': 0},\n",
       " 956: {'fold_num': 956,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 4.74682395e-04, -6.94984239e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.17850159e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.22575626978800353,\n",
       "  'predicted_label': 0},\n",
       " 957: {'fold_num': 957,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.78483807e-04,  1.19464979e-04,  0.00000000e+00, ...,\n",
       "          -2.03417413e-06,  0.00000000e+00,  7.17334234e-06]]),\n",
       "  'predictive_score': 0.22171253746253738,\n",
       "  'predicted_label': 0},\n",
       " 958: {'fold_num': 958,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 9.01004124e-04, -6.27669524e-05,  0.00000000e+00, ...,\n",
       "           1.85645757e-05, -7.28032826e-04,  1.02247741e-05]]),\n",
       "  'predictive_score': 0.35687769430861543,\n",
       "  'predicted_label': 0},\n",
       " 959: {'fold_num': 959,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.23695339e-04, -1.67157105e-05,  0.00000000e+00, ...,\n",
       "          -2.03417413e-06,  0.00000000e+00, -1.53371612e-05]]),\n",
       "  'predictive_score': 0.2857162918565782,\n",
       "  'predicted_label': 0},\n",
       " 960: {'fold_num': 960,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.30598852e-04, -6.90985726e-05,  0.00000000e+00, ...,\n",
       "           1.85645757e-05, -5.30098035e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.21449458428568352,\n",
       "  'predicted_label': 0},\n",
       " 961: {'fold_num': 961,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.07996319e-04, -8.50472260e-05,  0.00000000e+00, ...,\n",
       "           1.85645757e-05, -5.17850159e-06, -7.83454781e-05]]),\n",
       "  'predictive_score': 0.2937031310837424,\n",
       "  'predicted_label': 0},\n",
       " 962: {'fold_num': 962,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.58089474e-04, -3.41209767e-05,  0.00000000e+00, ...,\n",
       "          -3.27610160e-06,  0.00000000e+00, -9.54014836e-06]]),\n",
       "  'predictive_score': 0.29302370382885096,\n",
       "  'predicted_label': 0},\n",
       " 963: {'fold_num': 963,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.94855257e-04, -2.49536560e-05,  0.00000000e+00, ...,\n",
       "           2.29669140e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.11455896805722655,\n",
       "  'predicted_label': 0},\n",
       " 964: {'fold_num': 964,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.47006735e-04,  2.19985757e-05,  0.00000000e+00, ...,\n",
       "           1.11188861e-05,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.06930844430767032,\n",
       "  'predicted_label': 0},\n",
       " 965: {'fold_num': 965,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.04452773e-05, -1.85309203e-05,  0.00000000e+00, ...,\n",
       "           5.41527479e-06,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.33375890735081915,\n",
       "  'predicted_label': 0},\n",
       " 966: {'fold_num': 966,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.74368614e-04, -6.90113012e-05,  0.00000000e+00, ...,\n",
       "           4.64764020e-05, -6.92266456e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.25420359419991767,\n",
       "  'predicted_label': 0},\n",
       " 967: {'fold_num': 967,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 6.93452447e-04, -6.90113012e-05, -5.91149354e-05, ...,\n",
       "          -1.79930117e-05,  0.00000000e+00, -1.53371612e-05]]),\n",
       "  'predictive_score': 0.2895603840603841,\n",
       "  'predicted_label': 0},\n",
       " 968: {'fold_num': 968,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.48967754e-04, -3.01755199e-05,  0.00000000e+00, ...,\n",
       "           1.28073933e-05,  0.00000000e+00, -8.82920868e-06]]),\n",
       "  'predictive_score': 0.11730538873321378,\n",
       "  'predicted_label': 0},\n",
       " 969: {'fold_num': 969,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.39639586e-06, -5.25820923e-05,  0.00000000e+00, ...,\n",
       "           1.85436616e-05,  0.00000000e+00, -1.53371612e-05]]),\n",
       "  'predictive_score': 0.2705475901807171,\n",
       "  'predicted_label': 0},\n",
       " 970: {'fold_num': 970,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.92434071e-05, -3.01755199e-05,  0.00000000e+00, ...,\n",
       "          -3.27241088e-06,  0.00000000e+00,  7.17334234e-06]]),\n",
       "  'predictive_score': 0.13381289543789546,\n",
       "  'predicted_label': 0},\n",
       " 971: {'fold_num': 971,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.05070860e-04, -2.08688519e-05, -5.53071943e-04, ...,\n",
       "          -2.03417413e-06,  1.05188430e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.14127492645495576,\n",
       "  'predicted_label': 0},\n",
       " 972: {'fold_num': 972,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 3.84723279e-05, -5.16128085e-05,  2.24290966e-05, ...,\n",
       "          -1.98065954e-05, -5.52144240e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3122961310490334,\n",
       "  'predicted_label': 0},\n",
       " 973: {'fold_num': 973,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.67853185e-05,  1.38147594e-04,  5.29889047e-06, ...,\n",
       "          -2.03417413e-06,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.19515621184371182,\n",
       "  'predicted_label': 0},\n",
       " 974: {'fold_num': 974,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.29215547e-05, -2.44506557e-04,  2.45990369e-06, ...,\n",
       "           5.98425221e-05,  0.00000000e+00, -5.75427984e-06]]),\n",
       "  'predictive_score': 0.3804038061396808,\n",
       "  'predicted_label': 0},\n",
       " 975: {'fold_num': 975,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.18364764e-05, -4.83363321e-05, -9.37587209e-06, ...,\n",
       "          -7.74638541e-05,  1.21530809e-05, -5.75427984e-06]]),\n",
       "  'predictive_score': 0.20237987086013398,\n",
       "  'predicted_label': 0},\n",
       " 976: {'fold_num': 976,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.49327775e-05,  2.20657655e-05, -7.87440400e-05, ...,\n",
       "          -1.74082764e-04, -6.67319606e-05, -3.49728412e-05]]),\n",
       "  'predictive_score': 0.2590601273726274,\n",
       "  'predicted_label': 0},\n",
       " 977: {'fold_num': 977,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-7.24219854e-05,  2.36195374e-05, -8.15830268e-05, ...,\n",
       "          -1.92309340e-04, -2.96498411e-05, -7.85523429e-06]]),\n",
       "  'predictive_score': 0.19354127563183288,\n",
       "  'predicted_label': 0},\n",
       " 978: {'fold_num': 978,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.33198590e-05, -1.65341392e-05,  2.97009163e-04, ...,\n",
       "           1.50461614e-05, -3.39533965e-05, -9.00643154e-06]]),\n",
       "  'predictive_score': 0.29416057063851186,\n",
       "  'predicted_label': 0},\n",
       " 979: {'fold_num': 979,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 7.03923417e-05,  3.03775297e-05, -1.00151626e-05, ...,\n",
       "           1.75621021e-05, -6.34477597e-05, -5.73920009e-06]]),\n",
       "  'predictive_score': 0.14596473420370473,\n",
       "  'predicted_label': 0},\n",
       " 980: {'fold_num': 980,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.90855694e-05, -3.44278670e-05, -7.92798404e-06, ...,\n",
       "           3.04508225e-05,  1.70999640e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.1319400011752953,\n",
       "  'predicted_label': 0},\n",
       " 981: {'fold_num': 981,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.29299478e-05, -2.94229229e-05, ...,\n",
       "           1.66027562e-04,  9.72429481e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.16700110854058217,\n",
       "  'predicted_label': 0},\n",
       " 982: {'fold_num': 982,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-9.05461803e-05, -1.65016103e-05,  3.18088056e-05, ...,\n",
       "           1.85750796e-05, -8.80879421e-05,  9.72798860e-06]]),\n",
       "  'predictive_score': 0.3288327272057148,\n",
       "  'predicted_label': 0},\n",
       " 983: {'fold_num': 983,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.32736000e-05, -3.42994264e-05, -3.30596891e-05, ...,\n",
       "           5.07957496e-06,  3.52168420e-04,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3286231681330365,\n",
       "  'predicted_label': 0},\n",
       " 984: {'fold_num': 984,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.62016430e-04, -1.36637729e-05, -6.93809012e-05, ...,\n",
       "           1.93729588e-05,  1.92435751e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3177217622848428,\n",
       "  'predicted_label': 0},\n",
       " 985: {'fold_num': 985,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.71236896e-04,  1.45420922e-05, -4.09833968e-05, ...,\n",
       "           4.40989684e-05, -4.03865642e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.3177858967872512,\n",
       "  'predicted_label': 0},\n",
       " 986: {'fold_num': 986,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-5.65985208e-05, -1.34310492e-05,  4.95237280e-06, ...,\n",
       "           0.00000000e+00, -3.69225731e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2799650737334561,\n",
       "  'predicted_label': 0},\n",
       " 987: {'fold_num': 987,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.40616377e-04, -1.64899942e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.05099158e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.07714052614052612,\n",
       "  'predicted_label': 0},\n",
       " 988: {'fold_num': 988,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-1.64626642e-04, -2.49068527e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -7.53572366e-06,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.13410289607193632,\n",
       "  'predicted_label': 0},\n",
       " 989: {'fold_num': 989,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.83198140e-04, -1.64810378e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -3.39079418e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.12604629507918977,\n",
       "  'predicted_label': 0},\n",
       " 990: {'fold_num': 990,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.32741315e-04, -3.43036194e-05,  5.41732688e-06, ...,\n",
       "           0.00000000e+00, -2.66874371e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.21104521173271182,\n",
       "  'predicted_label': 0},\n",
       " 991: {'fold_num': 991,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.69828456e-04,  4.53644803e-05, -6.07030480e-05, ...,\n",
       "           0.00000000e+00, -1.69213985e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.38747765640156956,\n",
       "  'predicted_label': 0},\n",
       " 992: {'fold_num': 992,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-2.18618650e-05, -1.20001610e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -2.21864586e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.16456100688956732,\n",
       "  'predicted_label': 0},\n",
       " 993: {'fold_num': 993,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-4.95774905e-04, -5.13006845e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -4.94039088e-05,  7.17334234e-06]]),\n",
       "  'predictive_score': 0.22471629759129755,\n",
       "  'predicted_label': 0},\n",
       " 994: {'fold_num': 994,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[-3.26217567e-05,  1.45218629e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.90016493e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.2193814175842628,\n",
       "  'predicted_label': 0},\n",
       " 995: {'fold_num': 995,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00, -1.88583766e-05,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  9.58402137e-05, -1.53371612e-05]]),\n",
       "  'predictive_score': 0.22304818082244554,\n",
       "  'predicted_label': 0},\n",
       " 996: {'fold_num': 996,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00, -5.89065944e-05, -1.53371612e-05]]),\n",
       "  'predictive_score': 0.2806389789690873,\n",
       "  'predicted_label': 0},\n",
       " 997: {'fold_num': 997,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 2.02461800e-05,  0.00000000e+00,  3.79666754e-05, ...,\n",
       "           0.00000000e+00, -1.54927006e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.26949502703179173,\n",
       "  'predicted_label': 0},\n",
       " 998: {'fold_num': 998,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 1.51168725e-05,  0.00000000e+00, -8.54907361e-05, ...,\n",
       "           0.00000000e+00, -2.88995182e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.14113738344988344,\n",
       "  'predicted_label': 0},\n",
       " 999: {'fold_num': 999,\n",
       "  'correct': True,\n",
       "  'label': 0,\n",
       "  'shap_values': array([[ 7.79459017e-05,  0.00000000e+00, -6.22731803e-05, ...,\n",
       "           0.00000000e+00, -5.87209870e-05,  0.00000000e+00]]),\n",
       "  'predictive_score': 0.09185268487532415,\n",
       "  'predicted_label': 0},\n",
       " ...}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531b4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the dictionary: 1230\n",
      "Last five keys in the dictionary: [1225, 1226, 1227, 1228, 1229]\n"
     ]
    }
   ],
   "source": [
    "num_keys = len(loaded_shap_values)\n",
    "print(\"Number of keys in the dictionary:\", num_keys)\n",
    "\n",
    "last_five_keys = list(loaded_shap_values.keys())[-5:]\n",
    "print(\"Last five keys in the dictionary:\", last_five_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04618adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_five_keys = list(loaded_shap_values.keys())[-5:]\n",
    "\n",
    "# Print the last five elements\n",
    "for key in last_five_keys:\n",
    "    print(f\"Key: {key}, Value: {loaded_shap_values[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf66b51",
   "metadata": {},
   "source": [
    "## Obtaining RF metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63b8659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.00      0.00      0.00       615\n",
      "          AD       0.50      1.00      0.67       615\n",
      "\n",
      "    accuracy                           0.50      1230\n",
      "   macro avg       0.25      0.50      0.33      1230\n",
      "weighted avg       0.25      0.50      0.33      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmottaqi/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vmottaqi/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vmottaqi/.conda/envs/mcf7/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# use the next one\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Load the dictionary from the pickle file\n",
    "with open('shap_values_16_13k_clinical.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)\n",
    "\n",
    "# Extract true labels and predicted labels from the dictionary\n",
    "true_labels = [value['label'] for value in shap_values_per_sample.values()]\n",
    "predicted_labels = [value['predictive_score'] >= 0.5 for value in shap_values_per_sample.values()]  # Convert predictive scores to binary labels\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Control', 'AD'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4d177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.86      0.89      0.88       615\n",
      "          AD       0.89      0.86      0.87       615\n",
      "\n",
      "    accuracy                           0.87      1230\n",
      "   macro avg       0.88      0.87      0.87      1230\n",
      "weighted avg       0.88      0.87      0.87      1230\n",
      "\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Load the SHAP values dictionary from the file\n",
    "with open('shap_values_16_13k_clinical.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)\n",
    "\n",
    "# Extract true labels and predicted labels from the dictionary\n",
    "true_labels = [result['label'] for result in shap_values_per_sample.values()]\n",
    "predicted_labels = [result['predicted_label'] for result in shap_values_per_sample.values()]\n",
    "\n",
    "# Calculate and print classification metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['Control', 'AD']))\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f50c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f4f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d161a0ec",
   "metadata": {},
   "source": [
    "## Filtering the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2616699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dictionary from the pickle file\n",
    "with open('shap_values_16_13k_clinical.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the correctly  classified AD samples: 527\n"
     ]
    }
   ],
   "source": [
    "# Filter the dictionary to include only the samples that are AD (1), correctly classified, and have higher-than-average prediction scores\n",
    "filtered_dict = {key: value for key, value in shap_values_per_sample.items()\n",
    "                 if value['label'] == 1 and value['correct']}\n",
    "\n",
    "print(f\"All the correctly  classified AD samples: {len(filtered_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0168f7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the filtered dictionary: 298\n"
     ]
    }
   ],
   "source": [
    "# next one is more accurate\n",
    "# This contains samples with higher than average predcition score among all AD samples\n",
    "import numpy as np\n",
    "\n",
    "# Filter the dictionary to include only the samples that are AD (1), correctly classified, and have higher-than-average prediction scores\n",
    "filtered_dict = {key: value for key, value in shap_values_per_sample.items()\n",
    "                 if value['label'] == 1 and value['correct'] and value['predictive_score'] > np.mean([v['predictive_score'] for v in shap_values_per_sample.values() if v['label'] == 1])}\n",
    "\n",
    "print(f\"Number of samples in the filtered dictionary: {len(filtered_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd82500e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This contains samples with higher than average predcition score among correctly-classified AD samples\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate the average predictive score among AD correctly classified samples\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m average_score_ad_correct \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean([value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictive_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m shap_values_per_sample\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter the dictionary to include only the samples that are AD (1), correctly classified, and have a predictive score higher than the average among AD correctly classified samples\u001b[39;00m\n\u001b[1;32m      7\u001b[0m filtered_dict \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m shap_values_per_sample\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m      8\u001b[0m                  \u001b[38;5;28;01mif\u001b[39;00m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictive_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m average_score_ad_correct}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# This contains samples with higher than average predcition score among correctly-classified AD samples\n",
    "\n",
    "# Calculate the average predictive score among AD correctly classified samples\n",
    "average_score_ad_correct = np.mean([value['predictive_score'] for value in shap_values_per_sample.values() if value['label'] == 1 and value['correct']])\n",
    "\n",
    "# Filter the dictionary to include only the samples that are AD (1), correctly classified, and have a predictive score higher than the average among AD correctly classified samples\n",
    "filtered_dict = {key: value for key, value in shap_values_per_sample.items()\n",
    "                 if value['label'] == 1 and value['correct'] and value['predictive_score'] > average_score_ad_correct}\n",
    "\n",
    "print(f\"Number of samples in the filtered dictionary: {len(filtered_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232b058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of SHAP values for the first sample: 12999\n"
     ]
    }
   ],
   "source": [
    "# Get the first sample's SHAP values from the filtered dictionary\n",
    "first_sample_shap_values = list(filtered_dict.values())[1]['shap_values']\n",
    "\n",
    "# Print the length of the SHAP values array for the first sample\n",
    "print(\"Length of SHAP values for the first sample:\", len(first_sample_shap_values[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f512e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of zero SHAP values for sample 1: 7596\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the SHAP values for sample 1\n",
    "sample_1_shap_values = filtered_dict[16]['shap_values'][0]\n",
    "\n",
    "# Count the number of zero SHAP values\n",
    "num_zeros = np.count_nonzero(sample_1_shap_values == 0)\n",
    "\n",
    "# Print the total number of zero SHAP values for sample 1\n",
    "print(\"Total number of zero SHAP values for sample 1:\", num_zeros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2321cc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of zero SHAP values for all samples: 7605.025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count the number of zero SHAP values for each sample\n",
    "zero_counts = [np.count_nonzero(value['shap_values'] == 0) for value in filtered_dict.values()]\n",
    "\n",
    "# Calculate the mean number of zero SHAP values\n",
    "mean_zero_count = np.mean(zero_counts)\n",
    "\n",
    "# Print the mean number of zero SHAP values\n",
    "print(\"Mean number of zero SHAP values for all samples:\", mean_zero_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c5805fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of positive SHAP values for all samples: 3262.2214285714285\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count the number of positive SHAP values for each sample\n",
    "positive_counts = [np.count_nonzero(value['shap_values'] > 0) for value in filtered_dict.values()]\n",
    "\n",
    "# Calculate the mean number of positive SHAP values\n",
    "mean_positive_count = np.mean(positive_counts)\n",
    "\n",
    "# Print the mean number of positive SHAP values\n",
    "print(\"Mean number of positive SHAP values for all samples:\", mean_positive_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657d439",
   "metadata": {},
   "source": [
    "## Distribution of SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24722a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine all SHAP values from all samples into a single list\n",
    "all_shap_values = np.concatenate([value['shap_values'][0] for value in filtered_dict.values()])\n",
    "\n",
    "# Plot a histogram of the SHAP values\n",
    "plt.hist(all_shap_values, bins=150, color='blue', alpha=0.7)\n",
    "plt.xlabel('SHAP Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of SHAP Values for All Samples')\n",
    "#plt.xlim(-0.004, 0.004)  # Set the x-axis range\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine all SHAP values from all samples into a single list and take their absolute values\n",
    "all_abs_shap_values = np.abs(np.concatenate([value['shap_values'][0] for value in filtered_dict.values()]))\n",
    "\n",
    "# Plot a histogram of the absolute SHAP values\n",
    "plt.hist(all_abs_shap_values, bins=150, color='green', alpha=0.7)\n",
    "plt.xlabel('Absolute SHAP Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Absolute SHAP Values for All Samples')\n",
    "plt.xlim(0, 0.005)  # Set the x-axis range\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18481386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of the lowest 10 percent of SHAP values: -0.0030373025362549944\n",
      "Range of the highest 10 percent of SHAP values: 0.003047686154820966\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Combine all SHAP values from all samples into a single list\n",
    "all_shap_values = np.concatenate([value['shap_values'][0] for value in filtered_dict.values()])\n",
    "\n",
    "# Find the 10th and 90th percentiles\n",
    "lower_10_percentile = np.percentile(all_shap_values, 0.1)\n",
    "upper_10_percentile = np.percentile(all_shap_values, 99.9)\n",
    "\n",
    "# Print the range of the lowest 10 percent and the highest 10 percent of SHAP values\n",
    "print(\"Range of the lowest 10 percent of SHAP values:\", lower_10_percentile)\n",
    "print(\"Range of the highest 10 percent of SHAP values:\", upper_10_percentile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abb18948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 lowest SHAP values for sample 6:\n",
      "[-0.00629777 -0.00550874 -0.00482554 -0.00423678 -0.00383174 -0.00368543\n",
      " -0.0036339  -0.00361806 -0.00320204 -0.00305402 -0.00291594 -0.00280933\n",
      " -0.00275368 -0.00271549 -0.00264671 -0.00255994 -0.00205685 -0.00196276\n",
      " -0.00187754 -0.00184494 -0.00175042 -0.00173357 -0.00166808 -0.00166409\n",
      " -0.00163309 -0.00151453 -0.00137118 -0.00129624 -0.00127996 -0.00126629\n",
      " -0.00124239 -0.00123951 -0.00116294 -0.00111722 -0.00110871 -0.00107896\n",
      " -0.0010759  -0.001073   -0.00106946 -0.00105963 -0.00105884 -0.00101172\n",
      " -0.00100315 -0.00099947 -0.0009652  -0.00094283 -0.00093345 -0.00089788\n",
      " -0.00088082 -0.00087028]\n",
      "50 largest SHAP values for sample 6:\n",
      "[0.00203028 0.002059   0.00207291 0.00208599 0.00209355 0.00209489\n",
      " 0.00211424 0.00211634 0.00211656 0.0021228  0.00214412 0.00220623\n",
      " 0.00222569 0.00222836 0.00222889 0.00224822 0.00226905 0.00243424\n",
      " 0.00251584 0.00251595 0.00261329 0.00271375 0.00277562 0.00279562\n",
      " 0.0028764  0.00287879 0.00292001 0.00297565 0.00301145 0.00307943\n",
      " 0.00341956 0.00370977 0.00378244 0.00382266 0.00383903 0.00390497\n",
      " 0.00421725 0.00423012 0.0043639  0.00437352 0.00438945 0.00448499\n",
      " 0.00489508 0.00504761 0.00522954 0.00532842 0.00539465 0.00544803\n",
      " 0.00614804 0.0088259 ]\n"
     ]
    }
   ],
   "source": [
    "# Get the SHAP values for sample 6\n",
    "sample_6_shap_values = filtered_dict[16]['shap_values'][0]\n",
    "\n",
    "# Sort the SHAP values in ascending order\n",
    "sorted_shap_values = np.sort(sample_6_shap_values)\n",
    "\n",
    "# Print the 50 lowest SHAP values\n",
    "print(\"50 lowest SHAP values for sample 6:\")\n",
    "print(sorted_shap_values[:50])\n",
    "\n",
    "# Print the 50 largest SHAP values\n",
    "print(\"50 largest SHAP values for sample 6:\")\n",
    "print(sorted_shap_values[-50:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3380223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512788c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7ddabb",
   "metadata": {},
   "source": [
    "# Obtaining gene names based on SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section has too many useless blocks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32fd6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dictionary from the pickle file\n",
    "with open('shap_values_10_orginal_13k.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21d3e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the filtered dictionary: 280\n"
     ]
    }
   ],
   "source": [
    "# This contains samples with higher than average predcition score among correctly-classified AD samples\n",
    "\n",
    "# Calculate the average predictive score among AD correctly classified samples\n",
    "average_score_ad_correct = np.mean([value['predictive_score'] for value in shap_values_per_sample.values() if value['label'] == 1 and value['correct']])\n",
    "\n",
    "# Filter the dictionary to include only the samples that are AD (1), correctly classified, and have a predictive score higher than the average among AD correctly classified samples\n",
    "filtered_dict = {key: value for key, value in shap_values_per_sample.items()\n",
    "                 if value['label'] == 1 and value['correct'] and value['predictive_score'] > average_score_ad_correct}\n",
    "\n",
    "print(f\"Number of samples in the filtered dictionary: {len(filtered_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "202da184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 8.66319100e-05, 4.25409257e-05, 0.00000000e+00,\n",
       "       2.38775941e-04, 0.00000000e+00, 2.19506053e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.16104989e-05, 0.00000000e+00, 6.58546601e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.57391546e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dict[670]['shap_values'][0][:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77423916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the positive SHAP indices dictionary: 280\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the indices of positive SHAP values for each sample\n",
    "positive_shap_indices = {}\n",
    "\n",
    "# Iterate over the filtered dictionary\n",
    "for sample, data in filtered_dict.items():\n",
    "    # Get the indices of positive SHAP values\n",
    "    indices = [index for index, value in enumerate(data['shap_values'][0]) if value > 0]\n",
    "    # Store the indices in the dictionary\n",
    "    positive_shap_indices[sample] = indices\n",
    "\n",
    "print(f\"Number of samples in the positive SHAP indices dictionary: {len(positive_shap_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61f218a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 11,\n",
       " 15,\n",
       " 30,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 37,\n",
       " 38,\n",
       " 41,\n",
       " 42,\n",
       " 48,\n",
       " 51,\n",
       " 55,\n",
       " 56,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 73,\n",
       " 84,\n",
       " 86,\n",
       " 89,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 101,\n",
       " 102,\n",
       " 104,\n",
       " 116,\n",
       " 118,\n",
       " 121,\n",
       " 123,\n",
       " 124,\n",
       " 127,\n",
       " 129,\n",
       " 130,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 141,\n",
       " 144,\n",
       " 147,\n",
       " 152,\n",
       " 153,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 165,\n",
       " 167,\n",
       " 174,\n",
       " 175,\n",
       " 189,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 199,\n",
       " 201,\n",
       " 206,\n",
       " 209,\n",
       " 220,\n",
       " 230,\n",
       " 234,\n",
       " 235,\n",
       " 238,\n",
       " 243,\n",
       " 246,\n",
       " 247,\n",
       " 250,\n",
       " 255,\n",
       " 260,\n",
       " 264,\n",
       " 266,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 273,\n",
       " 276,\n",
       " 277,\n",
       " 279,\n",
       " 287,\n",
       " 290,\n",
       " 299,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 307,\n",
       " 322,\n",
       " 326,\n",
       " 328,\n",
       " 334,\n",
       " 337,\n",
       " 343,\n",
       " 345,\n",
       " 347,\n",
       " 349,\n",
       " 355,\n",
       " 359,\n",
       " 362,\n",
       " 363,\n",
       " 366,\n",
       " 369,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 390,\n",
       " 401,\n",
       " 405,\n",
       " 406,\n",
       " 412,\n",
       " 416,\n",
       " 421,\n",
       " 438,\n",
       " 450,\n",
       " 452,\n",
       " 455,\n",
       " 458,\n",
       " 464,\n",
       " 466,\n",
       " 470,\n",
       " 474,\n",
       " 477,\n",
       " 482,\n",
       " 483,\n",
       " 487,\n",
       " 491,\n",
       " 496,\n",
       " 508,\n",
       " 510,\n",
       " 515,\n",
       " 517,\n",
       " 519,\n",
       " 525,\n",
       " 526,\n",
       " 528,\n",
       " 531,\n",
       " 534,\n",
       " 541,\n",
       " 545,\n",
       " 550,\n",
       " 557,\n",
       " 560,\n",
       " 562,\n",
       " 563,\n",
       " 567,\n",
       " 581,\n",
       " 583,\n",
       " 594,\n",
       " 601,\n",
       " 603,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 609,\n",
       " 610,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 617,\n",
       " 620,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 635,\n",
       " 646,\n",
       " 647,\n",
       " 649,\n",
       " 653,\n",
       " 658,\n",
       " 660,\n",
       " 662,\n",
       " 669,\n",
       " 670,\n",
       " 672,\n",
       " 676,\n",
       " 682,\n",
       " 684,\n",
       " 695,\n",
       " 696,\n",
       " 703,\n",
       " 707,\n",
       " 709,\n",
       " 714,\n",
       " 719,\n",
       " 721,\n",
       " 731,\n",
       " 734,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 758,\n",
       " 760,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 780,\n",
       " 784,\n",
       " 787,\n",
       " 797,\n",
       " 798,\n",
       " 800,\n",
       " 806,\n",
       " 808,\n",
       " 819,\n",
       " 825,\n",
       " 827,\n",
       " 828,\n",
       " 831,\n",
       " 837,\n",
       " 844,\n",
       " 848,\n",
       " 849,\n",
       " 851,\n",
       " 862,\n",
       " 865,\n",
       " 866,\n",
       " 883,\n",
       " 895,\n",
       " 900,\n",
       " 905,\n",
       " 906,\n",
       " 909,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 925,\n",
       " 926,\n",
       " 928,\n",
       " 929,\n",
       " 935,\n",
       " 937,\n",
       " 939,\n",
       " 941,\n",
       " 942,\n",
       " 944,\n",
       " 945,\n",
       " 947,\n",
       " 952,\n",
       " 957,\n",
       " 966,\n",
       " 974,\n",
       " 981,\n",
       " 986,\n",
       " 988,\n",
       " 990,\n",
       " 995,\n",
       " 996,\n",
       " 999,\n",
       " 1000,\n",
       " 1003,\n",
       " 1007,\n",
       " 1014,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1026,\n",
       " 1030,\n",
       " 1046,\n",
       " 1053,\n",
       " 1054,\n",
       " 1064,\n",
       " 1066,\n",
       " 1067,\n",
       " 1068,\n",
       " 1076,\n",
       " 1081,\n",
       " 1083,\n",
       " 1084,\n",
       " 1086,\n",
       " 1089,\n",
       " 1094,\n",
       " 1095,\n",
       " 1100,\n",
       " 1101,\n",
       " 1102,\n",
       " 1104,\n",
       " 1110,\n",
       " 1111,\n",
       " 1117,\n",
       " 1118,\n",
       " 1121,\n",
       " 1126,\n",
       " 1129,\n",
       " 1132,\n",
       " 1142,\n",
       " 1143,\n",
       " 1148,\n",
       " 1153,\n",
       " 1167,\n",
       " 1178,\n",
       " 1184,\n",
       " 1188,\n",
       " 1190,\n",
       " 1204,\n",
       " 1209,\n",
       " 1212,\n",
       " 1214,\n",
       " 1215,\n",
       " 1220,\n",
       " 1223,\n",
       " 1224,\n",
       " 1228,\n",
       " 1232,\n",
       " 1240,\n",
       " 1243,\n",
       " 1244,\n",
       " 1246,\n",
       " 1249,\n",
       " 1255,\n",
       " 1264,\n",
       " 1269,\n",
       " 1272,\n",
       " 1275,\n",
       " 1279,\n",
       " 1284,\n",
       " 1285,\n",
       " 1286,\n",
       " 1293,\n",
       " 1300,\n",
       " 1310,\n",
       " 1320,\n",
       " 1323,\n",
       " 1324,\n",
       " 1329,\n",
       " 1330,\n",
       " 1334,\n",
       " 1338,\n",
       " 1343,\n",
       " 1349,\n",
       " 1353,\n",
       " 1357,\n",
       " 1372,\n",
       " 1375,\n",
       " 1377,\n",
       " 1380,\n",
       " 1385,\n",
       " 1386,\n",
       " 1391,\n",
       " 1392,\n",
       " 1393,\n",
       " 1397,\n",
       " 1402,\n",
       " 1408,\n",
       " 1414,\n",
       " 1422,\n",
       " 1423,\n",
       " 1438,\n",
       " 1442,\n",
       " 1451,\n",
       " 1462,\n",
       " 1463,\n",
       " 1476,\n",
       " 1478,\n",
       " 1479,\n",
       " 1483,\n",
       " 1485,\n",
       " 1488,\n",
       " 1496,\n",
       " 1502,\n",
       " 1505,\n",
       " 1506,\n",
       " 1523,\n",
       " 1526,\n",
       " 1531,\n",
       " 1534,\n",
       " 1538,\n",
       " 1552,\n",
       " 1556,\n",
       " 1557,\n",
       " 1560,\n",
       " 1562,\n",
       " 1572,\n",
       " 1574,\n",
       " 1575,\n",
       " 1581,\n",
       " 1591,\n",
       " 1593,\n",
       " 1594,\n",
       " 1597,\n",
       " 1603,\n",
       " 1610,\n",
       " 1613,\n",
       " 1615,\n",
       " 1619,\n",
       " 1620,\n",
       " 1624,\n",
       " 1628,\n",
       " 1630,\n",
       " 1631,\n",
       " 1641,\n",
       " 1647,\n",
       " 1648,\n",
       " 1655,\n",
       " 1656,\n",
       " 1661,\n",
       " 1662,\n",
       " 1673,\n",
       " 1674,\n",
       " 1680,\n",
       " 1693,\n",
       " 1695,\n",
       " 1699,\n",
       " 1700,\n",
       " 1701,\n",
       " 1708,\n",
       " 1710,\n",
       " 1717,\n",
       " 1721,\n",
       " 1722,\n",
       " 1730,\n",
       " 1739,\n",
       " 1740,\n",
       " 1741,\n",
       " 1744,\n",
       " 1747,\n",
       " 1755,\n",
       " 1756,\n",
       " 1757,\n",
       " 1761,\n",
       " 1763,\n",
       " 1765,\n",
       " 1768,\n",
       " 1775,\n",
       " 1778,\n",
       " 1784,\n",
       " 1786,\n",
       " 1787,\n",
       " 1791,\n",
       " 1794,\n",
       " 1801,\n",
       " 1805,\n",
       " 1807,\n",
       " 1808,\n",
       " 1810,\n",
       " 1813,\n",
       " 1817,\n",
       " 1820,\n",
       " 1824,\n",
       " 1833,\n",
       " 1836,\n",
       " 1841,\n",
       " 1848,\n",
       " 1855,\n",
       " 1857,\n",
       " 1863,\n",
       " 1866,\n",
       " 1867,\n",
       " 1868,\n",
       " 1873,\n",
       " 1875,\n",
       " 1876,\n",
       " 1885,\n",
       " 1890,\n",
       " 1899,\n",
       " 1903,\n",
       " 1907,\n",
       " 1909,\n",
       " 1911,\n",
       " 1919,\n",
       " 1920,\n",
       " 1921,\n",
       " 1923,\n",
       " 1925,\n",
       " 1926,\n",
       " 1927,\n",
       " 1929,\n",
       " 1935,\n",
       " 1938,\n",
       " 1940,\n",
       " 1941,\n",
       " 1942,\n",
       " 1947,\n",
       " 1950,\n",
       " 1952,\n",
       " 1960,\n",
       " 1969,\n",
       " 1970,\n",
       " 1977,\n",
       " 1978,\n",
       " 1980,\n",
       " 1981,\n",
       " 1982,\n",
       " 1989,\n",
       " 1990,\n",
       " 2003,\n",
       " 2006,\n",
       " 2007,\n",
       " 2011,\n",
       " 2015,\n",
       " 2022,\n",
       " 2023,\n",
       " 2033,\n",
       " 2041,\n",
       " 2046,\n",
       " 2047,\n",
       " 2052,\n",
       " 2063,\n",
       " 2064,\n",
       " 2067,\n",
       " 2069,\n",
       " 2080,\n",
       " 2081,\n",
       " 2082,\n",
       " 2083,\n",
       " 2090,\n",
       " 2094,\n",
       " 2097,\n",
       " 2100,\n",
       " 2102,\n",
       " 2110,\n",
       " 2111,\n",
       " 2115,\n",
       " 2122,\n",
       " 2124,\n",
       " 2125,\n",
       " 2126,\n",
       " 2127,\n",
       " 2128,\n",
       " 2132,\n",
       " 2138,\n",
       " 2143,\n",
       " 2147,\n",
       " 2152,\n",
       " 2153,\n",
       " 2154,\n",
       " 2155,\n",
       " 2158,\n",
       " 2180,\n",
       " 2181,\n",
       " 2182,\n",
       " 2187,\n",
       " 2195,\n",
       " 2196,\n",
       " 2197,\n",
       " 2210,\n",
       " 2212,\n",
       " 2214,\n",
       " 2215,\n",
       " 2218,\n",
       " 2225,\n",
       " 2228,\n",
       " 2230,\n",
       " 2231,\n",
       " 2237,\n",
       " 2240,\n",
       " 2241,\n",
       " 2248,\n",
       " 2256,\n",
       " 2266,\n",
       " 2267,\n",
       " 2276,\n",
       " 2277,\n",
       " 2278,\n",
       " 2283,\n",
       " 2287,\n",
       " 2290,\n",
       " 2293,\n",
       " 2294,\n",
       " 2296,\n",
       " 2302,\n",
       " 2303,\n",
       " 2309,\n",
       " 2310,\n",
       " 2313,\n",
       " 2316,\n",
       " 2318,\n",
       " 2319,\n",
       " 2320,\n",
       " 2321,\n",
       " 2327,\n",
       " 2340,\n",
       " 2341,\n",
       " 2350,\n",
       " 2351,\n",
       " 2354,\n",
       " 2366,\n",
       " 2367,\n",
       " 2370,\n",
       " 2374,\n",
       " 2375,\n",
       " 2378,\n",
       " 2380,\n",
       " 2383,\n",
       " 2388,\n",
       " 2394,\n",
       " 2400,\n",
       " 2401,\n",
       " 2404,\n",
       " 2406,\n",
       " 2411,\n",
       " 2428,\n",
       " 2430,\n",
       " 2432,\n",
       " 2435,\n",
       " 2444,\n",
       " 2450,\n",
       " 2452,\n",
       " 2464,\n",
       " 2466,\n",
       " 2469,\n",
       " 2474,\n",
       " 2475,\n",
       " 2481,\n",
       " 2482,\n",
       " 2486,\n",
       " 2488,\n",
       " 2493,\n",
       " 2497,\n",
       " 2498,\n",
       " 2513,\n",
       " 2514,\n",
       " 2517,\n",
       " 2519,\n",
       " 2523,\n",
       " 2525,\n",
       " 2526,\n",
       " 2528,\n",
       " 2530,\n",
       " 2532,\n",
       " 2539,\n",
       " 2540,\n",
       " 2546,\n",
       " 2547,\n",
       " 2548,\n",
       " 2553,\n",
       " 2556,\n",
       " 2557,\n",
       " 2561,\n",
       " 2570,\n",
       " 2574,\n",
       " 2587,\n",
       " 2588,\n",
       " 2592,\n",
       " 2595,\n",
       " 2598,\n",
       " 2601,\n",
       " 2604,\n",
       " 2609,\n",
       " 2610,\n",
       " 2611,\n",
       " 2614,\n",
       " 2620,\n",
       " 2629,\n",
       " 2630,\n",
       " 2636,\n",
       " 2641,\n",
       " 2643,\n",
       " 2651,\n",
       " 2660,\n",
       " 2665,\n",
       " 2668,\n",
       " 2669,\n",
       " 2673,\n",
       " 2677,\n",
       " 2685,\n",
       " 2686,\n",
       " 2688,\n",
       " 2691,\n",
       " 2693,\n",
       " 2695,\n",
       " 2700,\n",
       " 2705,\n",
       " 2711,\n",
       " 2713,\n",
       " 2715,\n",
       " 2719,\n",
       " 2720,\n",
       " 2726,\n",
       " 2728,\n",
       " 2730,\n",
       " 2731,\n",
       " 2736,\n",
       " 2740,\n",
       " 2748,\n",
       " 2753,\n",
       " 2755,\n",
       " 2760,\n",
       " 2765,\n",
       " 2769,\n",
       " 2773,\n",
       " 2777,\n",
       " 2781,\n",
       " 2792,\n",
       " 2794,\n",
       " 2795,\n",
       " 2796,\n",
       " 2798,\n",
       " 2802,\n",
       " 2804,\n",
       " 2815,\n",
       " 2818,\n",
       " 2822,\n",
       " 2824,\n",
       " 2827,\n",
       " 2833,\n",
       " 2840,\n",
       " 2846,\n",
       " 2850,\n",
       " 2853,\n",
       " 2854,\n",
       " 2856,\n",
       " 2862,\n",
       " 2863,\n",
       " 2867,\n",
       " 2868,\n",
       " 2871,\n",
       " 2872,\n",
       " 2874,\n",
       " 2876,\n",
       " 2878,\n",
       " 2880,\n",
       " 2881,\n",
       " 2886,\n",
       " 2887,\n",
       " 2900,\n",
       " 2914,\n",
       " 2917,\n",
       " 2920,\n",
       " 2921,\n",
       " 2922,\n",
       " 2924,\n",
       " 2929,\n",
       " 2932,\n",
       " 2933,\n",
       " 2941,\n",
       " 2957,\n",
       " 2960,\n",
       " 2964,\n",
       " 2965,\n",
       " 2969,\n",
       " 2974,\n",
       " 2976,\n",
       " 2978,\n",
       " 2981,\n",
       " 2998,\n",
       " 3000,\n",
       " 3002,\n",
       " 3006,\n",
       " 3007,\n",
       " 3017,\n",
       " 3019,\n",
       " 3026,\n",
       " 3027,\n",
       " 3031,\n",
       " 3035,\n",
       " 3036,\n",
       " 3037,\n",
       " 3040,\n",
       " 3043,\n",
       " 3047,\n",
       " 3050,\n",
       " 3051,\n",
       " 3061,\n",
       " 3066,\n",
       " 3072,\n",
       " 3073,\n",
       " 3079,\n",
       " 3082,\n",
       " 3084,\n",
       " 3085,\n",
       " 3087,\n",
       " 3088,\n",
       " 3089,\n",
       " 3113,\n",
       " 3122,\n",
       " 3126,\n",
       " 3136,\n",
       " 3141,\n",
       " 3148,\n",
       " 3149,\n",
       " 3150,\n",
       " 3155,\n",
       " 3159,\n",
       " 3160,\n",
       " 3164,\n",
       " 3166,\n",
       " 3168,\n",
       " 3171,\n",
       " 3176,\n",
       " 3185,\n",
       " 3190,\n",
       " 3199,\n",
       " 3206,\n",
       " 3208,\n",
       " 3214,\n",
       " 3215,\n",
       " 3218,\n",
       " 3222,\n",
       " 3224,\n",
       " 3229,\n",
       " 3240,\n",
       " 3242,\n",
       " 3246,\n",
       " 3248,\n",
       " 3249,\n",
       " 3251,\n",
       " 3253,\n",
       " 3259,\n",
       " 3262,\n",
       " 3263,\n",
       " 3264,\n",
       " 3267,\n",
       " 3268,\n",
       " 3270,\n",
       " 3277,\n",
       " 3281,\n",
       " 3285,\n",
       " 3286,\n",
       " 3297,\n",
       " 3298,\n",
       " 3300,\n",
       " 3301,\n",
       " 3302,\n",
       " 3308,\n",
       " 3313,\n",
       " 3314,\n",
       " 3319,\n",
       " 3321,\n",
       " 3323,\n",
       " 3328,\n",
       " 3330,\n",
       " 3338,\n",
       " 3343,\n",
       " 3354,\n",
       " 3355,\n",
       " 3356,\n",
       " 3363,\n",
       " 3372,\n",
       " 3373,\n",
       " 3379,\n",
       " 3387,\n",
       " 3389,\n",
       " 3394,\n",
       " 3403,\n",
       " 3411,\n",
       " 3425,\n",
       " 3426,\n",
       " 3429,\n",
       " 3432,\n",
       " 3434,\n",
       " 3436,\n",
       " 3438,\n",
       " 3445,\n",
       " 3446,\n",
       " 3451,\n",
       " 3454,\n",
       " 3455,\n",
       " 3462,\n",
       " 3466,\n",
       " 3468,\n",
       " 3469,\n",
       " 3473,\n",
       " 3476,\n",
       " 3480,\n",
       " 3481,\n",
       " 3482,\n",
       " 3486,\n",
       " 3487,\n",
       " 3489,\n",
       " 3490,\n",
       " 3492,\n",
       " 3493,\n",
       " 3494,\n",
       " 3505,\n",
       " 3516,\n",
       " 3518,\n",
       " 3519,\n",
       " 3524,\n",
       " 3526,\n",
       " 3527,\n",
       " 3539,\n",
       " 3541,\n",
       " 3545,\n",
       " 3549,\n",
       " 3550,\n",
       " 3552,\n",
       " 3559,\n",
       " 3570,\n",
       " 3571,\n",
       " 3572,\n",
       " 3576,\n",
       " 3585,\n",
       " 3592,\n",
       " 3593,\n",
       " 3595,\n",
       " 3598,\n",
       " 3612,\n",
       " 3628,\n",
       " 3631,\n",
       " 3635,\n",
       " 3643,\n",
       " 3644,\n",
       " 3646,\n",
       " 3650,\n",
       " 3653,\n",
       " 3654,\n",
       " 3655,\n",
       " 3658,\n",
       " 3665,\n",
       " 3671,\n",
       " 3673,\n",
       " 3677,\n",
       " 3678,\n",
       " 3684,\n",
       " 3686,\n",
       " 3693,\n",
       " 3698,\n",
       " 3700,\n",
       " 3701,\n",
       " 3707,\n",
       " 3715,\n",
       " 3728,\n",
       " 3733,\n",
       " 3734,\n",
       " 3737,\n",
       " 3743,\n",
       " 3750,\n",
       " 3758,\n",
       " 3761,\n",
       " 3765,\n",
       " 3772,\n",
       " 3775,\n",
       " 3789,\n",
       " 3796,\n",
       " 3806,\n",
       " 3809,\n",
       " 3811,\n",
       " 3814,\n",
       " 3817,\n",
       " 3818,\n",
       " 3819,\n",
       " 3828,\n",
       " 3831,\n",
       " 3833,\n",
       " 3834,\n",
       " 3838,\n",
       " 3841,\n",
       " 3843,\n",
       " 3856,\n",
       " 3857,\n",
       " 3864,\n",
       " 3867,\n",
       " 3874,\n",
       " 3879,\n",
       " 3884,\n",
       " 3895,\n",
       " 3898,\n",
       " 3899,\n",
       " 3905,\n",
       " 3907,\n",
       " 3908,\n",
       " 3910,\n",
       " 3913,\n",
       " 3914,\n",
       " 3919,\n",
       " 3920,\n",
       " 3924,\n",
       " 3927,\n",
       " 3938,\n",
       " 3940,\n",
       " 3942,\n",
       " 3945,\n",
       " 3948,\n",
       " 3950,\n",
       " 3956,\n",
       " 3958,\n",
       " 3961,\n",
       " 3968,\n",
       " 3969,\n",
       " 3970,\n",
       " 3973,\n",
       " 3979,\n",
       " 3992,\n",
       " 3996,\n",
       " 3997,\n",
       " 4008,\n",
       " 4009,\n",
       " 4010,\n",
       " 4014,\n",
       " 4017,\n",
       " 4018,\n",
       " 4020,\n",
       " 4037,\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_shap_indices[670]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2742767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_shap_indices[670]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one list of positive shaps\n",
    "# Merge all indices and remove duplicates -- \n",
    "merged_indices = set()\n",
    "for indices in positive_shap_indices.values():\n",
    "    merged_indices.update(indices)\n",
    "\n",
    "# Convert the set to a list\n",
    "merged_indices_list = list(merged_indices)\n",
    "\n",
    "print(\"Merged and unique indices:\", merged_indices_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1d5b8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12999\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f2491ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices common to all samples: []\n"
     ]
    }
   ],
   "source": [
    "# Find the intersection of all sets of indices\n",
    "common_indices = set.intersection(*[set(indices) for indices in positive_shap_indices.values()])\n",
    "\n",
    "# Convert the set to a list\n",
    "common_indices_list = list(common_indices)\n",
    "\n",
    "print(\"Indices common to all samples:\", common_indices_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50a27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"ROSMAP_counts_v7.csv\", index_col=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "443f13de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000000003', 'ENSG00000000457', 'ENSG00000000460',\n",
       "       'ENSG00000000938', 'ENSG00000000971', 'ENSG00000001036',\n",
       "       'ENSG00000001084', 'ENSG00000001460', 'ENSG00000001497',\n",
       "       'ENSG00000001617', 'ENSG00000001626', 'ENSG00000001629',\n",
       "       'ENSG00000001630', 'ENSG00000002016', 'ENSG00000002330',\n",
       "       'ENSG00000002549', 'ENSG00000002587', 'ENSG00000002745',\n",
       "       'ENSG00000002746'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "058203f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of gene names from the column headers of the dataset\n",
    "gene_names = list(X.columns)\n",
    "\n",
    "# Map the indices to gene names and add them to the dictionary\n",
    "for sample, indices in positive_shap_indices.items():\n",
    "    genes = [gene_names[index] for index in indices]\n",
    "    positive_shap_indices[sample] = {'indices': indices, 'gene_names': genes}\n",
    "\n",
    "# print(positive_shap_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_shap_indices[670]['indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef755419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the gene names for sample 5, each on a new line\n",
    "for gene_name in positive_shap_indices[670]['gene_names']:\n",
    "    print(gene_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05fc929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6f556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f1f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecdd61e8",
   "metadata": {},
   "source": [
    "# New RF model and shap values (modified 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244149da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On original imbalanced dataset (did not make a difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59705aab",
   "metadata": {},
   "source": [
    "## RF code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "def process_fold(train_ix, test_ix, X, y):\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=6,\n",
    "        random_state=1,\n",
    "        class_weight='balanced')  # Adjusting for class imbalance\n",
    "    fit = model.fit(X_train, y_train.ravel())\n",
    "    y_pred = fit.predict(X_test)\n",
    "    y_proba = fit.predict_proba(X_test)[0]\n",
    "    correct = y_pred[0] == y_test.iloc[0]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Collecting the SHAP values for the predicted class\n",
    "    relevant_shap_values = shap_values[1] if y_pred[0] == 1 else shap_values[0]\n",
    "\n",
    "    print(f'Fold number {test_ix[0]} completed')  # Print the completed fold number\n",
    "    return {\n",
    "        'fold_num': test_ix[0],\n",
    "        'correct': correct,\n",
    "        'label': y_test.iloc[0],\n",
    "        'shap_values': {X.columns[i]: relevant_shap_values[0][i] for i in range(len(X.columns))},  # SHAP values for each feature\n",
    "        'predictive_score': y_proba[1] if y_pred[0] == 1 else y_proba[0],  # Predictive score for the test sample\n",
    "        'predicted_label': y_pred[0]\n",
    "    }\n",
    "\n",
    "dataset_path = 'ROSMAP_counts_v8_original_13k.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('./metadata_v3.csv', index_col=0)\n",
    "df_metadata = metadata[(metadata['study'] == 'ROSMAP')]\n",
    "y = df_metadata['diagnosis']\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "loo = LeaveOneOut()\n",
    "results = Parallel(n_jobs=6)(delayed(process_fold)(train_ix, test_ix, X, y) for train_ix, test_ix in loo.split(X))\n",
    "\n",
    "# Calculate overall model performance\n",
    "y_true = [result['label'] for result in results]\n",
    "y_pred = [result['predicted_label'] for result in results]\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Overall model accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['Control', 'AD'])\n",
    "print(report)\n",
    "\n",
    "# Save SHAP values dictionary\n",
    "shap_values_per_sample = {result['fold_num']: result for result in results}\n",
    "with open('shap_values_11_orginal_13k.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values_per_sample, f)\n",
    "print('SHAP values dictionary saved to shap_values_10_orginal_13k.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c12f69",
   "metadata": {},
   "source": [
    "## Filtering dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58429c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('shap_values_18_13k_clinical.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932fee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bbe01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in the dictionary: 1230\n",
      "Number of unique specimen IDs: 1230\n",
      "All specimen IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Extract all specimen IDs from the original dictionary\n",
    "specimen_ids = [result['specimen_id'] for result in shap_values_per_sample.values()]\n",
    "\n",
    "# Count the number of unique specimen IDs\n",
    "unique_specimen_ids = set(specimen_ids)\n",
    "num_unique_specimen_ids = len(unique_specimen_ids)\n",
    "\n",
    "# Compare the number of unique specimen IDs to the total number of entries\n",
    "total_entries = len(shap_values_per_sample)\n",
    "print(f'Total number of entries in the dictionary: {total_entries}')\n",
    "print(f'Number of unique specimen IDs: {num_unique_specimen_ids}')\n",
    "\n",
    "if num_unique_specimen_ids == total_entries:\n",
    "    print(\"All specimen IDs are unique.\")\n",
    "else:\n",
    "    print(\"There are duplicate specimen IDs in the dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a892a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly classified AD patients: 527\n"
     ]
    }
   ],
   "source": [
    "# Load the SHAP values dictionary from the file\n",
    "with open('shap_values_18_13k_clinical.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)\n",
    "\n",
    "# Count the number of correctly classified AD patients\n",
    "correctly_classified_ad_patients = sum(\n",
    "    1 for result in shap_values_per_sample.values() if result['correct'] and result['label'] == 1\n",
    ")\n",
    "\n",
    "print(f'Number of correctly classified AD patients: {correctly_classified_ad_patients}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0dbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248c30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered results: 307\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aade058a",
   "metadata": {},
   "source": [
    "### Filtering the dict to send to collaborator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file contains a dictionary where each key is a patient ID (specimen_ID obtained from the metadata file), and the corresponding value is a nested dictionary containing gene Ensembl IDs and their respective SHAP values\n",
    "# Only genes with a positive SHAP value are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d372a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the SHAP values dictionary from the file\n",
    "with open('shap_values_18_13k_clinical.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c49725",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The filtering code for outcome pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ded5821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered SHAP values dictionary saved to ad_patient_genes_shap_values.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the SHAP values dictionary from the file\n",
    "with open('shap_values_18_13k_clinical.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)\n",
    "\n",
    "# Filter results to include only correctly classified AD patients and add predictive score for each patient\n",
    "filtered_results = {\n",
    "    result['specimen_id']: {\n",
    "        'shap_values': {gene: shap_value for gene, shap_value in result['shap_values'].items() if shap_value > 0},\n",
    "        'predictive_score': result['predictive_score']  # Include the predictive score for each patient\n",
    "    }\n",
    "    for result in shap_values_per_sample.values()\n",
    "    if result['correct'] and result['label'] == 1\n",
    "}\n",
    "\n",
    "# Save the filtered results to a new file\n",
    "with open('ad_patient_genes_shap_values.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_results, f)\n",
    "print('Filtered SHAP values dictionary saved to ad_patient_genes_shap_values.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4fe7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ad_patient_genes_shap_values.pkl', 'rb') as f:\n",
    "    shap_values_per_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a97df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4314ba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of keys in the dictionary: 527\n"
     ]
    }
   ],
   "source": [
    "total_keys = len(shap_values_per_sample.keys())\n",
    "\n",
    "print(f'Total number of keys in the dictionary: {total_keys}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81770173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc35c29a",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb47a2",
   "metadata": {},
   "source": [
    "### total shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1505b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "187",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming filtered_results is the dictionary containing the filtered SHAP values\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m sample_shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m187\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshap_values\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extracting SHAP values for plotting\u001b[39;00m\n\u001b[1;32m      7\u001b[0m shap_values_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(sample_shap_values\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[0;31mKeyError\u001b[0m: 187"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming filtered_results is the dictionary containing the filtered SHAP values\n",
    "sample_shap_values = filtered_results[187]['shap_values']\n",
    "\n",
    "# Extracting SHAP values for plotting\n",
    "shap_values_list = list(sample_shap_values.values())\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(shap_values_list, bins=90, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of SHAP Values for Sample 72')\n",
    "plt.xlabel('SHAP Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72428ddd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d765c088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238636ee",
   "metadata": {},
   "source": [
    "## Highest shap values (genes) for a sample (gene names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f523c3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSG00000134294\n",
      "ENSG00000088836\n",
      "ENSG00000157833\n",
      "ENSG00000108932\n",
      "ENSG00000145832\n",
      "ENSG00000125534\n",
      "ENSG00000166535\n",
      "ENSG00000101040\n",
      "ENSG00000198417\n",
      "ENSG00000228016\n",
      "ENSG00000197102\n",
      "ENSG00000172922\n",
      "ENSG00000171174\n",
      "ENSG00000139410\n",
      "ENSG00000158186\n",
      "ENSG00000198342\n",
      "ENSG00000171388\n",
      "ENSG00000158169\n",
      "ENSG00000111087\n",
      "ENSG00000056736\n",
      "ENSG00000115758\n",
      "ENSG00000196739\n",
      "ENSG00000243927\n",
      "ENSG00000261195\n",
      "ENSG00000128228\n",
      "ENSG00000184481\n",
      "ENSG00000125772\n",
      "ENSG00000203952\n",
      "ENSG00000136521\n",
      "ENSG00000125144\n",
      "ENSG00000179029\n",
      "ENSG00000125733\n",
      "ENSG00000154188\n",
      "ENSG00000135318\n",
      "ENSG00000187595\n",
      "ENSG00000184677\n",
      "ENSG00000102409\n",
      "ENSG00000053254\n",
      "ENSG00000062822\n",
      "ENSG00000248593\n",
      "ENSG00000168081\n",
      "ENSG00000164188\n",
      "ENSG00000198830\n",
      "ENSG00000144730\n",
      "ENSG00000174428\n",
      "ENSG00000196547\n",
      "ENSG00000070778\n",
      "ENSG00000114126\n",
      "ENSG00000175556\n",
      "ENSG00000204472\n",
      "ENSG00000278266\n",
      "ENSG00000133195\n",
      "ENSG00000165675\n",
      "ENSG00000260293\n",
      "ENSG00000167723\n",
      "age_death\n",
      "ENSG00000170791\n",
      "ENSG00000124253\n",
      "ENSG00000185414\n",
      "ENSG00000091879\n",
      "ENSG00000183688\n",
      "ENSG00000187699\n",
      "ENSG00000182253\n",
      "ENSG00000198624\n",
      "ENSG00000176907\n",
      "ENSG00000236753\n",
      "ENSG00000115267\n",
      "ENSG00000005189\n",
      "ENSG00000148824\n",
      "ENSG00000164978\n",
      "ENSG00000136451\n",
      "ENSG00000143157\n",
      "ENSG00000108784\n",
      "ENSG00000161642\n",
      "ENSG00000083067\n",
      "ENSG00000165175\n",
      "ENSG00000240024\n",
      "ENSG00000184154\n",
      "ENSG00000114115\n",
      "ENSG00000158019\n",
      "ENSG00000137411\n",
      "ENSG00000111961\n",
      "ENSG00000173530\n",
      "ENSG00000103769\n",
      "ENSG00000258655\n",
      "ENSG00000279789\n",
      "ENSG00000138036\n",
      "ENSG00000103160\n",
      "ENSG00000281327\n",
      "ENSG00000159176\n",
      "ENSG00000186298\n",
      "ENSG00000214756\n",
      "ENSG00000126602\n",
      "ENSG00000206159\n",
      "ENSG00000188763\n",
      "ENSG00000164104\n",
      "ENSG00000234028\n",
      "ENSG00000280650\n",
      "ENSG00000228058\n",
      "ENSG00000198429\n",
      "ENSG00000259343\n",
      "ENSG00000178104\n",
      "ENSG00000188916\n",
      "ENSG00000269893\n",
      "ENSG00000147403\n",
      "ENSG00000203930\n",
      "ENSG00000117461\n",
      "ENSG00000186834\n",
      "ENSG00000260788\n",
      "ENSG00000141198\n",
      "ENSG00000170899\n",
      "ENSG00000135447\n",
      "ENSG00000100227\n",
      "ENSG00000119977\n",
      "ENSG00000215301\n",
      "ENSG00000169902\n",
      "ENSG00000115598\n",
      "ENSG00000010310\n",
      "ENSG00000187398\n",
      "ENSG00000110492\n",
      "ENSG00000184983\n",
      "ENSG00000162631\n",
      "ENSG00000285569\n",
      "ENSG00000254561\n",
      "ENSG00000079462\n",
      "ENSG00000172339\n",
      "ENSG00000089169\n",
      "ENSG00000111328\n",
      "ENSG00000271714\n",
      "ENSG00000183878\n",
      "ENSG00000067057\n",
      "ENSG00000198554\n",
      "ENSG00000154620\n",
      "ENSG00000101194\n",
      "ENSG00000189159\n",
      "ENSG00000132702\n",
      "ENSG00000109180\n",
      "ENSG00000105656\n",
      "ENSG00000251442\n",
      "ENSG00000119950\n",
      "ENSG00000185482\n",
      "ENSG00000142765\n",
      "ENSG00000197958\n",
      "ENSG00000237422\n",
      "ENSG00000179912\n",
      "ENSG00000113368\n",
      "ENSG00000099326\n",
      "ENSG00000197054\n",
      "ENSG00000100350\n",
      "ENSG00000205740\n",
      "ENSG00000105643\n",
      "ENSG00000114019\n",
      "ENSG00000100600\n",
      "ENSG00000249673\n",
      "ENSG00000205929\n",
      "ENSG00000267270\n",
      "ENSG00000236397\n",
      "ENSG00000235652\n",
      "ENSG00000255389\n",
      "ENSG00000160991\n",
      "ENSG00000184924\n",
      "ENSG00000247950\n",
      "ENSG00000106688\n",
      "ENSG00000142102\n",
      "ENSG00000145494\n",
      "ENSG00000135144\n",
      "ENSG00000168209\n",
      "ENSG00000077420\n",
      "ENSG00000114023\n",
      "ENSG00000168280\n",
      "ENSG00000251595\n",
      "ENSG00000260855\n",
      "ENSG00000174705\n",
      "ENSG00000224032\n",
      "ENSG00000060718\n",
      "ENSG00000092929\n",
      "ENSG00000125740\n",
      "ENSG00000286327\n",
      "ENSG00000103150\n",
      "ENSG00000111711\n",
      "ENSG00000184009\n",
      "ENSG00000130254\n",
      "ENSG00000125804\n",
      "ENSG00000250486\n",
      "ENSG00000256235\n",
      "ENSG00000125618\n",
      "ENSG00000169992\n",
      "ENSG00000261701\n",
      "ENSG00000120738\n",
      "ENSG00000173801\n",
      "ENSG00000188783\n",
      "ENSG00000278969\n",
      "ENSG00000185049\n",
      "ENSG00000281332\n",
      "ENSG00000163520\n",
      "ENSG00000138434\n",
      "ENSG00000183281\n",
      "ENSG00000177994\n",
      "ENSG00000104112\n",
      "ENSG00000180190\n",
      "ENSG00000197044\n",
      "ENSG00000248489\n",
      "ENSG00000273456\n",
      "ENSG00000086159\n",
      "ENSG00000165084\n",
      "ENSG00000204052\n",
      "ENSG00000112699\n",
      "ENSG00000105251\n",
      "ENSG00000284968\n",
      "ENSG00000251372\n",
      "ENSG00000272305\n",
      "ENSG00000269935\n",
      "ENSG00000243317\n",
      "ENSG00000089157\n",
      "ENSG00000271646\n",
      "ENSG00000101665\n",
      "ENSG00000185875\n",
      "ENSG00000103249\n",
      "ENSG00000157005\n",
      "ENSG00000073417\n",
      "ENSG00000096060\n",
      "ENSG00000145244\n",
      "ENSG00000116786\n",
      "ENSG00000272425\n",
      "ENSG00000100138\n",
      "ENSG00000259363\n",
      "ENSG00000163798\n",
      "ENSG00000100949\n",
      "ENSG00000143155\n",
      "ENSG00000140368\n",
      "ENSG00000287516\n",
      "ENSG00000251867\n",
      "ENSG00000142449\n",
      "ENSG00000272189\n",
      "ENSG00000178209\n",
      "ENSG00000128626\n",
      "ENSG00000245694\n",
      "ENSG00000197322\n",
      "ENSG00000091513\n",
      "ENSG00000173918\n",
      "ENSG00000155792\n",
      "ENSG00000068400\n",
      "ENSG00000233670\n",
      "ENSG00000165895\n",
      "ENSG00000186666\n",
      "ENSG00000128564\n",
      "ENSG00000213918\n",
      "ENSG00000132024\n",
      "ENSG00000260464\n",
      "ENSG00000172992\n",
      "ENSG00000198682\n",
      "ENSG00000279342\n",
      "ENSG00000124243\n",
      "ENSG00000198435\n",
      "ENSG00000213390\n",
      "ENSG00000020577\n",
      "ENSG00000278535\n",
      "ENSG00000188039\n",
      "ENSG00000259408\n",
      "ENSG00000147488\n",
      "ENSG00000125538\n",
      "ENSG00000206573\n",
      "ENSG00000135525\n",
      "ENSG00000198053\n",
      "ENSG00000112039\n",
      "ENSG00000138002\n",
      "ENSG00000162373\n",
      "ENSG00000166783\n",
      "ENSG00000163629\n",
      "ENSG00000172247\n",
      "ENSG00000108018\n",
      "ENSG00000167733\n",
      "ENSG00000176720\n",
      "ENSG00000260257\n",
      "ENSG00000067048\n",
      "ENSG00000198756\n",
      "ENSG00000259826\n",
      "ENSG00000147459\n",
      "ENSG00000141753\n",
      "ENSG00000184602\n",
      "ENSG00000165983\n",
      "ENSG00000138095\n",
      "ENSG00000180488\n",
      "ENSG00000099715\n",
      "ENSG00000260081\n",
      "ENSG00000100228\n",
      "ENSG00000188511\n",
      "ENSG00000152229\n",
      "ENSG00000112837\n",
      "ENSG00000120709\n",
      "ENSG00000124140\n",
      "ENSG00000143590\n",
      "ENSG00000269743\n",
      "ENSG00000182810\n",
      "ENSG00000283078\n",
      "ENSG00000198618\n",
      "ENSG00000171130\n",
      "ENSG00000211445\n",
      "ENSG00000183317\n",
      "ENSG00000247081\n",
      "ENSG00000164776\n",
      "ENSG00000287760\n",
      "ENSG00000169136\n",
      "ENSG00000168404\n",
      "ENSG00000104738\n",
      "ENSG00000266904\n",
      "ENSG00000248671\n",
      "ENSG00000155980\n",
      "ENSG00000161888\n",
      "ENSG00000126803\n",
      "ENSG00000109458\n",
      "ENSG00000042980\n",
      "ENSG00000118997\n",
      "ENSG00000077454\n",
      "ENSG00000149084\n",
      "ENSG00000138138\n",
      "ENSG00000121966\n",
      "ENSG00000167778\n",
      "ENSG00000147571\n",
      "ENSG00000144671\n",
      "ENSG00000134057\n",
      "ENSG00000185043\n",
      "ENSG00000037897\n",
      "ENSG00000135678\n",
      "ENSG00000214456\n",
      "ENSG00000279255\n",
      "ENSG00000163428\n",
      "ENSG00000246263\n",
      "ENSG00000133027\n",
      "ENSG00000167702\n",
      "ENSG00000276449\n",
      "ENSG00000187266\n",
      "ENSG00000081277\n",
      "ENSG00000101654\n",
      "ENSG00000107736\n",
      "ENSG00000112992\n",
      "ENSG00000084453\n",
      "ENSG00000166912\n",
      "ENSG00000164164\n",
      "ENSG00000163964\n",
      "ENSG00000076770\n",
      "ENSG00000156411\n",
      "ENSG00000183549\n",
      "ENSG00000189007\n",
      "ENSG00000205089\n",
      "ENSG00000105229\n",
      "ENSG00000076555\n",
      "ENSG00000129450\n",
      "ENSG00000106351\n",
      "ENSG00000203499\n",
      "ENSG00000203667\n",
      "ENSG00000224905\n",
      "ENSG00000007255\n",
      "ENSG00000160818\n",
      "ENSG00000129028\n",
      "ENSG00000059691\n",
      "ENSG00000169047\n",
      "ENSG00000156265\n",
      "ENSG00000176623\n",
      "ENSG00000141098\n",
      "ENSG00000147234\n",
      "ENSG00000237298\n",
      "ENSG00000121671\n",
      "ENSG00000267868\n",
      "ENSG00000139190\n",
      "ENSG00000257433\n",
      "ENSG00000155660\n",
      "ENSG00000139352\n",
      "ENSG00000152661\n",
      "ENSG00000171873\n",
      "ENSG00000149289\n",
      "ENSG00000136197\n",
      "ENSG00000257337\n",
      "ENSG00000124181\n",
      "ENSG00000204228\n",
      "ENSG00000271538\n",
      "ENSG00000102547\n",
      "ENSG00000245322\n",
      "ENSG00000173068\n",
      "ENSG00000137504\n",
      "ENSG00000112406\n",
      "ENSG00000137843\n",
      "ENSG00000188313\n",
      "ENSG00000215915\n",
      "ENSG00000156218\n",
      "ENSG00000271993\n",
      "ENSG00000261840\n",
      "ENSG00000184730\n",
      "ENSG00000178935\n",
      "ENSG00000111181\n",
      "ENSG00000198478\n",
      "ENSG00000280351\n",
      "ENSG00000237505\n",
      "ENSG00000223865\n",
      "ENSG00000133665\n",
      "ENSG00000265763\n",
      "ENSG00000196104\n",
      "ENSG00000136937\n",
      "ENSG00000075884\n",
      "ENSG00000251429\n",
      "ENSG00000164949\n",
      "ENSG00000102032\n",
      "ENSG00000272374\n",
      "ENSG00000136449\n",
      "ENSG00000108785\n",
      "ENSG00000125170\n",
      "ENSG00000135900\n",
      "ENSG00000276805\n",
      "ENSG00000133794\n",
      "ENSG00000142227\n",
      "ENSG00000147454\n",
      "ENSG00000134717\n",
      "ENSG00000272148\n",
      "ENSG00000245248\n",
      "ENSG00000198042\n",
      "ENSG00000272899\n",
      "sex\n",
      "ENSG00000258102\n",
      "ENSG00000105675\n",
      "ENSG00000119922\n",
      "ENSG00000153936\n",
      "ENSG00000102057\n",
      "ENSG00000198692\n",
      "ENSG00000116701\n",
      "ENSG00000275342\n",
      "ENSG00000061656\n",
      "ENSG00000278867\n",
      "ENSG00000251432\n",
      "ENSG00000057657\n",
      "ENSG00000248774\n",
      "ENSG00000165478\n",
      "ENSG00000163806\n",
      "ENSG00000128159\n",
      "ENSG00000078269\n",
      "ENSG00000285410\n",
      "ENSG00000138778\n",
      "ENSG00000120519\n",
      "ENSG00000241859\n",
      "ENSG00000175287\n",
      "ENSG00000166387\n",
      "ENSG00000176273\n",
      "ENSG00000166598\n",
      "ENSG00000271576\n",
      "ENSG00000114395\n",
      "ENSG00000152292\n",
      "ENSG00000176927\n",
      "ENSG00000278601\n",
      "ENSG00000137404\n",
      "ENSG00000204428\n",
      "ENSG00000057252\n",
      "ENSG00000100784\n",
      "ENSG00000105835\n",
      "ENSG00000132793\n",
      "ENSG00000180730\n",
      "ENSG00000196696\n",
      "ENSG00000105135\n",
      "ENSG00000107331\n",
      "ENSG00000090020\n",
      "ENSG00000159335\n",
      "ENSG00000237296\n",
      "ENSG00000137960\n",
      "ENSG00000109047\n",
      "ENSG00000249577\n",
      "ENSG00000198019\n",
      "ENSG00000213626\n",
      "ENSG00000141499\n",
      "ENSG00000072609\n",
      "ENSG00000139737\n",
      "ENSG00000138193\n",
      "ENSG00000172461\n",
      "ENSG00000115129\n",
      "ENSG00000168309\n",
      "ENSG00000260526\n",
      "ENSG00000048052\n",
      "ENSG00000023330\n",
      "ENSG00000251022\n",
      "ENSG00000042286\n",
      "ENSG00000196126\n",
      "ENSG00000169246\n",
      "ENSG00000173114\n",
      "ENSG00000087842\n",
      "ENSG00000152782\n",
      "ENSG00000157978\n",
      "ENSG00000281706\n",
      "ENSG00000175745\n",
      "ENSG00000075429\n",
      "ENSG00000119812\n",
      "ENSG00000156535\n",
      "ENSG00000272338\n",
      "ENSG00000090104\n",
      "ENSG00000189058\n",
      "ENSG00000205710\n",
      "ENSG00000168077\n",
      "ENSG00000177873\n",
      "ENSG00000228878\n",
      "ENSG00000143127\n",
      "ENSG00000129535\n",
      "ENSG00000100077\n",
      "ENSG00000238198\n",
      "ENSG00000276445\n",
      "ENSG00000145358\n",
      "ENSG00000275464\n",
      "ENSG00000197993\n",
      "ENSG00000142173\n",
      "ENSG00000172935\n",
      "ENSG00000287527\n",
      "ENSG00000140939\n",
      "ENSG00000286215\n",
      "ENSG00000256542\n",
      "ENSG00000124813\n",
      "ENSG00000100033\n",
      "ENSG00000107643\n",
      "ENSG00000137700\n",
      "ENSG00000116661\n",
      "ENSG00000004776\n",
      "ENSG00000062038\n",
      "ENSG00000285564\n",
      "ENSG00000100246\n",
      "ENSG00000157827\n",
      "ENSG00000177103\n",
      "ENSG00000108375\n",
      "ENSG00000160808\n",
      "ENSG00000123136\n",
      "ENSG00000134533\n",
      "ENSG00000232653\n",
      "ENSG00000093010\n",
      "ENSG00000147912\n",
      "ENSG00000104885\n",
      "ENSG00000287252\n",
      "ENSG00000286330\n",
      "ENSG00000158748\n",
      "ENSG00000167978\n",
      "ENSG00000166793\n",
      "ENSG00000138650\n",
      "ENSG00000198740\n",
      "ENSG00000119699\n",
      "ENSG00000182890\n",
      "ENSG00000253741\n",
      "ENSG00000141452\n",
      "ENSG00000107779\n",
      "ENSG00000214548\n",
      "ENSG00000175611\n",
      "ENSG00000228486\n",
      "ENSG00000136367\n",
      "ENSG00000196465\n",
      "ENSG00000234420\n",
      "ENSG00000121680\n",
      "ENSG00000178927\n",
      "ENSG00000285600\n",
      "ENSG00000039560\n",
      "ENSG00000234494\n",
      "ENSG00000113595\n",
      "ENSG00000168778\n",
      "ENSG00000177971\n",
      "ENSG00000100068\n",
      "ENSG00000076003\n",
      "ENSG00000278619\n",
      "ENSG00000186340\n",
      "ENSG00000163472\n",
      "ENSG00000237943\n",
      "ENSG00000186193\n",
      "ENSG00000187764\n",
      "ENSG00000182118\n",
      "ENSG00000174718\n",
      "ENSG00000138798\n",
      "ENSG00000198695\n",
      "ENSG00000173418\n",
      "ENSG00000287689\n",
      "ENSG00000151838\n",
      "ENSG00000254427\n",
      "ENSG00000179954\n",
      "ENSG00000172164\n",
      "ENSG00000196990\n",
      "ENSG00000168566\n",
      "ENSG00000091592\n",
      "ENSG00000080822\n",
      "ENSG00000118680\n",
      "ENSG00000223509\n",
      "ENSG00000183690\n",
      "ENSG00000146409\n",
      "ENSG00000280061\n",
      "ENSG00000115963\n",
      "ENSG00000121753\n",
      "ENSG00000109390\n",
      "ENSG00000232903\n",
      "ENSG00000274290\n",
      "ENSG00000092820\n",
      "ENSG00000111602\n",
      "ENSG00000183569\n",
      "ENSG00000114374\n",
      "ENSG00000124126\n",
      "ENSG00000214140\n",
      "ENSG00000232940\n",
      "ENSG00000188536\n",
      "ENSG00000116761\n",
      "ENSG00000286418\n",
      "ENSG00000177076\n",
      "ENSG00000101438\n",
      "ENSG00000169436\n",
      "ENSG00000272944\n",
      "ENSG00000272871\n",
      "ENSG00000185345\n",
      "ENSG00000196517\n",
      "ENSG00000239382\n",
      "ENSG00000100065\n",
      "ENSG00000110697\n",
      "ENSG00000009709\n",
      "ENSG00000187961\n",
      "ENSG00000156076\n",
      "ENSG00000258708\n",
      "ENSG00000254783\n",
      "ENSG00000151552\n",
      "ENSG00000125148\n",
      "ENSG00000105559\n",
      "ENSG00000109113\n",
      "ENSG00000173641\n",
      "ENSG00000163485\n",
      "ENSG00000206120\n",
      "ENSG00000119787\n",
      "ENSG00000149489\n",
      "ENSG00000204482\n",
      "ENSG00000101146\n",
      "ENSG00000224903\n",
      "ENSG00000160862\n",
      "ENSG00000171241\n",
      "ENSG00000071205\n",
      "ENSG00000051128\n",
      "ENSG00000255346\n",
      "ENSG00000075624\n",
      "ENSG00000059804\n",
      "ENSG00000183196\n",
      "ENSG00000161203\n",
      "ENSG00000277791\n",
      "ENSG00000122484\n",
      "ENSG00000068724\n",
      "ENSG00000163735\n",
      "ENSG00000198763\n",
      "ENSG00000228408\n",
      "ENSG00000211772\n",
      "ENSG00000273311\n",
      "ENSG00000250198\n",
      "ENSG00000110900\n",
      "ENSG00000145335\n",
      "ENSG00000149527\n",
      "ENSG00000267072\n",
      "ENSG00000099194\n",
      "ENSG00000158815\n",
      "ENSG00000183654\n",
      "ENSG00000197008\n",
      "ENSG00000197763\n",
      "ENSG00000184221\n",
      "ENSG00000125285\n",
      "ENSG00000246174\n",
      "ENSG00000174132\n",
      "ENSG00000235162\n",
      "ENSG00000156876\n",
      "ENSG00000010610\n",
      "ENSG00000133112\n",
      "ENSG00000121957\n",
      "ENSG00000134323\n",
      "ENSG00000180901\n",
      "ENSG00000175550\n",
      "ENSG00000129654\n",
      "ENSG00000230615\n",
      "ENSG00000006377\n",
      "ENSG00000133519\n",
      "ENSG00000108448\n",
      "ENSG00000276547\n",
      "ENSG00000118785\n",
      "ENSG00000184984\n",
      "ENSG00000137628\n",
      "ENSG00000175691\n",
      "ENSG00000236404\n",
      "ENSG00000225193\n",
      "ENSG00000091428\n",
      "ENSG00000112651\n",
      "ENSG00000168496\n",
      "ENSG00000233290\n",
      "ENSG00000141485\n",
      "ENSG00000183778\n",
      "ENSG00000164116\n",
      "ENSG00000163879\n",
      "ENSG00000203877\n",
      "ENSG00000129951\n",
      "ENSG00000244062\n",
      "ENSG00000268089\n",
      "ENSG00000214652\n",
      "ENSG00000039139\n",
      "ENSG00000095970\n",
      "ENSG00000113369\n",
      "ENSG00000148339\n",
      "ENSG00000187984\n",
      "ENSG00000072501\n",
      "ENSG00000169223\n",
      "ENSG00000123689\n",
      "ENSG00000164061\n",
      "ENSG00000187955\n",
      "ENSG00000183092\n",
      "ENSG00000154945\n",
      "ENSG00000113140\n",
      "ENSG00000174851\n",
      "ENSG00000183580\n",
      "ENSG00000164530\n",
      "ENSG00000176903\n",
      "ENSG00000171606\n",
      "ENSG00000156110\n",
      "ENSG00000204261\n",
      "ENSG00000272084\n",
      "ENSG00000164176\n",
      "ENSG00000165244\n",
      "ENSG00000246067\n",
      "ENSG00000176340\n",
      "ENSG00000125962\n",
      "ENSG00000167136\n",
      "ENSG00000286782\n",
      "ENSG00000225470\n",
      "ENSG00000226752\n",
      "ENSG00000286699\n",
      "ENSG00000134817\n",
      "ENSG00000065308\n",
      "ENSG00000197892\n",
      "ENSG00000167100\n",
      "ENSG00000042832\n",
      "ENSG00000146842\n",
      "ENSG00000171860\n",
      "ENSG00000184613\n",
      "ENSG00000134369\n",
      "ENSG00000164674\n",
      "ENSG00000132122\n",
      "ENSG00000272274\n",
      "ENSG00000131626\n",
      "ENSG00000163536\n",
      "ENSG00000148700\n",
      "ENSG00000136014\n",
      "ENSG00000196227\n",
      "ENSG00000282375\n",
      "ENSG00000186081\n",
      "ENSG00000196924\n",
      "ENSG00000234773\n",
      "ENSG00000117318\n",
      "ENSG00000129675\n",
      "ENSG00000064547\n",
      "ENSG00000220848\n",
      "ENSG00000179922\n",
      "ENSG00000034510\n",
      "ENSG00000131899\n",
      "ENSG00000147257\n",
      "ENSG00000139567\n",
      "ENSG00000123095\n",
      "ENSG00000164296\n",
      "ENSG00000130558\n",
      "ENSG00000165887\n",
      "ENSG00000053900\n",
      "ENSG00000146707\n",
      "ENSG00000196549\n",
      "ENSG00000287783\n",
      "ENSG00000117425\n",
      "ENSG00000147535\n",
      "ENSG00000197927\n",
      "ENSG00000259456\n",
      "ENSG00000049323\n",
      "ENSG00000105662\n",
      "ENSG00000243279\n",
      "ENSG00000205116\n",
      "ENSG00000132031\n",
      "ENSG00000204677\n",
      "ENSG00000075407\n",
      "ENSG00000287550\n",
      "ENSG00000280071\n",
      "ENSG00000287189\n",
      "ENSG00000146374\n",
      "ENSG00000155368\n",
      "ENSG00000168993\n",
      "ENSG00000162613\n",
      "ENSG00000204388\n",
      "ENSG00000235823\n",
      "ENSG00000125356\n",
      "ENSG00000134917\n",
      "ENSG00000260583\n",
      "ENSG00000223551\n",
      "ENSG00000176225\n",
      "ENSG00000241170\n",
      "ENSG00000226029\n",
      "ENSG00000278133\n",
      "ENSG00000260000\n",
      "ENSG00000130055\n",
      "ENSG00000245060\n",
      "ENSG00000100360\n",
      "ENSG00000008226\n",
      "ENSG00000196295\n",
      "ENSG00000213694\n",
      "ENSG00000125503\n",
      "ENSG00000157368\n",
      "ENSG00000158716\n",
      "ENSG00000160321\n",
      "ENSG00000159307\n",
      "ENSG00000197586\n",
      "ENSG00000186517\n",
      "ENSG00000274471\n",
      "ENSG00000161896\n",
      "ENSG00000165474\n",
      "ENSG00000124614\n",
      "ENSG00000112110\n",
      "ENSG00000164690\n",
      "ENSG00000166428\n",
      "ENSG00000059122\n",
      "ENSG00000181085\n",
      "ENSG00000253251\n",
      "ENSG00000072864\n",
      "ENSG00000246922\n",
      "ENSG00000267296\n",
      "ENSG00000158813\n",
      "ENSG00000168314\n",
      "ENSG00000004864\n",
      "ENSG00000136068\n",
      "ENSG00000184922\n",
      "ENSG00000113231\n",
      "ENSG00000272990\n",
      "ENSG00000148606\n",
      "ENSG00000234741\n",
      "ENSG00000111341\n",
      "ENSG00000273437\n",
      "ENSG00000002746\n",
      "ENSG00000149639\n",
      "ENSG00000180198\n",
      "ENSG00000255176\n",
      "ENSG00000150048\n",
      "ENSG00000164976\n",
      "ENSG00000205352\n",
      "ENSG00000179455\n",
      "ENSG00000238045\n",
      "ENSG00000084112\n",
      "ENSG00000131748\n",
      "ENSG00000181938\n",
      "ENSG00000108094\n",
      "ENSG00000172840\n",
      "ENSG00000152684\n",
      "ENSG00000171408\n",
      "ENSG00000233954\n",
      "ENSG00000146006\n",
      "ENSG00000118946\n",
      "ENSG00000287134\n",
      "ENSG00000129158\n",
      "ENSG00000176142\n",
      "ENSG00000170004\n",
      "ENSG00000205643\n",
      "ENSG00000188707\n",
      "ENSG00000189050\n",
      "ENSG00000102359\n",
      "ENSG00000162068\n",
      "ENSG00000135828\n",
      "ENSG00000135052\n",
      "ENSG00000124570\n",
      "ENSG00000219665\n",
      "ENSG00000113163\n",
      "ENSG00000172346\n",
      "ENSG00000141756\n",
      "ENSG00000245532\n",
      "ENSG00000225265\n",
      "ENSG00000204899\n",
      "ENSG00000197859\n",
      "ENSG00000232504\n",
      "ENSG00000170775\n",
      "ENSG00000100034\n",
      "ENSG00000205629\n",
      "ENSG00000151490\n",
      "ENSG00000149531\n",
      "ENSG00000242193\n",
      "ENSG00000087884\n",
      "ENSG00000184635\n",
      "ENSG00000139722\n",
      "ENSG00000140905\n",
      "ENSG00000196187\n",
      "ENSG00000285847\n",
      "ENSG00000196072\n",
      "ENSG00000166924\n",
      "ENSG00000166707\n",
      "ENSG00000105137\n",
      "ENSG00000205037\n",
      "ENSG00000196743\n",
      "ENSG00000196482\n",
      "ENSG00000138722\n",
      "ENSG00000151023\n",
      "ENSG00000233123\n",
      "ENSG00000140522\n",
      "ENSG00000125378\n",
      "ENSG00000107816\n",
      "ENSG00000173404\n",
      "ENSG00000120942\n",
      "ENSG00000149054\n",
      "ENSG00000166012\n",
      "ENSG00000224699\n",
      "ENSG00000221926\n",
      "ENSG00000175772\n",
      "ENSG00000011485\n",
      "ENSG00000228716\n",
      "ENSG00000273893\n",
      "ENSG00000279722\n",
      "ENSG00000135083\n",
      "ENSG00000162512\n",
      "ENSG00000238113\n",
      "ENSG00000249096\n",
      "ENSG00000162692\n",
      "ENSG00000181751\n",
      "ENSG00000123124\n",
      "ENSG00000105722\n",
      "ENSG00000175352\n",
      "ENSG00000187498\n",
      "ENSG00000125775\n",
      "ENSG00000144339\n",
      "ENSG00000134042\n",
      "ENSG00000135077\n",
      "ENSG00000123119\n",
      "ENSG00000142871\n",
      "ENSG00000174403\n",
      "ENSG00000215158\n",
      "ENSG00000103326\n",
      "ENSG00000186660\n",
      "ENSG00000151650\n",
      "ENSG00000268061\n",
      "ENSG00000114204\n",
      "ENSG00000261600\n",
      "ENSG00000234608\n",
      "ENSG00000223478\n",
      "ENSG00000229321\n",
      "ENSG00000114626\n",
      "ENSG00000232310\n",
      "ENSG00000260572\n",
      "ENSG00000144057\n",
      "ENSG00000148057\n",
      "ENSG00000260743\n",
      "ENSG00000037757\n",
      "ENSG00000162755\n",
      "ENSG00000183888\n",
      "ENSG00000128536\n",
      "ENSG00000115155\n",
      "ENSG00000139926\n",
      "ENSG00000166927\n",
      "ENSG00000180884\n",
      "ENSG00000138115\n",
      "ENSG00000225194\n",
      "ENSG00000081307\n",
      "ENSG00000165406\n",
      "ENSG00000100316\n",
      "ENSG00000158050\n",
      "ENSG00000118620\n",
      "ENSG00000164211\n",
      "ENSG00000163046\n",
      "ENSG00000163053\n",
      "ENSG00000175664\n",
      "ENSG00000165516\n",
      "ENSG00000205106\n",
      "ENSG00000087053\n",
      "ENSG00000127530\n",
      "ENSG00000160062\n",
      "ENSG00000139644\n",
      "ENSG00000140511\n",
      "ENSG00000182310\n",
      "ENSG00000153012\n",
      "ENSG00000185532\n",
      "ENSG00000249740\n",
      "ENSG00000102580\n",
      "ENSG00000188766\n",
      "ENSG00000154079\n",
      "ENSG00000280046\n",
      "ENSG00000197582\n",
      "ENSG00000178093\n",
      "ENSG00000204950\n",
      "ENSG00000267481\n",
      "ENSG00000153823\n",
      "ENSG00000286177\n",
      "ENSG00000232406\n",
      "ENSG00000253868\n",
      "ENSG00000248727\n",
      "ENSG00000102837\n",
      "ENSG00000272106\n",
      "ENSG00000261324\n",
      "ENSG00000259146\n",
      "ENSG00000038382\n",
      "ENSG00000137269\n",
      "ENSG00000182963\n",
      "ENSG00000180537\n",
      "ENSG00000084734\n",
      "ENSG00000198576\n",
      "ENSG00000147647\n",
      "ENSG00000035403\n",
      "ENSG00000258789\n",
      "ENSG00000180921\n",
      "ENSG00000248309\n",
      "ENSG00000273372\n",
      "ENSG00000143110\n",
      "ENSG00000127083\n",
      "ENSG00000258342\n",
      "ENSG00000221843\n",
      "ENSG00000183873\n",
      "ENSG00000075826\n",
      "ENSG00000105173\n",
      "ENSG00000141480\n",
      "ENSG00000280173\n",
      "ENSG00000147224\n",
      "ENSG00000122694\n",
      "ENSG00000250686\n",
      "ENSG00000003249\n",
      "ENSG00000109929\n",
      "ENSG00000253671\n",
      "ENSG00000286970\n",
      "ENSG00000074964\n",
      "ENSG00000174721\n",
      "ENSG00000158315\n",
      "ENSG00000114698\n",
      "ENSG00000170579\n",
      "ENSG00000026508\n",
      "ENSG00000121988\n",
      "ENSG00000173281\n",
      "ENSG00000188315\n",
      "ENSG00000122012\n",
      "ENSG00000050165\n",
      "ENSG00000120594\n",
      "ENSG00000213963\n",
      "ENSG00000168785\n",
      "ENSG00000136869\n",
      "ENSG00000094975\n",
      "ENSG00000203747\n",
      "ENSG00000102181\n",
      "ENSG00000113758\n",
      "ENSG00000113657\n",
      "ENSG00000149428\n",
      "ENSG00000224097\n",
      "ENSG00000213904\n",
      "ENSG00000123131\n",
      "ENSG00000089041\n",
      "ENSG00000134256\n",
      "ENSG00000000460\n",
      "ENSG00000118762\n",
      "ENSG00000130052\n",
      "ENSG00000100359\n",
      "ENSG00000166592\n",
      "ENSG00000175170\n",
      "ENSG00000256525\n",
      "ENSG00000051523\n",
      "ENSG00000108239\n",
      "ENSG00000143028\n",
      "ENSG00000177169\n",
      "ENSG00000003436\n",
      "ENSG00000108797\n",
      "ENSG00000088826\n",
      "ENSG00000272568\n",
      "ENSG00000197858\n",
      "ENSG00000205364\n",
      "ENSG00000150054\n",
      "ENSG00000255916\n",
      "ENSG00000144136\n",
      "ENSG00000152954\n",
      "ENSG00000239268\n",
      "ENSG00000112308\n",
      "ENSG00000164741\n",
      "ENSG00000273001\n",
      "ENSG00000163689\n",
      "ENSG00000168546\n",
      "ENSG00000185669\n",
      "ENSG00000184144\n",
      "ENSG00000165966\n",
      "ENSG00000105607\n",
      "ENSG00000107104\n",
      "ENSG00000280234\n",
      "ENSG00000182916\n",
      "ENSG00000133627\n",
      "ENSG00000111785\n",
      "ENSG00000137959\n",
      "ENSG00000187134\n",
      "ENSG00000176974\n",
      "ENSG00000180340\n",
      "ENSG00000104327\n",
      "ENSG00000133466\n",
      "ENSG00000100983\n",
      "ENSG00000262312\n",
      "ENSG00000154764\n",
      "ENSG00000159674\n",
      "ENSG00000175768\n",
      "ENSG00000230091\n",
      "ENSG00000035862\n",
      "ENSG00000164488\n",
      "ENSG00000273702\n",
      "ENSG00000284966\n",
      "ENSG00000187189\n",
      "ENSG00000261824\n",
      "ENSG00000182208\n",
      "ENSG00000157168\n",
      "ENSG00000157870\n",
      "ENSG00000183655\n",
      "ENSG00000103260\n",
      "ENSG00000277829\n",
      "ENSG00000235655\n",
      "ENSG00000197893\n",
      "ENSG00000083123\n",
      "ENSG00000182087\n",
      "ENSG00000005381\n",
      "ENSG00000163430\n",
      "ENSG00000176438\n",
      "ENSG00000116711\n",
      "ENSG00000188761\n",
      "ENSG00000135378\n",
      "ENSG00000156968\n",
      "ENSG00000175567\n",
      "ENSG00000122679\n",
      "ENSG00000183423\n",
      "ENSG00000163001\n",
      "ENSG00000115884\n",
      "ENSG00000223804\n",
      "ENSG00000164002\n",
      "ENSG00000165572\n",
      "ENSG00000146192\n",
      "ENSG00000259431\n",
      "ENSG00000126790\n",
      "ENSG00000132781\n",
      "ENSG00000104626\n",
      "ENSG00000134871\n",
      "ENSG00000236700\n",
      "ENSG00000259959\n",
      "ENSG00000261770\n",
      "ENSG00000221986\n",
      "ENSG00000104852\n",
      "ENSG00000176809\n",
      "ENSG00000166532\n",
      "ENSG00000144199\n",
      "ENSG00000152926\n",
      "ENSG00000090382\n",
      "ENSG00000147408\n",
      "ENSG00000065833\n",
      "ENSG00000026950\n",
      "ENSG00000138835\n",
      "ENSG00000183049\n",
      "ENSG00000188153\n",
      "ENSG00000179564\n",
      "ENSG00000154589\n",
      "ENSG00000262223\n",
      "ENSG00000248858\n",
      "ENSG00000172159\n",
      "ENSG00000137033\n",
      "ENSG00000184831\n",
      "ENSG00000277969\n",
      "ENSG00000111490\n",
      "ENSG00000173517\n",
      "ENSG00000244682\n",
      "ENSG00000144649\n",
      "ENSG00000205572\n",
      "ENSG00000113739\n",
      "ENSG00000179918\n",
      "ENSG00000134321\n",
      "ENSG00000065413\n",
      "ENSG00000204065\n",
      "ENSG00000100403\n",
      "ENSG00000050030\n",
      "ENSG00000146352\n",
      "ENSG00000120802\n",
      "ENSG00000139973\n",
      "ENSG00000176845\n",
      "ENSG00000205704\n",
      "ENSG00000261188\n",
      "ENSG00000146826\n",
      "ENSG00000141665\n",
      "ENSG00000136114\n",
      "ENSG00000182902\n",
      "ENSG00000164465\n",
      "ENSG00000151789\n",
      "ENSG00000283757\n",
      "ENSG00000130876\n",
      "ENSG00000100577\n",
      "ENSG00000187527\n",
      "ENSG00000142494\n",
      "ENSG00000112655\n",
      "ENSG00000058804\n",
      "ENSG00000180875\n",
      "ENSG00000250007\n",
      "ENSG00000170089\n",
      "ENSG00000047617\n",
      "ENSG00000152931\n",
      "ENSG00000162711\n",
      "ENSG00000231365\n",
      "ENSG00000102349\n",
      "ENSG00000237438\n",
      "ENSG00000174145\n",
      "ENSG00000280187\n",
      "ENSG00000165689\n",
      "ENSG00000198420\n",
      "ENSG00000157379\n",
      "ENSG00000128512\n",
      "ENSG00000088899\n",
      "ENSG00000150337\n",
      "ENSG00000189376\n",
      "ENSG00000226328\n",
      "ENSG00000176700\n",
      "ENSG00000177548\n",
      "ENSG00000181061\n",
      "ENSG00000224609\n",
      "ENSG00000183230\n",
      "ENSG00000154146\n",
      "ENSG00000186594\n",
      "ENSG00000110079\n",
      "ENSG00000149761\n",
      "ENSG00000048162\n",
      "ENSG00000105856\n",
      "ENSG00000005893\n",
      "ENSG00000266094\n",
      "ENSG00000226137\n",
      "ENSG00000241764\n",
      "ENSG00000120913\n",
      "ENSG00000249353\n",
      "ENSG00000228506\n",
      "ENSG00000130508\n",
      "ENSG00000155760\n",
      "ENSG00000243444\n",
      "ENSG00000101439\n",
      "ENSG00000102287\n",
      "ENSG00000259953\n",
      "ENSG00000173391\n",
      "ENSG00000204745\n",
      "ENSG00000187049\n",
      "ENSG00000285940\n",
      "ENSG00000268297\n",
      "ENSG00000256029\n",
      "ENSG00000246308\n",
      "ENSG00000242715\n",
      "ENSG00000205571\n",
      "ENSG00000092850\n",
      "ENSG00000090857\n",
      "ENSG00000183833\n",
      "ENSG00000259768\n",
      "ENSG00000184307\n",
      "ENSG00000129473\n",
      "ENSG00000204219\n",
      "ENSG00000270557\n",
      "ENSG00000152669\n",
      "ENSG00000184809\n",
      "ENSG00000187837\n",
      "ENSG00000270012\n",
      "ENSG00000133313\n",
      "ENSG00000174996\n",
      "ENSG00000231064\n",
      "ENSG00000279663\n",
      "ENSG00000103569\n",
      "ENSG00000242588\n",
      "ENSG00000132688\n",
      "ENSG00000110042\n",
      "ENSG00000171502\n",
      "ENSG00000173599\n",
      "ENSG00000164953\n",
      "ENSG00000241288\n",
      "ENSG00000129219\n",
      "ENSG00000149257\n",
      "ENSG00000286117\n",
      "ENSG00000196616\n",
      "ENSG00000087589\n",
      "ENSG00000125650\n",
      "ENSG00000217801\n",
      "ENSG00000139433\n",
      "ENSG00000144485\n",
      "ENSG00000197705\n",
      "ENSG00000136950\n",
      "ENSG00000164327\n",
      "ENSG00000204323\n",
      "ENSG00000159409\n",
      "ENSG00000172340\n",
      "ENSG00000130176\n",
      "ENSG00000286964\n",
      "ENSG00000159248\n",
      "ENSG00000089123\n",
      "ENSG00000124733\n",
      "ENSG00000132535\n",
      "ENSG00000135821\n",
      "ENSG00000110881\n",
      "ENSG00000166823\n",
      "ENSG00000048540\n",
      "ENSG00000175283\n",
      "ENSG00000272788\n",
      "ENSG00000259494\n",
      "ENSG00000239523\n",
      "ENSG00000130707\n",
      "ENSG00000123815\n",
      "ENSG00000247595\n",
      "ENSG00000175318\n",
      "ENSG00000284959\n",
      "ENSG00000233622\n",
      "ENSG00000278195\n",
      "ENSG00000137177\n",
      "ENSG00000081377\n",
      "ENSG00000259877\n",
      "ENSG00000139890\n",
      "ENSG00000130962\n",
      "ENSG00000109466\n",
      "ENSG00000277007\n",
      "ENSG00000115556\n",
      "ENSG00000183850\n",
      "ENSG00000236963\n",
      "ENSG00000130287\n",
      "ENSG00000281692\n",
      "ENSG00000174791\n",
      "ENSG00000159086\n",
      "ENSG00000267317\n",
      "ENSG00000196950\n",
      "ENSG00000164087\n",
      "ENSG00000116774\n",
      "ENSG00000174776\n",
      "ENSG00000126950\n",
      "ENSG00000257285\n",
      "ENSG00000143340\n",
      "ENSG00000124440\n",
      "ENSG00000134769\n",
      "ENSG00000279456\n",
      "ENSG00000105373\n",
      "ENSG00000279656\n",
      "ENSG00000230454\n",
      "ENSG00000280734\n",
      "ENSG00000158865\n",
      "ENSG00000204291\n",
      "ENSG00000170417\n",
      "ENSG00000189190\n",
      "ENSG00000197774\n",
      "ENSG00000160766\n",
      "ENSG00000160606\n",
      "ENSG00000234160\n",
      "ENSG00000227799\n",
      "ENSG00000151849\n",
      "ENSG00000110077\n",
      "ENSG00000241472\n",
      "ENSG00000272321\n",
      "ENSG00000229956\n",
      "ENSG00000157184\n",
      "ENSG00000186501\n",
      "ENSG00000110104\n",
      "ENSG00000255920\n",
      "ENSG00000186026\n",
      "ENSG00000255652\n",
      "ENSG00000273419\n",
      "ENSG00000115112\n",
      "ENSG00000146054\n",
      "ENSG00000182326\n",
      "ENSG00000249437\n",
      "ENSG00000204623\n",
      "ENSG00000224536\n",
      "ENSG00000257522\n",
      "ENSG00000166130\n",
      "ENSG00000108828\n",
      "ENSG00000267248\n",
      "ENSG00000213064\n",
      "ENSG00000134516\n",
      "ENSG00000160218\n",
      "ENSG00000239827\n",
      "ENSG00000157191\n",
      "ENSG00000156463\n",
      "ENSG00000103449\n",
      "ENSG00000156858\n",
      "ENSG00000167077\n",
      "ENSG00000062524\n",
      "ENSG00000127311\n",
      "ENSG00000174370\n",
      "ENSG00000277566\n",
      "ENSG00000198298\n",
      "ENSG00000174607\n",
      "ENSG00000184925\n",
      "ENSG00000171840\n",
      "ENSG00000012223\n",
      "ENSG00000229618\n",
      "ENSG00000163235\n",
      "ENSG00000205634\n",
      "ENSG00000100368\n",
      "ENSG00000241278\n",
      "ENSG00000152760\n",
      "ENSG00000115339\n",
      "ENSG00000270959\n",
      "ENSG00000136098\n",
      "ENSG00000186952\n",
      "ENSG00000237489\n",
      "ENSG00000204128\n",
      "ENSG00000137154\n",
      "ENSG00000172380\n",
      "ENSG00000280383\n",
      "ENSG00000243970\n",
      "ENSG00000276900\n",
      "ENSG00000115297\n",
      "ENSG00000265531\n",
      "ENSG00000117228\n",
      "ENSG00000188739\n",
      "ENSG00000162650\n",
      "ENSG00000255769\n",
      "ENSG00000137142\n",
      "ENSG00000137221\n",
      "ENSG00000225978\n",
      "ENSG00000269473\n",
      "ENSG00000244694\n",
      "ENSG00000144040\n",
      "ENSG00000138207\n",
      "ENSG00000183346\n",
      "ENSG00000177675\n",
      "ENSG00000064666\n",
      "ENSG00000197360\n",
      "ENSG00000175449\n",
      "ENSG00000189306\n",
      "ENSG00000226711\n",
      "ENSG00000258429\n",
      "ENSG00000144802\n",
      "ENSG00000105877\n",
      "ENSG00000159720\n",
      "ENSG00000178445\n",
      "ENSG00000279685\n",
      "ENSG00000272631\n",
      "ENSG00000146263\n",
      "ENSG00000100852\n",
      "ENSG00000274602\n",
      "ENSG00000269335\n",
      "ENSG00000164850\n",
      "ENSG00000214026\n",
      "ENSG00000151465\n",
      "ENSG00000275832\n",
      "ENSG00000239887\n",
      "ENSG00000276728\n",
      "ENSG00000184384\n",
      "ENSG00000174720\n",
      "ENSG00000148180\n",
      "ENSG00000103404\n",
      "ENSG00000215146\n",
      "ENSG00000133048\n",
      "ENSG00000171885\n",
      "ENSG00000125827\n",
      "ENSG00000146216\n",
      "ENSG00000071626\n",
      "ENSG00000167074\n",
      "ENSG00000273084\n",
      "ENSG00000179935\n",
      "ENSG00000116815\n",
      "ENSG00000107249\n",
      "ENSG00000112357\n",
      "ENSG00000144119\n",
      "ENSG00000088387\n",
      "ENSG00000152315\n",
      "ENSG00000277692\n",
      "ENSG00000160392\n",
      "ENSG00000169989\n",
      "ENSG00000273344\n",
      "ENSG00000153064\n",
      "ENSG00000171522\n",
      "ENSG00000090924\n",
      "ENSG00000214353\n",
      "ENSG00000116649\n",
      "ENSG00000167604\n",
      "ENSG00000114200\n",
      "ENSG00000179066\n",
      "ENSG00000143442\n",
      "ENSG00000247679\n",
      "ENSG00000129493\n",
      "ENSG00000168615\n",
      "ENSG00000276075\n",
      "ENSG00000254858\n",
      "ENSG00000141858\n",
      "ENSG00000074219\n",
      "ENSG00000231609\n",
      "ENSG00000171951\n",
      "ENSG00000107614\n",
      "ENSG00000104332\n",
      "ENSG00000243789\n",
      "ENSG00000108840\n",
      "ENSG00000151632\n",
      "ENSG00000267731\n",
      "ENSG00000248738\n",
      "ENSG00000184005\n",
      "ENSG00000149499\n",
      "ENSG00000163257\n",
      "ENSG00000224934\n",
      "ENSG00000101347\n",
      "ENSG00000170860\n",
      "ENSG00000111110\n",
      "ENSG00000166206\n",
      "ENSG00000173559\n",
      "ENSG00000101974\n",
      "ENSG00000006747\n",
      "ENSG00000181904\n",
      "ENSG00000100526\n",
      "ENSG00000168062\n",
      "ENSG00000175175\n",
      "ENSG00000173166\n",
      "ENSG00000198301\n",
      "ENSG00000105401\n",
      "ENSG00000141956\n",
      "ENSG00000164669\n",
      "ENSG00000010704\n",
      "ENSG00000175727\n",
      "ENSG00000172794\n",
      "ENSG00000228775\n",
      "ENSG00000197860\n",
      "ENSG00000286667\n",
      "ENSG00000110318\n",
      "ENSG00000277778\n",
      "ENSG00000135414\n",
      "ENSG00000197696\n",
      "ENSG00000099250\n",
      "ENSG00000272923\n",
      "ENSG00000198355\n",
      "ENSG00000111859\n",
      "ENSG00000102174\n",
      "ENSG00000253598\n",
      "ENSG00000130724\n",
      "ENSG00000136732\n",
      "ENSG00000148704\n",
      "ENSG00000262766\n",
      "ENSG00000267278\n",
      "ENSG00000176973\n",
      "ENSG00000137100\n",
      "ENSG00000174886\n",
      "ENSG00000287222\n",
      "ENSG00000141576\n",
      "ENSG00000105711\n",
      "ENSG00000111229\n",
      "ENSG00000232859\n",
      "ENSG00000091640\n",
      "ENSG00000249859\n",
      "ENSG00000260400\n",
      "ENSG00000270504\n",
      "ENSG00000066651\n",
      "ENSG00000158156\n",
      "ENSG00000269959\n",
      "ENSG00000132801\n",
      "ENSG00000268350\n",
      "ENSG00000105227\n",
      "ENSG00000259448\n",
      "ENSG00000119698\n",
      "ENSG00000003393\n",
      "ENSG00000171298\n",
      "ENSG00000129194\n",
      "ENSG00000121101\n",
      "ENSG00000145247\n",
      "ENSG00000249249\n",
      "ENSG00000170962\n",
      "ENSG00000133874\n",
      "ENSG00000143494\n",
      "ENSG00000249335\n",
      "ENSG00000117586\n",
      "ENSG00000269713\n",
      "ENSG00000103540\n",
      "ENSG00000149311\n",
      "ENSG00000133789\n",
      "ENSG00000182263\n",
      "ENSG00000164344\n",
      "ENSG00000146469\n",
      "ENSG00000123700\n",
      "ENSG00000206145\n",
      "ENSG00000226091\n",
      "ENSG00000203668\n",
      "ENSG00000261474\n",
      "ENSG00000103485\n",
      "ENSG00000114473\n",
      "ENSG00000198075\n",
      "ENSG00000146250\n",
      "ENSG00000256742\n",
      "ENSG00000182134\n",
      "ENSG00000169554\n",
      "ENSG00000170909\n",
      "ENSG00000231856\n",
      "ENSG00000231764\n",
      "ENSG00000124212\n",
      "ENSG00000270426\n",
      "ENSG00000286261\n",
      "ENSG00000146233\n",
      "ENSG00000215769\n",
      "ENSG00000247092\n",
      "ENSG00000138135\n",
      "ENSG00000128283\n",
      "ENSG00000249898\n",
      "ENSG00000226891\n",
      "ENSG00000196189\n",
      "ENSG00000164542\n",
      "ENSG00000256762\n",
      "ENSG00000049540\n",
      "ENSG00000260495\n",
      "ENSG00000071242\n",
      "ENSG00000259446\n",
      "ENSG00000187079\n",
      "ENSG00000279495\n",
      "ENSG00000172264\n",
      "ENSG00000143367\n",
      "ENSG00000131116\n",
      "ENSG00000141522\n",
      "ENSG00000069431\n",
      "ENSG00000175938\n",
      "ENSG00000283156\n",
      "ENSG00000106462\n",
      "ENSG00000147162\n",
      "ENSG00000272870\n",
      "ENSG00000124145\n",
      "ENSG00000286647\n",
      "ENSG00000099725\n",
      "ENSG00000171621\n",
      "ENSG00000198483\n",
      "ENSG00000177337\n",
      "ENSG00000248449\n",
      "ENSG00000177303\n",
      "ENSG00000263120\n",
      "ENSG00000112208\n",
      "ENSG00000125753\n",
      "ENSG00000263278\n",
      "ENSG00000139636\n",
      "ENSG00000245750\n",
      "ENSG00000235092\n",
      "ENSG00000198276\n",
      "ENSG00000181631\n",
      "ENSG00000198286\n",
      "ENSG00000276698\n",
      "ENSG00000205913\n",
      "ENSG00000251623\n",
      "ENSG00000065518\n",
      "ENSG00000198795\n",
      "ENSG00000133639\n",
      "ENSG00000198502\n",
      "ENSG00000196358\n",
      "ENSG00000119508\n",
      "ENSG00000147119\n",
      "ENSG00000117862\n",
      "ENSG00000166068\n",
      "ENSG00000104472\n",
      "ENSG00000139675\n",
      "ENSG00000219438\n",
      "ENSG00000233967\n",
      "ENSG00000197562\n",
      "ENSG00000170500\n",
      "ENSG00000111252\n",
      "ENSG00000168374\n",
      "ENSG00000282851\n",
      "ENSG00000144791\n",
      "ENSG00000126067\n",
      "ENSG00000108798\n",
      "ENSG00000280739\n",
      "ENSG00000237753\n",
      "ENSG00000260118\n",
      "ENSG00000136243\n",
      "ENSG00000127946\n",
      "ENSG00000131584\n",
      "ENSG00000164615\n",
      "ENSG00000261490\n",
      "ENSG00000138686\n",
      "ENSG00000273729\n",
      "ENSG00000122877\n",
      "ENSG00000082781\n",
      "ENSG00000162999\n",
      "ENSG00000172889\n",
      "ENSG00000157227\n",
      "ENSG00000214029\n",
      "ENSG00000138100\n",
      "ENSG00000198870\n",
      "ENSG00000155897\n",
      "ENSG00000148680\n",
      "ENSG00000176401\n",
      "ENSG00000286662\n",
      "ENSG00000173258\n",
      "ENSG00000160223\n",
      "ENSG00000125746\n",
      "ENSG00000132434\n",
      "ENSG00000157625\n",
      "ENSG00000285210\n",
      "ENSG00000189129\n",
      "ENSG00000137936\n",
      "ENSG00000197279\n",
      "ENSG00000254206\n",
      "ENSG00000115541\n",
      "ENSG00000240344\n",
      "ENSG00000269858\n",
      "ENSG00000170153\n",
      "ENSG00000178882\n",
      "ENSG00000160588\n",
      "ENSG00000177042\n",
      "ENSG00000174938\n",
      "ENSG00000022556\n",
      "ENSG00000171695\n",
      "ENSG00000217643\n",
      "ENSG00000229891\n",
      "ENSG00000160352\n",
      "ENSG00000116337\n",
      "ENSG00000228314\n",
      "ENSG00000261373\n",
      "ENSG00000168852\n",
      "ENSG00000161647\n",
      "ENSG00000269235\n",
      "ENSG00000184489\n",
      "ENSG00000276282\n",
      "ENSG00000287750\n",
      "ENSG00000249592\n",
      "ENSG00000164576\n",
      "ENSG00000272701\n",
      "ENSG00000186310\n",
      "ENSG00000162636\n",
      "ENSG00000074356\n",
      "ENSG00000274828\n",
      "ENSG00000106278\n",
      "ENSG00000166173\n",
      "ENSG00000146425\n",
      "ENSG00000118276\n",
      "ENSG00000181690\n",
      "ENSG00000104881\n",
      "ENSG00000063127\n",
      "ENSG00000100804\n",
      "ENSG00000133316\n",
      "ENSG00000178852\n",
      "ENSG00000185904\n",
      "ENSG00000138463\n",
      "ENSG00000110429\n",
      "ENSG00000276231\n",
      "ENSG00000204237\n",
      "ENSG00000227268\n",
      "ENSG00000171222\n",
      "ENSG00000120341\n",
      "ENSG00000213719\n",
      "ENSG00000148426\n",
      "ENSG00000180448\n",
      "ENSG00000162231\n",
      "ENSG00000143149\n",
      "ENSG00000286710\n",
      "ENSG00000204287\n",
      "ENSG00000171476\n",
      "ENSG00000119632\n",
      "ENSG00000171772\n",
      "ENSG00000196932\n",
      "ENSG00000163702\n",
      "ENSG00000267575\n",
      "ENSG00000155380\n",
      "ENSG00000142541\n",
      "ENSG00000130529\n",
      "ENSG00000135898\n",
      "ENSG00000143977\n",
      "ENSG00000115128\n",
      "ENSG00000147255\n",
      "ENSG00000131778\n",
      "ENSG00000089163\n",
      "ENSG00000088448\n",
      "ENSG00000160172\n",
      "ENSG00000146281\n",
      "ENSG00000103460\n",
      "ENSG00000255423\n",
      "ENSG00000242866\n",
      "ENSG00000282390\n",
      "ENSG00000177943\n",
      "ENSG00000137494\n",
      "ENSG00000138741\n",
      "ENSG00000205413\n",
      "ENSG00000244405\n",
      "ENSG00000157514\n",
      "ENSG00000166979\n",
      "ENSG00000133169\n",
      "ENSG00000184047\n",
      "ENSG00000153707\n",
      "ENSG00000243696\n",
      "ENSG00000088325\n",
      "ENSG00000136866\n",
      "ENSG00000112619\n",
      "ENSG00000242294\n",
      "ENSG00000083857\n",
      "ENSG00000140876\n",
      "ENSG00000271895\n",
      "ENSG00000224086\n",
      "ENSG00000267056\n",
      "ENSG00000178538\n",
      "ENSG00000134851\n",
      "ENSG00000144118\n",
      "ENSG00000111058\n",
      "ENSG00000111269\n",
      "ENSG00000166164\n",
      "ENSG00000272853\n",
      "ENSG00000198707\n",
      "ENSG00000268654\n",
      "ENSG00000077063\n",
      "ENSG00000140030\n",
      "ENSG00000079841\n",
      "ENSG00000256925\n",
      "ENSG00000248485\n",
      "ENSG00000103196\n",
      "ENSG00000073150\n",
      "ENSG00000196542\n",
      "ENSG00000143318\n",
      "ENSG00000145428\n",
      "ENSG00000078902\n",
      "ENSG00000184445\n",
      "ENSG00000182185\n",
      "ENSG00000180879\n",
      "ENSG00000250490\n",
      "ENSG00000230498\n",
      "ENSG00000166928\n",
      "ENSG00000107593\n",
      "ENSG00000196776\n",
      "ENSG00000167994\n",
      "ENSG00000172354\n",
      "ENSG00000281128\n",
      "ENSG00000164758\n",
      "ENSG00000019549\n",
      "ENSG00000260236\n",
      "ENSG00000006016\n",
      "ENSG00000179134\n",
      "ENSG00000238099\n",
      "ENSG00000284633\n",
      "ENSG00000188559\n",
      "ENSG00000162490\n",
      "ENSG00000003137\n",
      "ENSG00000001630\n",
      "ENSG00000281404\n",
      "ENSG00000276975\n",
      "ENSG00000226828\n",
      "ENSG00000186818\n",
      "ENSG00000167513\n",
      "ENSG00000186010\n",
      "ENSG00000156313\n",
      "ENSG00000163611\n",
      "ENSG00000263956\n",
      "ENSG00000154380\n",
      "ENSG00000243710\n",
      "ENSG00000171243\n",
      "ENSG00000115107\n",
      "ENSG00000173714\n",
      "ENSG00000168038\n",
      "ENSG00000086205\n",
      "ENSG00000176723\n",
      "ENSG00000203900\n",
      "ENSG00000185561\n",
      "ENSG00000126733\n",
      "ENSG00000139220\n",
      "ENSG00000147536\n",
      "ENSG00000118322\n",
      "ENSG00000136938\n",
      "ENSG00000225828\n",
      "ENSG00000124664\n",
      "ENSG00000185483\n",
      "ENSG00000181804\n",
      "ENSG00000221968\n",
      "ENSG00000122863\n",
      "ENSG00000183091\n",
      "ENSG00000272145\n",
      "ENSG00000124006\n",
      "ENSG00000226686\n",
      "ENSG00000127472\n",
      "ENSG00000253230\n",
      "ENSG00000183691\n",
      "ENSG00000172890\n",
      "ENSG00000247982\n",
      "ENSG00000143575\n",
      "ENSG00000173894\n",
      "ENSG00000012779\n",
      "ENSG00000166046\n",
      "ENSG00000163528\n",
      "ENSG00000163162\n",
      "ENSG00000182376\n",
      "ENSG00000101049\n",
      "ENSG00000221983\n",
      "ENSG00000268055\n",
      "ENSG00000183401\n",
      "ENSG00000174871\n",
      "ENSG00000003989\n",
      "ENSG00000227110\n",
      "ENSG00000182325\n",
      "ENSG00000079150\n",
      "ENSG00000133321\n",
      "ENSG00000266573\n",
      "ENSG00000188803\n",
      "ENSG00000164330\n",
      "ENSG00000130669\n",
      "ENSG00000246985\n",
      "ENSG00000158792\n",
      "ENSG00000168748\n",
      "ENSG00000277795\n",
      "ENSG00000176771\n",
      "ENSG00000149305\n",
      "ENSG00000228624\n",
      "ENSG00000244274\n",
      "ENSG00000184451\n",
      "ENSG00000122862\n",
      "ENSG00000178199\n",
      "ENSG00000164651\n",
      "ENSG00000224975\n",
      "ENSG00000189056\n",
      "ENSG00000104915\n",
      "ENSG00000140859\n",
      "ENSG00000135333\n",
      "ENSG00000122966\n",
      "ENSG00000280120\n",
      "ENSG00000105519\n",
      "ENSG00000148803\n",
      "ENSG00000122335\n",
      "ENSG00000171792\n",
      "ENSG00000164434\n",
      "ENSG00000254093\n",
      "ENSG00000186468\n",
      "ENSG00000177853\n",
      "ENSG00000023909\n",
      "ENSG00000132470\n",
      "ENSG00000244480\n",
      "ENSG00000156860\n",
      "ENSG00000197599\n",
      "ENSG00000232545\n",
      "ENSG00000152076\n",
      "ENSG00000240207\n",
      "ENSG00000130822\n",
      "ENSG00000127364\n",
      "ENSG00000169733\n",
      "ENSG00000118729\n",
      "ENSG00000180592\n",
      "ENSG00000141337\n",
      "ENSG00000204175\n",
      "ENSG00000273203\n",
      "ENSG00000065989\n",
      "ENSG00000185220\n",
      "ENSG00000105989\n",
      "ENSG00000167483\n",
      "ENSG00000214401\n",
      "ENSG00000278727\n",
      "ENSG00000012171\n",
      "ENSG00000064601\n",
      "ENSG00000145808\n",
      "ENSG00000175455\n",
      "ENSG00000116205\n",
      "ENSG00000101134\n",
      "ENSG00000127252\n",
      "ENSG00000140873\n",
      "ENSG00000108641\n",
      "ENSG00000105865\n",
      "ENSG00000164904\n",
      "ENSG00000121068\n",
      "ENSG00000169221\n",
      "ENSG00000253159\n",
      "ENSG00000127578\n",
      "ENSG00000255561\n",
      "ENSG00000136002\n",
      "ENSG00000125246\n",
      "ENSG00000198952\n",
      "ENSG00000131386\n",
      "ENSG00000158966\n",
      "ENSG00000272108\n",
      "ENSG00000058335\n",
      "ENSG00000118292\n",
      "ENSG00000164112\n",
      "ENSG00000153162\n",
      "ENSG00000115252\n",
      "ENSG00000151617\n",
      "ENSG00000137642\n",
      "ENSG00000157214\n",
      "ENSG00000149260\n",
      "ENSG00000140543\n",
      "ENSG00000065882\n",
      "ENSG00000106100\n",
      "ENSG00000104814\n",
      "ENSG00000167380\n",
      "ENSG00000109832\n",
      "ENSG00000283312\n",
      "ENSG00000196922\n",
      "ENSG00000249550\n",
      "ENSG00000273305\n",
      "ENSG00000123353\n",
      "ENSG00000172366\n",
      "ENSG00000175970\n",
      "ENSG00000130255\n",
      "ENSG00000066032\n",
      "ENSG00000228672\n",
      "ENSG00000135426\n",
      "ENSG00000115977\n",
      "ENSG00000254681\n",
      "ENSG00000138587\n",
      "ENSG00000213445\n",
      "ENSG00000115368\n",
      "ENSG00000272040\n",
      "ENSG00000198468\n",
      "ENSG00000187323\n",
      "ENSG00000248161\n",
      "ENSG00000227733\n",
      "ENSG00000261366\n",
      "ENSG00000131174\n",
      "ENSG00000080166\n",
      "ENSG00000099949\n",
      "ENSG00000156482\n",
      "ENSG00000233452\n",
      "ENSG00000134072\n",
      "ENSG00000106366\n",
      "ENSG00000188011\n",
      "ENSG00000148158\n",
      "ENSG00000108691\n",
      "ENSG00000162913\n",
      "ENSG00000266967\n",
      "ENSG00000285184\n",
      "ENSG00000189410\n",
      "ENSG00000274642\n",
      "ENSG00000106526\n",
      "ENSG00000144908\n",
      "ENSG00000006327\n",
      "ENSG00000134899\n",
      "ENSG00000171729\n",
      "ENSG00000061936\n",
      "ENSG00000229638\n",
      "ENSG00000182511\n",
      "ENSG00000147894\n",
      "ENSG00000069509\n",
      "ENSG00000072210\n",
      "ENSG00000247624\n",
      "ENSG00000134982\n",
      "ENSG00000177108\n",
      "ENSG00000074621\n",
      "ENSG00000266910\n",
      "ENSG00000073350\n",
      "ENSG00000139971\n",
      "ENSG00000053524\n",
      "ENSG00000145423\n",
      "ENSG00000171450\n",
      "ENSG00000117616\n",
      "ENSG00000161618\n",
      "ENSG00000143195\n",
      "ENSG00000066294\n",
      "ENSG00000138641\n",
      "ENSG00000009694\n",
      "ENSG00000004478\n",
      "ENSG00000279880\n",
      "ENSG00000079459\n",
      "ENSG00000064886\n",
      "ENSG00000132294\n",
      "ENSG00000167196\n",
      "ENSG00000067064\n",
      "ENSG00000135549\n",
      "ENSG00000141469\n",
      "ENSG00000177485\n",
      "ENSG00000261737\n",
      "ENSG00000038002\n",
      "ENSG00000160219\n",
      "ENSG00000023445\n",
      "ENSG00000159840\n",
      "ENSG00000127993\n",
      "ENSG00000267080\n",
      "ENSG00000272842\n",
      "ENSG00000133104\n",
      "ENSG00000249167\n",
      "ENSG00000178342\n",
      "ENSG00000138823\n",
      "ENSG00000070444\n",
      "ENSG00000163002\n",
      "ENSG00000165138\n",
      "ENSG00000214226\n",
      "ENSG00000056998\n",
      "ENSG00000165238\n",
      "ENSG00000128591\n",
      "ENSG00000123297\n",
      "ENSG00000129932\n",
      "ENSG00000261423\n",
      "ENSG00000095587\n",
      "ENSG00000115539\n",
      "ENSG00000123999\n",
      "ENSG00000162520\n",
      "ENSG00000116729\n",
      "ENSG00000116750\n",
      "ENSG00000150551\n",
      "ENSG00000233170\n",
      "ENSG00000072182\n",
      "ENSG00000243155\n",
      "ENSG00000136235\n",
      "ENSG00000140718\n",
      "ENSG00000254726\n",
      "ENSG00000255559\n",
      "ENSG00000236438\n",
      "ENSG00000164442\n",
      "ENSG00000259905\n",
      "ENSG00000172062\n",
      "ENSG00000140961\n",
      "ENSG00000188295\n",
      "ENSG00000211450\n",
      "ENSG00000250305\n",
      "ENSG00000138759\n",
      "ENSG00000106948\n",
      "ENSG00000154874\n",
      "ENSG00000138621\n",
      "ENSG00000261766\n",
      "ENSG00000121310\n",
      "ENSG00000131238\n",
      "ENSG00000110013\n",
      "ENSG00000174226\n",
      "ENSG00000237686\n",
      "ENSG00000247095\n",
      "ENSG00000175787\n",
      "ENSG00000166377\n",
      "ENSG00000249889\n",
      "ENSG00000249471\n",
      "ENSG00000198346\n",
      "ENSG00000239704\n",
      "ENSG00000235381\n",
      "ENSG00000267534\n",
      "ENSG00000151338\n",
      "ENSG00000125848\n",
      "ENSG00000273024\n",
      "ENSG00000267796\n",
      "ENSG00000150275\n",
      "ENSG00000286749\n",
      "ENSG00000114853\n",
      "ENSG00000150630\n",
      "ENSG00000253200\n",
      "ENSG00000159164\n",
      "ENSG00000171045\n",
      "ENSG00000110324\n",
      "ENSG00000267272\n",
      "ENSG00000143546\n",
      "ENSG00000132541\n",
      "ENSG00000261542\n",
      "ENSG00000067113\n",
      "ENSG00000162882\n",
      "ENSG00000179981\n",
      "ENSG00000165959\n",
      "ENSG00000264515\n",
      "ENSG00000170667\n",
      "ENSG00000182329\n",
      "ENSG00000143774\n",
      "ENSG00000185989\n",
      "ENSG00000287978\n",
      "ENSG00000134184\n",
      "ENSG00000271122\n",
      "ENSG00000246100\n",
      "ENSG00000106236\n",
      "ENSG00000159873\n",
      "ENSG00000169918\n",
      "ENSG00000163016\n",
      "ENSG00000182957\n",
      "ENSG00000168071\n",
      "ENSG00000228107\n",
      "ENSG00000286388\n",
      "ENSG00000224786\n",
      "ENSG00000173039\n",
      "ENSG00000163703\n",
      "ENSG00000164398\n",
      "ENSG00000233016\n",
      "ENSG00000151882\n",
      "ENSG00000150637\n",
      "ENSG00000168398\n",
      "ENSG00000251165\n",
      "ENSG00000270127\n",
      "ENSG00000158201\n",
      "ENSG00000152582\n",
      "ENSG00000279894\n",
      "ENSG00000254415\n",
      "ENSG00000100522\n",
      "ENSG00000206344\n",
      "ENSG00000182264\n",
      "ENSG00000182674\n",
      "ENSG00000113361\n",
      "ENSG00000206557\n",
      "ENSG00000169085\n",
      "ENSG00000286403\n",
      "ENSG00000083845\n",
      "ENSG00000225877\n",
      "ENSG00000127564\n",
      "ENSG00000271824\n",
      "ENSG00000157890\n",
      "ENSG00000179178\n",
      "ENSG00000048342\n",
      "ENSG00000072657\n",
      "ENSG00000251661\n",
      "ENSG00000184788\n",
      "ENSG00000186675\n",
      "ENSG00000282826\n",
      "ENSG00000137710\n",
      "ENSG00000135094\n",
      "ENSG00000091483\n",
      "ENSG00000174842\n",
      "ENSG00000275004\n",
      "ENSG00000171357\n",
      "ENSG00000075426\n",
      "ENSG00000228300\n",
      "ENSG00000166923\n",
      "ENSG00000149596\n",
      "ENSG00000172687\n",
      "ENSG00000280119\n",
      "ENSG00000141741\n",
      "ENSG00000162852\n",
      "ENSG00000110060\n",
      "ENSG00000272841\n",
      "ENSG00000130299\n",
      "ENSG00000152034\n",
      "ENSG00000164128\n",
      "ENSG00000170906\n",
      "ENSG00000274422\n",
      "ENSG00000237945\n",
      "ENSG00000117242\n",
      "ENSG00000152217\n",
      "ENSG00000138031\n",
      "ENSG00000204278\n",
      "ENSG00000143994\n",
      "ENSG00000276462\n",
      "ENSG00000102317\n",
      "ENSG00000228274\n",
      "ENSG00000139625\n",
      "ENSG00000160233\n",
      "ENSG00000169756\n",
      "ENSG00000286861\n",
      "ENSG00000225953\n",
      "ENSG00000146215\n",
      "ENSG00000114767\n",
      "ENSG00000169689\n",
      "ENSG00000163827\n",
      "ENSG00000116525\n",
      "ENSG00000184110\n",
      "ENSG00000183807\n",
      "ENSG00000198547\n",
      "ENSG00000157796\n",
      "ENSG00000235961\n",
      "ENSG00000273540\n",
      "ENSG00000232388\n",
      "ENSG00000134317\n",
      "ENSG00000060762\n",
      "ENSG00000128944\n",
      "ENSG00000173083\n",
      "ENSG00000165186\n",
      "ENSG00000169946\n",
      "ENSG00000278991\n",
      "ENSG00000177374\n",
      "ENSG00000166199\n",
      "ENSG00000251602\n",
      "ENSG00000198034\n",
      "ENSG00000165097\n",
      "ENSG00000275910\n",
      "ENSG00000288049\n",
      "ENSG00000148908\n",
      "ENSG00000223508\n",
      "ENSG00000139915\n",
      "ENSG00000230453\n",
      "ENSG00000083812\n",
      "ENSG00000186377\n",
      "ENSG00000000457\n",
      "ENSG00000283154\n",
      "ENSG00000004660\n",
      "ENSG00000280063\n",
      "ENSG00000167508\n",
      "ENSG00000078053\n",
      "ENSG00000146757\n",
      "ENSG00000225706\n",
      "ENSG00000197380\n",
      "ENSG00000206560\n",
      "ENSG00000168658\n",
      "ENSG00000162623\n",
      "ENSG00000100503\n",
      "ENSG00000143772\n",
      "ENSG00000076604\n",
      "ENSG00000120322\n",
      "ENSG00000165416\n",
      "ENSG00000177854\n",
      "ENSG00000130244\n",
      "ENSG00000260316\n",
      "ENSG00000276417\n",
      "ENSG00000186352\n",
      "ENSG00000196476\n",
      "ENSG00000145063\n",
      "ENSG00000115137\n",
      "ENSG00000126458\n",
      "ENSG00000126777\n",
      "ENSG00000243667\n",
      "ENSG00000115828\n",
      "ENSG00000165168\n",
      "ENSG00000245910\n",
      "ENSG00000255408\n",
      "ENSG00000010319\n",
      "ENSG00000145220\n",
      "ENSG00000179222\n",
      "ENSG00000147113\n",
      "ENSG00000126860\n",
      "ENSG00000179846\n",
      "ENSG00000118503\n",
      "ENSG00000134548\n",
      "ENSG00000167862\n",
      "ENSG00000205838\n",
      "ENSG00000132481\n",
      "ENSG00000111679\n",
      "ENSG00000149451\n",
      "ENSG00000250786\n",
      "ENSG00000079739\n",
      "ENSG00000278963\n",
      "ENSG00000131323\n",
      "ENSG00000078804\n",
      "ENSG00000135063\n",
      "ENSG00000133863\n",
      "ENSG00000237742\n",
      "ENSG00000096063\n",
      "ENSG00000268049\n",
      "ENSG00000104835\n",
      "ENSG00000084764\n",
      "ENSG00000135899\n",
      "ENSG00000227252\n",
      "ENSG00000104164\n",
      "ENSG00000100908\n",
      "ENSG00000010327\n",
      "ENSG00000141873\n",
      "ENSG00000177182\n",
      "ENSG00000175395\n",
      "ENSG00000102309\n",
      "ENSG00000204516\n",
      "ENSG00000179546\n",
      "ENSG00000168890\n",
      "ENSG00000042781\n",
      "ENSG00000184208\n",
      "ENSG00000273271\n",
      "ENSG00000075420\n",
      "ENSG00000172965\n",
      "ENSG00000126259\n",
      "ENSG00000107020\n",
      "ENSG00000232527\n",
      "ENSG00000134627\n",
      "ENSG00000254876\n",
      "ENSG00000113811\n",
      "ENSG00000100767\n",
      "ENSG00000112769\n",
      "ENSG00000172493\n",
      "ENSG00000107317\n",
      "ENSG00000115392\n",
      "ENSG00000177989\n",
      "ENSG00000198954\n",
      "ENSG00000215845\n",
      "ENSG00000173457\n",
      "ENSG00000187676\n",
      "ENSG00000116641\n",
      "ENSG00000186019\n",
      "ENSG00000125835\n",
      "ENSG00000276259\n",
      "ENSG00000101017\n",
      "ENSG00000273367\n",
      "ENSG00000276644\n",
      "ENSG00000224043\n",
      "ENSG00000134962\n",
      "ENSG00000215041\n",
      "ENSG00000196912\n",
      "ENSG00000187624\n",
      "ENSG00000237973\n",
      "ENSG00000105321\n",
      "ENSG00000244734\n",
      "ENSG00000247516\n",
      "ENSG00000196876\n",
      "ENSG00000113161\n",
      "ENSG00000133640\n",
      "ENSG00000183484\n",
      "ENSG00000163923\n",
      "ENSG00000065802\n",
      "ENSG00000273373\n",
      "ENSG00000167654\n",
      "ENSG00000161921\n",
      "ENSG00000007168\n",
      "ENSG00000138381\n",
      "ENSG00000110002\n",
      "ENSG00000151690\n",
      "ENSG00000162511\n",
      "ENSG00000198142\n",
      "ENSG00000138660\n",
      "ENSG00000197355\n",
      "ENSG00000275367\n",
      "ENSG00000226450\n",
      "ENSG00000286000\n",
      "ENSG00000269951\n",
      "ENSG00000274220\n",
      "ENSG00000087303\n",
      "ENSG00000273213\n",
      "ENSG00000178401\n",
      "ENSG00000128965\n",
      "ENSG00000203883\n",
      "ENSG00000088876\n",
      "ENSG00000108106\n",
      "ENSG00000164136\n",
      "ENSG00000133805\n",
      "ENSG00000115946\n",
      "ENSG00000160791\n",
      "ENSG00000118557\n",
      "ENSG00000234224\n",
      "ENSG00000062485\n",
      "ENSG00000099377\n",
      "ENSG00000185442\n",
      "ENSG00000104059\n",
      "ENSG00000127903\n",
      "ENSG00000181788\n",
      "ENSG00000171724\n",
      "ENSG00000213949\n",
      "ENSG00000170091\n",
      "ENSG00000158825\n",
      "ENSG00000280214\n",
      "ENSG00000054148\n",
      "ENSG00000110080\n",
      "ENSG00000169432\n",
      "ENSG00000002549\n",
      "ENSG00000272479\n",
      "ENSG00000119927\n",
      "ENSG00000152380\n",
      "ENSG00000255710\n",
      "ENSG00000235831\n",
      "ENSG00000226530\n",
      "ENSG00000278291\n",
      "ENSG00000204653\n",
      "ENSG00000136167\n",
      "ENSG00000143333\n",
      "ENSG00000095303\n",
      "ENSG00000059915\n",
      "ENSG00000135363\n",
      "ENSG00000114646\n",
      "ENSG00000005075\n",
      "ENSG00000165105\n",
      "ENSG00000271869\n",
      "ENSG00000099308\n",
      "ENSG00000186777\n",
      "ENSG00000206341\n",
      "ENSG00000272512\n",
      "ENSG00000114737\n",
      "ENSG00000198168\n",
      "ENSG00000180900\n",
      "ENSG00000184517\n",
      "ENSG00000141854\n",
      "ENSG00000179388\n",
      "ENSG00000108821\n",
      "ENSG00000155465\n",
      "ENSG00000159433\n",
      "ENSG00000128266\n",
      "ENSG00000267169\n",
      "ENSG00000166225\n",
      "ENSG00000080947\n",
      "ENSG00000273343\n",
      "ENSG00000225484\n",
      "ENSG00000069535\n",
      "ENSG00000271862\n",
      "ENSG00000268231\n",
      "ENSG00000112378\n",
      "ENSG00000160050\n",
      "ENSG00000128833\n",
      "ENSG00000197261\n",
      "ENSG00000140280\n",
      "ENSG00000198892\n",
      "ENSG00000123329\n",
      "ENSG00000139921\n",
      "ENSG00000272356\n",
      "ENSG00000186642\n",
      "ENSG00000259065\n",
      "ENSG00000196141\n",
      "ENSG00000049759\n",
      "ENSG00000154040\n",
      "ENSG00000173905\n",
      "ENSG00000272865\n",
      "ENSG00000168394\n",
      "ENSG00000100629\n",
      "ENSG00000071537\n",
      "ENSG00000163788\n",
      "ENSG00000181610\n",
      "ENSG00000119986\n",
      "ENSG00000146070\n",
      "ENSG00000153922\n",
      "ENSG00000279302\n",
      "ENSG00000187824\n",
      "ENSG00000157350\n",
      "ENSG00000063241\n",
      "ENSG00000197584\n",
      "ENSG00000012983\n",
      "ENSG00000286138\n",
      "ENSG00000099330\n",
      "ENSG00000198598\n",
      "ENSG00000198556\n",
      "ENSG00000183914\n",
      "ENSG00000197978\n",
      "ENSG00000255642\n",
      "ENSG00000264522\n",
      "ENSG00000232063\n",
      "ENSG00000115266\n",
      "ENSG00000106648\n",
      "ENSG00000073331\n",
      "ENSG00000255052\n",
      "ENSG00000147231\n",
      "ENSG00000280216\n",
      "ENSG00000165501\n",
      "ENSG00000105048\n",
      "ENSG00000006453\n",
      "ENSG00000160271\n",
      "ENSG00000116299\n",
      "ENSG00000106605\n",
      "ENSG00000235568\n",
      "ENSG00000223797\n",
      "ENSG00000130035\n",
      "ENSG00000154640\n",
      "ENSG00000115993\n",
      "ENSG00000134470\n",
      "ENSG00000177192\n",
      "ENSG00000117600\n",
      "ENSG00000132471\n",
      "ENSG00000147676\n",
      "ENSG00000183856\n",
      "ENSG00000174028\n",
      "ENSG00000260244\n",
      "ENSG00000261342\n",
      "ENSG00000225125\n",
      "ENSG00000166822\n",
      "ENSG00000253873\n",
      "ENSG00000090006\n",
      "ENSG00000109536\n",
      "ENSG00000177410\n",
      "ENSG00000152147\n",
      "ENSG00000196843\n",
      "ENSG00000233264\n",
      "ENSG00000048140\n",
      "ENSG00000150433\n",
      "ENSG00000236829\n",
      "ENSG00000231389\n",
      "ENSG00000280073\n",
      "ENSG00000196756\n",
      "ENSG00000272622\n",
      "ENSG00000267778\n",
      "ENSG00000279500\n",
      "ENSG00000086730\n",
      "ENSG00000145990\n",
      "ENSG00000197083\n",
      "ENSG00000176928\n",
      "ENSG00000185761\n",
      "ENSG00000167103\n",
      "ENSG00000163605\n",
      "ENSG00000118496\n",
      "ENSG00000144596\n",
      "ENSG00000183570\n",
      "ENSG00000143882\n",
      "ENSG00000090971\n",
      "ENSG00000111817\n",
      "ENSG00000163516\n",
      "ENSG00000108830\n",
      "ENSG00000205363\n",
      "ENSG00000116991\n",
      "ENSG00000261096\n",
      "ENSG00000226648\n",
      "ENSG00000204934\n",
      "ENSG00000126214\n",
      "ENSG00000229980\n",
      "ENSG00000213197\n",
      "ENSG00000197956\n",
      "ENSG00000165802\n",
      "ENSG00000197798\n",
      "ENSG00000181191\n",
      "ENSG00000186369\n",
      "ENSG00000021645\n",
      "ENSG00000286863\n",
      "ENSG00000115423\n",
      "ENSG00000112118\n",
      "ENSG00000080819\n",
      "ENSG00000197345\n",
      "ENSG00000233487\n",
      "ENSG00000198755\n",
      "ENSG00000235703\n",
      "ENSG00000163817\n",
      "ENSG00000198046\n",
      "ENSG00000183117\n",
      "ENSG00000147246\n",
      "ENSG00000129946\n",
      "ENSG00000205903\n",
      "ENSG00000117868\n",
      "ENSG00000235034\n",
      "ENSG00000125434\n",
      "ENSG00000127152\n",
      "ENSG00000161980\n",
      "ENSG00000233602\n",
      "ENSG00000111262\n",
      "ENSG00000233067\n",
      "ENSG00000270084\n",
      "ENSG00000198300\n",
      "ENSG00000149571\n",
      "ENSG00000188488\n",
      "ENSG00000271978\n",
      "ENSG00000173825\n",
      "ENSG00000108298\n",
      "ENSG00000136044\n",
      "ENSG00000224271\n",
      "ENSG00000095794\n",
      "ENSG00000180155\n",
      "ENSG00000183684\n",
      "ENSG00000183160\n",
      "ENSG00000136854\n",
      "ENSG00000057663\n",
      "ENSG00000064042\n",
      "ENSG00000261292\n",
      "ENSG00000065675\n",
      "ENSG00000160439\n",
      "ENSG00000184500\n",
      "ENSG00000120708\n",
      "ENSG00000189350\n",
      "ENSG00000178295\n",
      "ENSG00000286613\n",
      "ENSG00000271851\n",
      "ENSG00000183486\n",
      "ENSG00000173264\n",
      "ENSG00000227500\n",
      "ENSG00000136826\n",
      "ENSG00000215244\n",
      "ENSG00000174238\n",
      "ENSG00000146267\n",
      "ENSG00000164713\n",
      "ENSG00000139318\n",
      "ENSG00000140090\n",
      "ENSG00000184220\n",
      "ENSG00000137672\n",
      "ENSG00000273066\n",
      "ENSG00000137944\n",
      "ENSG00000160783\n",
      "ENSG00000267680\n",
      "ENSG00000125851\n",
      "ENSG00000186439\n",
      "ENSG00000163297\n",
      "ENSG00000223705\n",
      "ENSG00000234684\n",
      "ENSG00000231607\n",
      "ENSG00000273136\n",
      "ENSG00000106665\n",
      "ENSG00000228376\n",
      "ENSG00000143036\n",
      "ENSG00000139173\n",
      "ENSG00000150361\n",
      "ENSG00000256060\n",
      "ENSG00000280832\n",
      "ENSG00000166523\n",
      "ENSG00000112936\n",
      "ENSG00000114654\n",
      "ENSG00000152785\n",
      "ENSG00000102030\n",
      "ENSG00000183696\n",
      "ENSG00000124608\n",
      "ENSG00000122584\n",
      "ENSG00000204282\n",
      "ENSG00000127863\n",
      "ENSG00000268670\n",
      "ENSG00000178057\n",
      "ENSG00000253452\n",
      "ENSG00000268225\n",
      "ENSG00000188786\n",
      "ENSG00000272079\n",
      "ENSG00000100216\n",
      "ENSG00000135334\n",
      "ENSG00000106333\n",
      "ENSG00000106785\n",
      "ENSG00000138071\n",
      "ENSG00000272732\n",
      "ENSG00000233061\n",
      "ENSG00000261340\n",
      "ENSG00000230303\n",
      "ENSG00000138821\n",
      "ENSG00000127337\n",
      "ENSG00000180035\n",
      "ENSG00000248508\n",
      "ENSG00000253875\n",
      "ENSG00000139637\n",
      "ENSG00000183527\n",
      "ENSG00000122420\n",
      "ENSG00000058272\n",
      "ENSG00000239306\n",
      "ENSG00000176681\n",
      "ENSG00000105339\n",
      "ENSG00000279133\n",
      "ENSG00000268858\n",
      "ENSG00000270164\n",
      "ENSG00000215305\n",
      "ENSG00000080561\n",
      "ENSG00000068079\n",
      "ENSG00000279923\n",
      "ENSG00000160213\n",
      "ENSG00000146966\n",
      "ENSG00000245146\n",
      "ENSG00000267002\n",
      "ENSG00000137198\n",
      "ENSG00000102466\n",
      "ENSG00000282608\n",
      "ENSG00000141441\n",
      "ENSG00000127507\n",
      "ENSG00000136404\n",
      "ENSG00000125912\n",
      "ENSG00000134490\n",
      "ENSG00000259868\n",
      "ENSG00000168283\n",
      "ENSG00000123810\n",
      "ENSG00000163818\n",
      "ENSG00000260992\n",
      "ENSG00000107796\n",
      "ENSG00000228113\n",
      "ENSG00000180257\n",
      "ENSG00000286198\n",
      "ENSG00000140264\n",
      "ENSG00000277938\n",
      "ENSG00000181544\n",
      "ENSG00000205885\n",
      "ENSG00000134201\n",
      "ENSG00000119772\n",
      "ENSG00000168874\n",
      "ENSG00000206052\n",
      "ENSG00000278949\n",
      "ENSG00000198589\n",
      "ENSG00000275131\n",
      "ENSG00000164620\n",
      "ENSG00000133138\n",
      "ENSG00000271425\n",
      "ENSG00000224222\n",
      "ENSG00000117114\n",
      "ENSG00000255717\n",
      "ENSG00000286654\n",
      "ENSG00000137124\n",
      "ENSG00000166123\n",
      "ENSG00000134755\n",
      "ENSG00000197429\n",
      "ENSG00000169439\n",
      "ENSG00000148488\n",
      "ENSG00000215302\n",
      "ENSG00000166426\n",
      "ENSG00000082014\n",
      "ENSG00000205212\n",
      "ENSG00000090905\n",
      "ENSG00000256422\n",
      "ENSG00000276071\n",
      "ENSG00000165338\n",
      "ENSG00000123473\n",
      "ENSG00000123358\n",
      "ENSG00000077092\n",
      "ENSG00000263327\n",
      "ENSG00000007384\n",
      "ENSG00000248429\n",
      "ENSG00000247934\n",
      "ENSG00000070886\n",
      "ENSG00000175040\n",
      "ENSG00000254685\n",
      "ENSG00000018280\n",
      "ENSG00000179277\n",
      "ENSG00000106733\n",
      "ENSG00000260314\n",
      "ENSG00000157326\n",
      "ENSG00000277399\n",
      "ENSG00000286084\n",
      "ENSG00000205959\n",
      "ENSG00000269821\n",
      "ENSG00000163634\n",
      "ENSG00000126953\n",
      "ENSG00000279092\n",
      "ENSG00000132182\n",
      "ENSG00000253807\n",
      "ENSG00000163406\n",
      "ENSG00000145331\n",
      "ENSG00000115109\n",
      "ENSG00000267348\n",
      "ENSG00000103269\n",
      "ENSG00000109771\n",
      "ENSG00000133019\n",
      "ENSG00000266489\n",
      "ENSG00000260947\n",
      "ENSG00000171121\n",
      "ENSG00000073849\n",
      "ENSG00000101447\n",
      "ENSG00000134824\n",
      "ENSG00000077713\n",
      "ENSG00000108684\n",
      "ENSG00000101680\n",
      "ENSG00000166578\n",
      "ENSG00000083937\n",
      "ENSG00000181418\n",
      "ENSG00000173275\n",
      "ENSG00000261728\n",
      "ENSG00000103168\n",
      "ENSG00000119714\n",
      "ENSG00000187193\n",
      "ENSG00000166510\n",
      "ENSG00000229180\n",
      "ENSG00000156140\n",
      "ENSG00000280339\n",
      "ENSG00000148291\n",
      "ENSG00000130222\n",
      "ENSG00000264589\n",
      "ENSG00000163110\n",
      "ENSG00000119917\n",
      "ENSG00000248540\n",
      "ENSG00000272010\n",
      "ENSG00000287837\n",
      "ENSG00000206140\n",
      "ENSG00000278558\n",
      "ENSG00000260898\n",
      "ENSG00000173511\n",
      "ENSG00000162972\n",
      "ENSG00000154975\n",
      "ENSG00000269929\n",
      "ENSG00000141968\n",
      "ENSG00000164089\n",
      "ENSG00000095059\n",
      "ENSG00000171044\n",
      "ENSG00000286196\n",
      "ENSG00000198585\n",
      "ENSG00000061273\n",
      "ENSG00000255693\n",
      "ENSG00000167693\n",
      "ENSG00000106018\n",
      "ENSG00000158769\n",
      "ENSG00000166340\n",
      "ENSG00000102984\n",
      "ENSG00000265018\n",
      "ENSG00000162377\n",
      "ENSG00000026297\n",
      "ENSG00000224424\n",
      "ENSG00000253704\n",
      "ENSG00000140015\n",
      "ENSG00000168918\n",
      "ENSG00000156239\n",
      "ENSG00000143786\n",
      "ENSG00000230445\n",
      "ENSG00000151726\n",
      "ENSG00000116984\n",
      "ENSG00000160678\n",
      "ENSG00000151655\n",
      "ENSG00000249853\n",
      "ENSG00000084093\n",
      "ENSG00000198324\n",
      "ENSG00000228623\n",
      "ENSG00000143891\n",
      "ENSG00000182575\n",
      "ENSG00000019582\n",
      "ENSG00000231768\n",
      "ENSG00000158869\n",
      "ENSG00000258875\n",
      "ENSG00000261167\n",
      "ENSG00000090238\n",
      "ENSG00000155307\n",
      "ENSG00000175985\n",
      "ENSG00000162777\n",
      "ENSG00000205559\n",
      "ENSG00000141577\n",
      "ENSG00000232956\n",
      "ENSG00000260895\n",
      "ENSG00000169035\n",
      "ENSG00000230701\n",
      "ENSG00000123338\n",
      "ENSG00000125520\n",
      "ENSG00000261115\n",
      "ENSG00000112578\n",
      "ENSG00000239911\n",
      "ENSG00000256229\n",
      "ENSG00000128272\n",
      "ENSG00000008517\n",
      "ENSG00000153179\n",
      "ENSG00000286523\n",
      "ENSG00000115844\n",
      "ENSG00000249459\n",
      "ENSG00000137561\n",
      "ENSG00000167306\n",
      "ENSG00000162433\n",
      "ENSG00000126945\n",
      "ENSG00000232656\n",
      "ENSG00000279555\n",
      "ENSG00000198580\n",
      "ENSG00000131378\n",
      "ENSG00000270362\n",
      "ENSG00000168385\n",
      "ENSG00000246375\n",
      "ENSG00000172458\n",
      "ENSG00000196421\n",
      "ENSG00000198039\n",
      "ENSG00000253767\n",
      "ENSG00000164236\n",
      "ENSG00000159069\n",
      "ENSG00000163823\n",
      "ENSG00000179941\n",
      "ENSG00000187609\n",
      "ENSG00000100197\n",
      "ENSG00000117472\n",
      "ENSG00000100156\n",
      "ENSG00000174669\n",
      "ENSG00000141519\n",
      "ENSG00000279162\n",
      "ENSG00000237172\n",
      "ENSG00000152082\n",
      "ENSG00000213640\n",
      "ENSG00000182508\n",
      "ENSG00000166741\n",
      "ENSG00000129151\n",
      "ENSG00000173269\n",
      "ENSG00000286220\n",
      "ENSG00000132718\n",
      "ENSG00000263069\n",
      "ENSG00000143815\n",
      "ENSG00000175928\n",
      "ENSG00000109586\n",
      "ENSG00000161267\n",
      "ENSG00000138074\n",
      "ENSG00000180353\n",
      "ENSG00000149131\n",
      "ENSG00000249115\n",
      "ENSG00000119125\n",
      "ENSG00000234899\n",
      "ENSG00000114861\n",
      "ENSG00000260426\n",
      "ENSG00000233221\n",
      "ENSG00000146067\n",
      "ENSG00000154734\n",
      "ENSG00000163344\n",
      "ENSG00000152049\n",
      "ENSG00000185986\n",
      "ENSG00000103148\n",
      "ENSG00000188493\n",
      "ENSG00000070669\n",
      "ENSG00000134248\n",
      "ENSG00000146232\n",
      "ENSG00000175356\n",
      "ENSG00000115935\n",
      "ENSG00000104043\n",
      "ENSG00000123243\n",
      "ENSG00000152583\n",
      "ENSG00000116473\n",
      "ENSG00000133460\n",
      "ENSG00000268001\n",
      "ENSG00000136250\n",
      "ENSG00000119574\n",
      "ENSG00000159216\n",
      "ENSG00000086619\n",
      "ENSG00000136997\n"
     ]
    }
   ],
   "source": [
    "# Extracting SHAP values for sample 72\n",
    "sample_shap_values = filtered_results[176]['shap_values']\n",
    "\n",
    "# Filtering positive SHAP values and sorting them in descending order\n",
    "positive_shap_values = {gene: shap_value for gene, shap_value in sample_shap_values.items() if shap_value > 0}\n",
    "sorted_positive_shap_values = sorted(positive_shap_values.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Getting the top 200 gene names\n",
    "top_200_genes = [gene for gene, shap_value in sorted_positive_shap_values[:2900]]\n",
    "\n",
    "for gene in top_200_genes:\n",
    "    print(gene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting gene Ensemble IDs to Enterez ID for EnrichR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699ccc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_path = 'ROSMAP_counts_v7.csv'\n",
    "X = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "metadata = pd.read_csv('./metadata_v6_rosmap.csv', index_col=0)\n",
    "y = metadata['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65022252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMEM107\n",
      "DDX60\n",
      "DPYSL3\n",
      "REXO5\n",
      "LOC119746555\n",
      "PPP1R1A\n",
      "PEMT\n",
      "NDUFC1\n",
      "NBEAP2\n",
      "TMSB10\n",
      "CDPF1\n",
      "LMAN2\n",
      "SLC32A1\n",
      "NDUFS6\n",
      "B3GALT5\n",
      "DKFZp451B082\n",
      "MMRN1\n",
      "LOC105373429\n",
      "NAV1\n",
      "RHBDL2\n",
      "TAF1A-AS1\n",
      "GIPR\n",
      "LOC107984948\n",
      "SMAD7\n",
      "CORIN\n",
      "NELL2\n",
      "IFT27\n",
      "ACSM5\n",
      "ANGPT1\n",
      "PAK6\n",
      "BUB1B-PAK6\n",
      "LRCH4\n",
      "NCF2\n",
      "NPIPB3\n",
      "G0S2\n",
      "FOXN3\n",
      "CAB39L\n",
      "FUBP1\n",
      "TF\n",
      "LCMT1\n",
      "LNCOC1\n",
      "MRPS6\n",
      "DGCR11\n",
      "ADK\n",
      "NDUFB5\n",
      "CHD3\n",
      "CPM\n",
      "DPYS\n",
      "LOC101928416\n",
      "SGSM3\n",
      "RPL10\n",
      "FOXRED2\n",
      "SLC20A1\n",
      "LINC01410\n",
      "ZNF93\n",
      "SLC2A3\n",
      "TRIM16\n",
      "YIF1A\n",
      "PAFAH1B3\n",
      "GFOD2\n",
      "PIGX\n",
      "RPS6KA5\n",
      "NTNG1\n",
      "VCL\n",
      "RAB34\n",
      "EPHA10\n",
      "SORCS1\n",
      "LOC102724023\n",
      "TNFRSF10D\n",
      "NNT\n",
      "MYCN\n",
      "RPL12\n",
      "PAX8\n",
      "SYPL2\n",
      "LINC00847\n",
      "COL6A2\n",
      "IQANK1\n",
      "PRCD\n",
      "CXCL5\n",
      "HEXIM1\n",
      "ADNP-AS1\n",
      "SERHL2\n",
      "C6orf62\n",
      "HTR6\n",
      "KEL\n",
      "JPX\n",
      "RERG\n",
      "IRS1\n",
      "PRKG1\n",
      "RNMT\n",
      "PRDM1\n",
      "COL14A1\n",
      "ADD3\n",
      "FUT9\n",
      "ATP6V0E2\n",
      "HMGN2\n",
      "SPATA6\n",
      "TMEFF2\n",
      "KCTD21-AS1\n",
      "FBXL7\n",
      "RPL3\n",
      "SYNM\n",
      "ZBTB40\n",
      "MTMR2\n",
      "NDE1\n",
      "CSKMT\n",
      "NCBP1\n",
      "PAX7\n",
      "APLN\n",
      "CCDC69\n",
      "DYDC2\n",
      "NR2F1\n",
      "POLD1\n",
      "LRRC10B\n",
      "ZDHHC12-DT\n",
      "FAM182A\n",
      "OLIG1\n",
      "PEX16\n",
      "FBLN2\n",
      "PLXDC2\n",
      "TREM2\n",
      "DUSP23\n",
      "DDX3Y\n",
      "TXNRD3\n",
      "GTF2IRD2B\n",
      "C1QTNF4\n",
      "CD109\n",
      "PARD6G-AS1\n",
      "KLHL17\n",
      "SPMIP1\n",
      "SERPINI1\n",
      "PPP5C\n",
      "P2RX7\n",
      "LGI2\n",
      "CD44\n",
      "RNASEL\n",
      "MEF2C-AS1\n",
      "MYL6B\n",
      "FAM217B\n",
      "LPIN3\n",
      "VCAM1\n",
      "FOXO4\n",
      "LRPPRC\n",
      "ZFP91\n",
      "BCDIN3D\n",
      "ACTG1\n",
      "NLRP1\n",
      "TBC1D12\n",
      "SERGEF\n",
      "SLC9A1\n",
      "PDIA4\n",
      "RBKS\n",
      "PDXDC2P-NPIPB14P\n",
      "LRRN3\n",
      "RMDN1\n",
      "UBA5\n",
      "CEBPA-DT\n",
      "DHFR\n",
      "VAMP1\n",
      "CRY2\n",
      "CHFR\n",
      "MAP1LC3B2\n",
      "SLC4A1AP\n",
      "GAREM2\n",
      "EPM2A-DT\n",
      "ESRRG\n",
      "BTF3L4\n",
      "LINC01948\n",
      "HPR\n",
      "GATB\n",
      "PRAF2\n",
      "LOC101927480\n",
      "CRNDE\n",
      "ZNF69\n",
      "PGGHG\n",
      "COX20\n",
      "PTER\n",
      "POMZP3\n",
      "ABCA2\n",
      "WRAP53\n",
      "IMP3\n",
      "S1PR3\n",
      "MKLN1-AS\n",
      "MEG3\n",
      "FMNL2\n",
      "DRAP1\n",
      "TMEM132E-DT\n",
      "LONRF3\n",
      "MT1F\n",
      "SNHG8\n",
      "R3HDM2\n",
      "SLC13A5\n",
      "METTL1\n",
      "ARRB2\n",
      "ZBTB8A\n",
      "PRKN\n",
      "KLHDC2\n",
      "SEMA4D\n",
      "PAPSS2\n",
      "PFKP\n",
      "ZNF784\n",
      "ATL2\n",
      "SLC25A48\n",
      "SOAT1\n",
      "SYTL3\n",
      "CHST6\n",
      "CCNE1\n",
      "KCTD2\n",
      "KIFC2\n",
      "ENKUR\n",
      "C2orf73\n",
      "TIMELESS\n",
      "ENTPD6\n",
      "DYNC1H1\n",
      "NRARP\n",
      "RABGGTA\n",
      "RIPPLY2\n",
      "IL17RD\n",
      "ANAPC4\n",
      "PPP1R3B\n",
      "ZNF442\n",
      "ZNF215\n",
      "FAM174A\n",
      "PSTPIP2\n",
      "CLEC1A\n",
      "BEGAIN\n",
      "ADORA1\n",
      "SLCO1A2\n",
      "CDK13-DT\n",
      "PRELP\n",
      "CXCR4\n",
      "C2orf88\n",
      "PIRT\n",
      "MAPK8\n",
      "SIGLEC9\n",
      "PIAS4\n",
      "ARC\n",
      "ZNF138\n",
      "IFIH1\n",
      "ENOX2\n",
      "HBA2\n",
      "ZC3H12C\n",
      "HMGB2\n",
      "TMSB4Y\n",
      "PELO\n",
      "TMEM63A\n",
      "STARD3\n",
      "BNC2\n",
      "TG\n",
      "ATAD1\n",
      "C7orf25\n",
      "SHD\n",
      "A2ML1\n",
      "GUCY1A1\n",
      "ARHGEF6\n",
      "COX8A\n",
      "KCNIP4-IT1\n",
      "SLC25A13\n",
      "SPP1\n",
      "CCN1\n",
      "MARF1\n",
      "PIK3R3\n",
      "CIB1\n",
      "GPSM2\n",
      "PLSCR1\n",
      "C3orf62\n",
      "NELFA\n",
      "CYBA\n",
      "ATP4A\n",
      "GJA1\n",
      "SOX21\n",
      "ZNF763\n",
      "GPX3\n",
      "LBH\n",
      "CYP2C8\n",
      "LRRC1\n",
      "CCNJL\n",
      "LINC01012\n",
      "DNAH7\n",
      "ANKRD30BL\n",
      "COL4A1\n",
      "YPEL4\n",
      "GINS3\n",
      "SLC16A6\n",
      "VGF\n",
      "LOC105372401\n",
      "ZNF441\n",
      "OLMALINC\n",
      "LINC01736\n",
      "PKD2\n",
      "TTTY15\n",
      "USP9Y\n",
      "GJB2\n",
      "SLC16A14\n",
      "CLCN7\n",
      "ROM1\n",
      "LINC03002\n",
      "HEPACAM\n",
      "FOXJ1\n",
      "CRTC1\n",
      "CD99L2\n",
      "PHYHD1\n",
      "QDPR\n",
      "ZNF367\n",
      "SLC4A11\n",
      "CPLX1\n",
      "MRAS\n",
      "CDHR3\n",
      "FKBP10\n",
      "GAS5\n",
      "IGFBP4\n",
      "SCG3\n",
      "ZNF792\n",
      "BHLHE41\n",
      "TMEM39A\n",
      "PCDH11Y\n",
      "PLCG1\n",
      "FIRRM\n",
      "HAVCR2\n",
      "PTCH2\n",
      "SLC25A21-AS1\n",
      "CYB561D2\n",
      "SMOX\n",
      "POLG2\n",
      "HLA-DPB1\n",
      "EPOR\n",
      "OTUD4\n",
      "SHLD3\n",
      "DHRS11\n",
      "DDX28\n",
      "MT1M\n",
      "LZTS2\n",
      "FANCC\n",
      "LOC105376156\n",
      "MYL3\n",
      "TMBIM6\n",
      "C2orf92\n",
      "EGF\n",
      "CTH\n",
      "EDIL3\n",
      "HSP90B1\n",
      "RRAD\n",
      "TCTN2\n",
      "THAP9-AS1\n",
      "PDE4DIP\n",
      "MACIR\n",
      "GPATCH4\n",
      "PRR13\n",
      "TRIO\n",
      "SAPCD2\n",
      "PSMB8-AS1\n",
      "TRAM2\n",
      "GFRA2\n",
      "RANBP3L\n",
      "TSPAN5\n",
      "CDH3\n",
      "SDSL\n",
      "RAPGEF4-AS1\n",
      "RASGRP3-AS1\n",
      "FAM98A\n",
      "GOLM1\n",
      "HS2ST1\n",
      "TMEM88B\n",
      "SRPX2\n",
      "MTUS1-DT\n",
      "ALKBH6\n",
      "FAM107A\n",
      "ELL\n",
      "UBAP1L\n",
      "CENPE\n",
      "TFDP2\n",
      "PLEKHM2\n",
      "MOBP\n",
      "PCDHGB5\n",
      "GPC3\n",
      "SLC12A5\n",
      "MKRN3\n",
      "ARRDC2\n",
      "ZMYND8\n",
      "ZFHX2\n",
      "RBP1\n",
      "GLI1\n",
      "LST1\n",
      "PPFIBP2\n",
      "SNRNP48\n",
      "PCDH17\n",
      "ST18\n",
      "ADAT2\n",
      "HYOU1\n",
      "SLC25A25\n",
      "LOC102724159\n",
      "CD4\n",
      "HOMER3\n",
      "LOC100289518\n",
      "NAMPT\n",
      "C1QTNF1\n",
      "LINC01772\n",
      "FRMPD3\n",
      "HCG25\n",
      "LOC105370259\n",
      "PDP2\n",
      "MCM4\n",
      "FKBP5\n",
      "MRPL18\n",
      "GSTA4\n",
      "OCIAD1\n",
      "COL22A1\n",
      "SNU13\n",
      "CUL2\n",
      "PREX1\n",
      "RSPO3\n",
      "PRPS1\n",
      "AZGP1\n",
      "SERPINB6\n",
      "DNAJC3\n",
      "MZF1\n",
      "NRM\n",
      "C8orf34\n",
      "LINC00092\n",
      "LOC105376159\n",
      "PDE8B\n",
      "LRRC73\n",
      "RNFT1\n",
      "MTCL2\n",
      "UNC13D\n",
      "APOD\n",
      "SLC25A37\n",
      "DOCK5\n",
      "SNN\n",
      "MIGA1\n",
      "ACER2\n",
      "SST\n",
      "VARS2\n",
      "TRAPPC6A\n",
      "GLUD2\n",
      "SPATA31H1\n",
      "GRIPAP1\n",
      "FRMD6\n",
      "MAP3K7CL\n",
      "ABTB1\n",
      "DCAKD\n",
      "CREBZF\n",
      "LOC100289230\n",
      "CHD1-DT\n",
      "LINC01166\n",
      "BEX4\n",
      "RAB36\n",
      "FAM153CP\n",
      "FEN1\n",
      "POLDIP3\n",
      "SV2C\n",
      "CHRM5\n",
      "NDUFA6\n",
      "MARCHF11\n",
      "UTY\n",
      "GCSH\n",
      "SDHAF4\n",
      "SPDYA\n",
      "GABRQ\n",
      "MDK\n",
      "MGP\n",
      "DLGAP1\n",
      "LY6G5C\n",
      "IL1B\n",
      "NECAB1\n",
      "PPDPF\n",
      "SDCBP2\n",
      "SPACA6\n",
      "APOBR\n",
      "GPCPD1\n",
      "SRARP\n",
      "PLIN5\n",
      "GABPB1-IT1\n",
      "DDX3X\n",
      "MATN3\n",
      "MCM6\n",
      "GM2A\n",
      "DLX6\n",
      "GIPC2\n",
      "MZT1\n",
      "SH3PXD2B\n",
      "COL27A1\n",
      "FER1L6-AS2\n",
      "ZNF385A\n",
      "DNAL4\n",
      "PPP1R12C\n",
      "ANGPT2\n",
      "SPC24\n",
      "PLPP5\n",
      "DDIT4L\n",
      "FOSB\n",
      "NT5E\n",
      "FGFBP3\n",
      "GMDS\n",
      "AIDAP2\n",
      "RND3\n",
      "PNMA1\n",
      "KIF5C\n",
      "RESF1\n",
      "LINC02615\n",
      "ATF5\n",
      "ZNF208\n",
      "RPAP2\n",
      "TRAP1\n",
      "RCVRN\n",
      "IP6K3\n",
      "FAM89A\n",
      "MAP7\n",
      "SUCO\n",
      "HECA\n",
      "AIF1\n",
      "SLC37A4\n",
      "COL11A1\n",
      "HSPB7\n",
      "INSM1\n",
      "GPAA1\n",
      "SLC6A9\n",
      "POLR3A\n",
      "EFHC2\n",
      "TCIM\n",
      "GLIPR2\n",
      "SDC3\n",
      "ARMCX5\n",
      "KLHDC9\n",
      "THNSL1\n",
      "CPVL-AS2\n",
      "TIPRL\n",
      "POGK\n",
      "TSSK6\n",
      "SNCA\n",
      "DBI\n",
      "TLR4\n",
      "FAM163B\n",
      "AIFM2\n",
      "PITPNM1\n",
      "CC2D1A\n",
      "LOC401442\n",
      "ADAMTSL3\n",
      "TPT1\n",
      "HSD17B8\n",
      "OLFM4\n",
      "RNF43\n",
      "TRIP10\n",
      "RFLNB\n",
      "INSYN2A\n",
      "DBN1\n",
      "RCC1\n",
      "SHCBP1\n",
      "GEM\n",
      "STARD8\n",
      "MAN2A2\n",
      "GDPD2\n",
      "TDRP\n",
      "MME\n",
      "MTG1\n",
      "TOM1L1\n",
      "NAA20\n",
      "SLC18B1\n",
      "EFCAB5\n",
      "RPS10\n",
      "SCARA3\n",
      "RGS1\n",
      "MRPL30\n",
      "AP2M1\n",
      "LINC00515\n",
      "C12orf75\n",
      "PTPN13\n",
      "CDK2AP1\n",
      "ERCC6L2-AS1\n",
      "CSDC2\n",
      "MRPL2\n",
      "PNOC\n",
      "ADAMTSL2\n",
      "ITGA10\n",
      "ALG14\n",
      "HSPA2\n",
      "ARHGAP19\n",
      "DNALI1\n",
      "RAPGEF4\n",
      "SMC1A\n",
      "ALAS1\n",
      "KIF13B\n",
      "ZNF652\n",
      "EFNA3\n",
      "GCKR\n",
      "MYORG\n",
      "EPCIP\n",
      "MTMR10\n",
      "NUDT2\n",
      "C1orf162\n",
      "FCGR3A\n",
      "TBX18\n",
      "SP2-AS1\n",
      "ATP5MJ\n",
      "SH2D6\n",
      "BOK\n",
      "BMAL1\n",
      "LINC01265\n",
      "LAMTOR5-AS1\n",
      "NYAP1\n",
      "SLC22A14\n",
      "DLC1\n",
      "ARHGAP30\n",
      "SNAI3\n",
      "GAB1\n",
      "LDLRAP1\n",
      "OMD\n",
      "MS4A7\n",
      "DEPTOR\n",
      "MT-ND2\n",
      "SYNJ2\n",
      "MAPK15\n",
      "SPOCK3\n",
      "SAFB2\n",
      "RUNX2\n",
      "RPH3A\n",
      "EIF2AK3-DT\n",
      "LRRC58\n",
      "PTPN21\n",
      "TMEM209\n",
      "THAP10\n",
      "EDA\n",
      "FGF17\n",
      "CEDORA\n",
      "COLGALT2\n",
      "CYBC1\n",
      "SASS6\n",
      "CCDC160\n",
      "SCD\n",
      "RPLP0\n",
      "MRI1\n",
      "ARHGEF10L\n",
      "GOLT1B\n",
      "ZCCHC18\n",
      "ZNF552\n",
      "HLA-DRB1\n",
      "TEX26\n",
      "DBNDD1\n",
      "SPAG4\n",
      "TMSB4XP4\n",
      "PI16\n",
      "FBXO10\n",
      "PLCE1\n",
      "CNTN2\n",
      "CFAP20DC\n",
      "SMIM3\n",
      "ARHGAP10\n",
      "EMP3\n",
      "PHKG1\n",
      "NAGLU\n",
      "TUBGCP6\n",
      "HSD17B12\n",
      "SNTB1\n",
      "TGFB3\n",
      "PLGLB1\n",
      "C17orf107\n",
      "IRF2-DT\n",
      "AGFG2\n",
      "LINC01007\n",
      "LOC730183\n",
      "MRPL44\n",
      "ZNF727\n",
      "APLNR\n",
      "VLDLR-AS1\n",
      "THBS2\n",
      "BEND5\n",
      "FZD9\n",
      "LGMN\n",
      "ZRANB3\n",
      "MARCHF8\n",
      "FBN3\n",
      "SPRED3\n",
      "ANKRD2\n",
      "ZNF77\n",
      "ZNF619\n",
      "MPP7\n",
      "KIF5A\n",
      "WDHD1\n",
      "PKN2-AS1\n",
      "SASH1\n",
      "TMEM79\n",
      "ARHGAP42\n",
      "STAC3\n",
      "ADGRB2\n",
      "MIR3667HG\n",
      "LRRC51\n",
      "TNS2-AS1\n",
      "CNTNAP1\n",
      "SLC1A1\n",
      "PTPRO\n",
      "LTBP1\n",
      "OLFM1\n",
      "BMPR1A\n",
      "CCNI2\n",
      "SLC25A53\n",
      "NEAT1\n",
      "DYNC2LI1\n",
      "SEC24B-AS1\n",
      "HSPB6\n",
      "OTOF\n",
      "RMC1\n",
      "RPL31P46\n",
      "STARD4\n",
      "SHH\n",
      "PIR\n",
      "NOX5\n",
      "TPST1\n",
      "PSTPIP1\n",
      "FAM83H\n",
      "TRPV3\n",
      "ACTB\n",
      "LOC107986669\n",
      "EIF1AY\n",
      "MT-ND6\n",
      "HSDL1\n",
      "LLGL1\n",
      "NRIP3\n",
      "MYL12B\n",
      "SLC10A7\n",
      "TFPI\n",
      "SSC5D\n",
      "ADAMTS8\n",
      "SRRM2\n",
      "HSD11B1L\n",
      "ILVBL\n",
      "SYDE1\n",
      "PPFIA1\n",
      "ZNF385C\n",
      "SYTL1\n",
      "SEC31B\n",
      "COMT\n",
      "PRKCQ-AS1\n",
      "SH3BGRL2\n",
      "EGR1\n",
      "RTTN\n",
      "DNASE1\n",
      "ASCL1\n",
      "FLYWCH1\n",
      "PKP1\n",
      "PLD4\n",
      "IDNK\n",
      "SDF2L1\n",
      "NTN3\n",
      "PDE8A\n",
      "TSPAN11\n",
      "SHISA2\n",
      "PANK1\n",
      "SLC17A9\n",
      "CDH23\n",
      "RAI14\n",
      "PLEKHA4\n",
      "STMP1\n",
      "IL1RL2\n",
      "ACVRL1\n",
      "LOC100128966\n",
      "FAM53C\n",
      "FAM162A\n",
      "MAPKAPK5-AS1\n",
      "AAMDC\n",
      "CSRP1\n",
      "ZNF37A\n",
      "BLOC1S2\n",
      "RENBP\n",
      "DOK4\n",
      "HAPLN2\n",
      "ATAD3C\n",
      "AMOTL2\n",
      "FLNB\n",
      "LINC00632\n",
      "TCTN3\n",
      "IFT172\n",
      "CERT1\n",
      "NRL\n",
      "SPRYD3\n",
      "MAK16\n",
      "DSCAML1\n",
      "MLYCD\n",
      "LOC100130691\n",
      "ID3\n",
      "ANKRD40\n",
      "SSH1\n",
      "LUZP2\n",
      "MT2A\n",
      "HDAC9\n",
      "PSMB3\n",
      "MT1G\n",
      "TRBC2\n",
      "ADAM28\n",
      "ARHGAP15\n",
      "PLEC\n",
      "TP53I3\n",
      "H2BC6\n",
      "SC5D\n",
      "MXI1\n",
      "ZNF430\n",
      "UBIAD1\n",
      "DUSP2\n",
      "PPP1CC\n",
      "KCND1\n",
      "MLKL\n",
      "VENTX\n",
      "SLC35G1\n",
      "USP44\n",
      "THUMPD3-AS1\n",
      "KRT5\n",
      "ITPRID2\n",
      "IFIT2\n",
      "UQCRHL\n",
      "TIGD6\n",
      "DKK3\n",
      "RLBP1\n",
      "GJC1\n",
      "CARD10\n",
      "HECW1\n",
      "SIRPA\n",
      "ACACB\n",
      "ARRDC3\n",
      "FANCE\n",
      "PLSCR4\n",
      "BSN\n",
      "PID1\n",
      "LMNB1\n",
      "SLC6A12\n",
      "HSPA1B\n",
      "NLGN2\n",
      "LINC00499\n",
      "CAPN15\n",
      "RAE1\n",
      "RNF182\n",
      "HAPLN3\n",
      "BMP4\n",
      "LINC03051\n",
      "CCNB1\n",
      "DTX1\n",
      "LPAR2\n",
      "FBXO2\n",
      "TRPM3\n",
      "RNASEH2C\n",
      "PCDH10\n",
      "SAMD14\n",
      "SLC38A2\n",
      "TAF1D\n",
      "PCK1\n",
      "CACNG5\n",
      "FMNL1\n",
      "OR7C1\n",
      "WIF1\n",
      "MBNL3\n",
      "LOC105371115\n",
      "NRSN1\n",
      "BABAM2\n",
      "LINC02696\n",
      "SPARC\n",
      "MRGPRF\n",
      "ZNF274\n",
      "MRM1\n",
      "MID1IP1\n",
      "MRPS12\n",
      "GOLGA8N\n",
      "NWD1\n",
      "GRK3\n",
      "PRAG1\n",
      "DNAH5\n",
      "LRIG2-DT\n",
      "DDIT4\n",
      "PLPPR3\n",
      "NDUFA1\n",
      "ULK1\n",
      "ODC1\n",
      "PTMS\n",
      "C3AR1\n",
      "TTC7A\n",
      "JUP\n",
      "LOC101930071\n",
      "LIPE-AS1\n",
      "GPR37\n",
      "VPS37B\n",
      "VEZF1\n",
      "JPT1\n",
      "AQP6\n",
      "EZR\n",
      "PTRHD1\n",
      "SLAIN1\n",
      "ADRA1D\n",
      "VIM2P\n",
      "FAM218A\n",
      "ENDOG\n",
      "SLC39A11\n",
      "LOC400553\n",
      "MRO\n",
      "RAB11A\n",
      "CCDC175\n",
      "LOC105369147\n",
      "PLCH2\n",
      "BCAS4\n",
      "NOL3\n",
      "DOT1L\n",
      "CRH\n",
      "CHCHD7\n",
      "CLDND1\n",
      "SERPINI2\n",
      "ZNF488\n",
      "CD101\n",
      "TRIM23\n",
      "WWP1\n",
      "ORAI2\n",
      "ZNF433-AS1\n",
      "SCN5A\n",
      "SMG1P1\n",
      "LOC101927055\n",
      "TTN-AS1\n",
      "LRRTM2\n",
      "SCUBE1\n",
      "MYCBPAP\n",
      "ERF\n",
      "APBB1IP\n",
      "DLEC1\n",
      "IL34\n",
      "SAMD4A\n",
      "FLNA\n",
      "ARGLU1-DT\n",
      "PDE7B\n",
      "DDX39A\n",
      "PRDX4\n",
      "ST6GAL2\n",
      "PRODH\n",
      "PPM1F\n",
      "IL17RB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from the text file\n",
    "df = pd.read_csv('/home/vmottaqi/rnaseq_synapse/enterez.txt', sep='\\t', header=None)  # Adjust the separator if needed\n",
    "\n",
    "# Select the second column (excluding the first row) and print each value on a new line\n",
    "for value in df.iloc[1:, 1]:\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8964c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f63de0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('shap_values_18_13k_clinical.pkl', 'rb') as f:\n",
    "    filtered_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27ee3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average predictive score among correctly classified patients: 0.7222770398481974\n",
      "Average predictive score among all patients: 0.6820325203252032\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Calculate the average predictive score among correctly classified patients\n",
    "average_score_correct_patients = np.mean([value['predictive_score'] for value in filtered_dict.values() if value['label'] == 1 and value['correct']])\n",
    "\n",
    "# Calculate the average predictive score among all patients\n",
    "average_score_all_patients = np.mean([value['predictive_score'] for value in filtered_dict.values() if value['label'] == 1])\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average predictive score among correctly classified patients:\", average_score_correct_patients)\n",
    "print(\"Average predictive score among all patients:\", average_score_all_patients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14576f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly classified patients with a prediction score higher than average: 260\n",
      "Number of correctly classified patients with a prediction score not higher than average: 267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the average predictive score among correctly classified patients\n",
    "average_score_correct_patients = np.mean([value['predictive_score'] for value in filtered_dict.values() if value['label'] == 1 and value['correct']])\n",
    "\n",
    "# Count the number of correctly classified patients with a prediction score higher than average\n",
    "num_correct_above_average = sum(1 for value in filtered_dict.values() if value['label'] == 1 and value['correct'] and value['predictive_score'] > average_score_correct_patients)\n",
    "\n",
    "# Count the number of correctly classified patients with a prediction score not higher than average\n",
    "num_correct_not_above_average = sum(1 for value in filtered_dict.values() if value['label'] == 1 and value['correct'] and value['predictive_score'] <= average_score_correct_patients)\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of correctly classified patients with a prediction score higher than average:\", num_correct_above_average)\n",
    "print(\"Number of correctly classified patients with a prediction score not higher than average:\", num_correct_not_above_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03bd96ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common genes among correctly classified patients:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store the sets of gene names with positive SHAP values for each correctly classified patient\n",
    "positive_genes_sets = [set(gene for gene, shap_value in value['shap_values'].items() if shap_value > 0) for value in filtered_dict.values() if value['label'] == 1 and value['correct']]\n",
    "\n",
    "# Find the intersection of all sets to get the common gene names\n",
    "common_genes = set.intersection(*positive_genes_sets)\n",
    "\n",
    "# Print the common genes\n",
    "print(\"Common genes among correctly classified patients:\")\n",
    "print(common_genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75bdfc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes with positive SHAP values across correctly classified patients with higher than average SHAP values: 13003\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average predictive score among correctly classified patients\n",
    "average_score_correct_patients = np.mean([value['predictive_score'] for value in filtered_dict.values() if value['label'] == 1 and value['correct']])\n",
    "\n",
    "# Create a set to store the union of gene names with positive SHAP values for correctly classified patients with higher than average SHAP values\n",
    "union_genes = set()\n",
    "\n",
    "# Iterate over the filtered dictionary and update the union set\n",
    "for value in filtered_dict.values():\n",
    "    if value['label'] == 1 and value['correct'] and value['predictive_score'] > average_score_correct_patients:\n",
    "        positive_genes = {gene for gene, shap_value in value['shap_values'].items() if shap_value > 0}\n",
    "        union_genes.update(positive_genes)\n",
    "\n",
    "# Print the number of unique genes\n",
    "print(\"Number of unique genes with positive SHAP values across correctly classified patients with higher than average SHAP values:\", len(union_genes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169de51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125549cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract all positive SHAP values from the filtered dictionary\n",
    "positive_shap_values = []\n",
    "for value in filtered_dict.values():\n",
    "    positive_shap_values.extend([shap_value for shap_value in value['shap_values'].values() if shap_value > 0])\n",
    "\n",
    "# Plot a histogram of the positive SHAP values\n",
    "plt.hist(positive_shap_values, bins=190, color='blue', alpha=0.7)\n",
    "plt.xlabel('Positive SHAP Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Positive SHAP Values')\n",
    "plt.xlim(0,0.001)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f08904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv('./metadata_v6_rosmap.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225235f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfc6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730adffb",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
